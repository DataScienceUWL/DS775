{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-7c1ac19e-5241-418f-9f2f-ca961ebb1b3b.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"260.509px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"ec6932","input":"#not included in quiz/solutions\n#Use the following: 'action', 'adventure', 'Beijing New Picture Film Co. Ltd.', 1000000, filtered after\nbuild_chart(movies, filterMovies, weighted_rating, 'after', 5)","metadata":{"cocalc":{"outputs":{"1":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"action"},"2":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"3":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"adventure"},"4":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"5":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"Beijing New Picture Film Co. Ltd."},"6":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"7":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"1000000"},"8":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"120"}}}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"8b2ba8","input":"#Not included in Quiz/Solutions\n# execute to import notebook styling for tables and width etc.\nfrom IPython.core.display import HTML\nimport urllib.request\nresponse = urllib.request.urlopen('https://raw.githubusercontent.com/DataScienceUWL/DS775v2/master/ds755.css')\nHTML(response.read().decode(\"utf-8\"));\n\n\n# computational imports\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk import word_tokenize    \nnltk.download('averaged_perceptron_tagger')\nfrom sklearn.feature_extraction import text\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.corpus import wordnet as wn\nimport string","metadata":{"code_folding":[0]},"output":{"0":{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/user/nltk_data...\n"},"1":{"name":"stderr","output_type":"stream","text":"[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"}},"pos":0,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"f9ad21","input":"#Add your code here","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"fad826","input":"#Add your code here","pos":36,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"3f7396","input":"#Add your code here\n","pos":38,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"b16765","input":"#hint code: not included in quiz/solutions\n# Read in some ted talk data\nted = pd.read_csv('data/ted-simplified.csv')\n\n#Define a TF-IDF Vectorizer Object. Use the LemmaTokenizer defined above, convert to lowercase, and remove stopwords, and only use the top 100 features.\ntfidf = TfidfVectorizer(tokenizer=LemmaTokenizer(), lowercase=True, stop_words=lemmatized_stop_words, max_features = 100)\n\nsim = fetchSimilarityMatrix(ted, 'description', tfidf, 'Tfidf')\nround(sim[1,0], 2)","output":{"0":{"name":"stdout","output_type":"stream","text":"Using Linear Kernel (Tfidf)\n"},"1":{"data":{"text/plain":"0.2"},"exec_count":11,"output_type":"execute_result"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"cd72dd","input":"#Add your code here","pos":41,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"80d62d","input":"#Add your code here","pos":44,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"3d5b30","input":"#Add your code here","pos":46,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"6f75ca","input":"#Add your code here","pos":48,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"4c4661","input":"#Add your code here","pos":50,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"f95517","input":"#hint code\nsimdf = pd.DataFrame(sim, index=movies['title'], columns=movies['title'])\nround(simdf['Spider-Man 3']['The Dark Knight Rises'], 2)","output":{"0":{"data":{"text/plain":"0.11"},"exec_count":19,"output_type":"execute_result"}},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"081b68","input":"#Add  your code here","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"be0d4a","input":"#not included in quiz/solutions\ndef content_recommender(df, seed, seedCol, sim_matrix,  topN=5): \n    #get the indices based off the seedCol\n    indices = pd.Series(df.index, index=df[seedCol]).drop_duplicates()\n    \n    # Obtain the index of the item that matches our seed\n    idx = indices[seed]\n    \n    # Get the pairwsie similarity scores of all items and convert to tuples\n    sim_scores = list(enumerate(sim_matrix[idx]))\n    \n    #delete the item that was passed in\n    del sim_scores[idx]\n    \n    # Sort the items based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    \n    # Get the scores of the top-n most similar items.\n    sim_scores = sim_scores[:topN]\n    \n    # Get the item indices\n    movie_indices = [i[0] for i in sim_scores]\n    \n    # Return the topN most similar items\n    return df.iloc[movie_indices]","pos":43,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"07ca9b","input":"#Add your code here","pos":13,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"db42c5","input":"\ndef filterMovies(df, genre1, genre2, company, budgetmax):\n    '''\n    Parameters:\n    df: The pandas dataframe to filter\n    genre1: A possible genre\n    genre2: Another possible genre\n    company: A production company that can not be in the production company column\n    budgetmax: The maximum budget allowed\n\n    Returns: a filtered dataframe\n    '''\n    ##############\n    #write your code here\n    ##############\n    ","pos":8,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"f7757e","input":"#Add your code here","pos":15,"type":"cell"}
{"cell_type":"code","exec_count":47,"id":"3acd89","input":"#not included in quiz/solutions\n#################\n# Provided code. Run this cell \n#################\n\n# Function to compute the IMDB weighted rating for each movie\ndef weighted_rating(x, m, C):\n    v = x['vote_count']\n    R = x['vote_average']\n    # Compute the weighted score\n    return (v/(v+m) * R) + (m/(m+v) * C)","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":48,"id":"a78acf","input":"\ndef build_chart(df, filter_func, rater, filter_location, n=10):\n    '''\n    Parameters\n    df: the dataframe to that will be filtered, scored, sorted (not necessarily in that order)\n    filter: the function that's being used to filter (in this case, it would be the filterMovies function)\n    rater: the function used to rate or score each movie (in this case, it would be the weighted_rating function)\n    filter_location: either the string 'before' or the string 'after.' If 'before' is passed, the filter will be applied before scoring. If after, it will be applied after.\n    n: the number of rows to return. Defaults to 10\n\n    Returns\n    The top n rows of the sorted dataframe\n    '''\n    #Add your code here\n","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"7839a3","input":"#add your code here","metadata":{"cocalc":{"outputs":{"1":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"horror"},"2":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"3":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"mystery"},"5":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"Paramount Pictures"},"6":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"}}}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"a121fb","input":"#Add your code here\n","metadata":{"cocalc":{"outputs":{"1":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"horror"},"3":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"mystery"},"4":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"5":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"Paramount Pictures"},"7":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"1500000"}}}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"e31042","input":"\ndef fetchSimilarityMatrix(df, soupCol, vectorizer, vectorType='Tfidf'):\n    '''\n    Parameters\n    df: the dataframe containing a soup column to tranform\n    soupCol: The string title of the soup column\n    vectorizer: an initialized vectorizer, with all pre-processing you desire\n    vectorType: 'Tfidf' or 'Count' - representing the type of vectorizer you used.\n\n    Returns\n    Sparse Similarity Matrix\n    '''\n\n    #Add your code here\n\n","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"921277","input":"#Add your code here","pos":32,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"a480c4","input":"#not included in quiz/solutions\n#################################\n# This cell does all the set up work - you only need to run this once per notebook\n#################################\n\n#Create a helper function to get part of speech\ndef get_wordnet_pos(word, pretagged = False):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    if pretagged:\n        tag = word[1].upper() \n    else:\n        tag = nltk.pos_tag([word])[0][1][0].upper()\n    \n    tag_dict = {\"J\": wn.ADJ,\n                \"N\": wn.NOUN,\n                \"V\": wn.VERB,\n                \"R\": wn.ADV}\n\n    return tag_dict.get(tag, wn.NOUN)\n\n#create a tokenizer that uses lemmatization (word shortening)\nclass LemmaTokenizer(object):\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, articles):\n        \n        #get the sentences\n        sents = sent_tokenize(articles)\n        #get the parts of speech for sentence tokens\n        sent_pos = [nltk.pos_tag(word_tokenize(s)) for s in sents]\n        #flatten the list\n        pos = [item for sublist in sent_pos for item in sublist]\n        #lemmatize based on POS (otherwise, all words are nouns)\n        lems = [self.wnl.lemmatize(t[0], get_wordnet_pos(t, True)) for t in pos if t[0] not in string.punctuation]\n        #clean up in-word punctuation\n        lems_clean = [''.join(c for c in s if c not in string.punctuation) for s in lems]\n        return lems_clean \n\n\n    \n#lemmatize the stop words\nlemmatizer = WordNetLemmatizer()\nlemmatized_stop_words = [lemmatizer.lemmatize(w) for w in text.ENGLISH_STOP_WORDS]\n#extend the stop words with any other words you want to add, these are bits of contractions\nlemmatized_stop_words.extend(['ve','nt','ca','wo','ll'])","pos":26,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"0ca3a7","input":"#Add your code here\n","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"00197a","input":"# Build a Knowledge-Based Recommender","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"2c9a4f","input":"## **Question 13** - Preparing the Movies Metadata Soup (Manually Graded) <font color=\"magenta\">5 points</font>\n\nFor this problem we'll be using the same data set **tmdb-simplified.csv** to build a meta-data based recommender by creating a \"soup\" based on: \n\n- all genres\n- all keywords\n- all production companies\n\nYou will need to sanitize the production companies and the keywords. Review the self-assessment solution for code to sanitize.\n\nMake sure that you concatenate the columns in the order listed (genres, then keywords, then production companies).\n","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"2e5827","input":"## **Question 5** Calling Your Filter Function <font color=\"magenta\">2 points</font>\nCall your function using the following parameters:\n\n* genres of 'action' and 'crime'\n* the production company 'Columbia Pictures'\n* max budget of 2 million (2000000). \n\nReport how many movies are left.\n\n\n\n\n","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"375ed7","input":"## **Question 17** Generating Recommendations from the MetaData Soup <font color=\"magenta\">2 points</font>\nFinally! We have all our pieces and we can run our meta-data based content recommender. Use the pieces that you've done so far and the content_recommender function from the lesson (copied for you below) to determine the top 5 movies related to the \"title\" (that's your seed column) of \"Spider-Man 3\" - based on the similarity matrix you've already generated above.\n\nWhat is the top movie?\n\n* The Amazing Spider Man\n* The Moneky King 2\n* Spider-Man 2\n* The Broadway Melody\n* Krull\n","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"3d17c8","input":"## **Question 14** What is the soup for Spider-Man 3? <font color=\"magenta\">2 points</font>\n\nThere are lots of different ways to extract text from a Pandas dataframe. You can use whatever way you choose, just make sure that you're able to see the complete text. Spider-Man 3 should be the 6th row in your dataframe (so with zero-based indexes, that would be [5]. We recommend that you confirm that you're reviewing the correct row. Once you're sure you're looking at the correct row, select which of the following is the correct soup for Spider-Man 3.\n\n* fantasy action adventure dualidentity amnesia sandstorm columbiapictures lauraziskinproductions marvelenterprises\n* fantasy action adventure dualidentityamnesiasandstorm columbiapictures lauraziskinproductions marvelenterprises \n* fantasy action adventure dual identity amnesia sandstorm Columbia Pictures Laura Ziskin Productions Marvel Enterprises \n* fantasy action adventure d u a l i d e n t i t y a m n e s i a s a n d s t o r m columbiapictures lauraziskinproductions marvelenterprises ","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"429121","input":"## **Question 4** - Prep Work & Building a Filter Function (manually graded) <font color=\"magenta\">5 points</font>\n\nBefore we build the recommender function that allows for user input, we're going to write a filter function that takes in manual (coded) input and filters our dataframe. Your function should take in parameters for the dataframe, two genres, a production company, and max budget. The filter should identify movies that meet the following criteria:\n\n* Have either genre\n* Are NOT made by the production company (the production company is not in the list of production companies)\n* Have a budget that is less than or equal to the max budget.\n\nThe function should return the filtered dataframe. \n\nWe've given you the function definition. Fill in the code.\n\nUse the examples given in the lesson and Banik's book as a guide. (Do not explode. Use the lesson approach.) \n","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"445d36","input":"## **Question 16** Determine Similarity between two movies <font color=\"magenta\">1 points</font>\nThere are many ways to use the matrix to determine the similarity between any two movies. In the cell below, we determine the similarity between 'Spider-Man 3' and 'The Dark Knight Rises' rounded to 2 digits.\n\n<font color=\"blue\">Hint: it should be 0.11</font>\n\nBased on this sample code, determine the similarity between 'Primer' and 'Avatar', rounded to 2 digits.\n\n","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"5f2b1f","input":"## **Question 19** - Using N-Grams of the Overview <font color=\"magenta\">2 points</font>\nGenerate a similarity matrix using just 3 word phrases (n-grams) of the 'overview' column. Since this is freeform text, use the Tfidf vectorizer. Pre-process the text by lemmatizing the words, using the lemmatized_stop_words. Again, limit to 1000 features.  Generate the top 5 recommendations for 'Spider-Man 3' again.\n\n<font color=\"blue\">Hint: You should only need a few lines of code here...</font>\n\nWhat is the top movie?\n\n* The Amazing Spider Man\n* Pirates of the Caribbean: At World's End\n* John Carter\n* Spider-Man\n* Avatar","pos":47,"type":"cell"}
{"cell_type":"markdown","id":"6a626c","input":"## **Question 10** - Filter After <font color=\"magenta\">2 points</font>\n\nNow use the same parameters, but perform the filter after you apply the scores. \n\nWhat is the final movie in your chart?\n* The Evil Dead\n* Night of the Living Dead\n* Insidious\n* Eraserhead\n* Rebecca","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"756847","input":"<font size=18>Week 13 Homework - Recommender Systems 1</font>","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"79f442","input":"<font color='blue'>Hint: If you call your function with the following parameters, you should be left with 27 movies:</font>\n\n    * genres of 'action' and 'adventure' \n    * production company: 'Beijing New Picture Film Co. Ltd.'\n    * max budget: 1000000\n","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"7b7b50","input":"## **Question 18** - Using Just the Overview <font color=\"magenta\">2 points</font>\nInstead of using the soup, generate a similarity matrix using the 'overview' column. Since this is freeform text, use the Tfidf vectorizer. Pre-process the text by lemmatizing the words, using the lemmatized_stop_words. Again, limit to 1000 features.  Generate the top 5 recommendations for 'Spider-Man 3' again.\n\n<font color=\"blue\">Hint: You should only need a few lines of code here...</font>\n\nWhat is the top movie?\n\n* The Amazing Spider Man\n* The Monkey King 2\n* Spider-Man 2\n* The Broadway Melody\n* Krull\n","pos":45,"type":"cell"}
{"cell_type":"markdown","id":"863d98","input":"You will be using the data set **tmdb-simplified.csv** to build a simple knowledge-based recommender system. This data set can be found in the data folder in the same folder as this notebook. \n\n**You will need to use the option encoding = \"ISO-8859-1\" in the read_csv function in order to open this file.** \n\n* Read in the file to a variable called \"movies\" and review the data.\n* Apply literal_eval to the genres, keywords, and production_companies columns. (They are already lists, not dictionaries.)\n* Filter out movies that have have nothing or zero in the budget.\n* Determine how many rows are in this dataframe. \n\n**Note: This code is ungraded.**","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"8b6840","input":"## **Question 11** - Create the fetchSimilarityMatrix Function (Manually Graded) <font color=\"magenta\">5 points</font>\nWe know that we have two kinds of vectorization we can do, and each requires a slightly different similarity matrix. Let's create a wrapper function that has the following parameters:\n\n* df: the dataframe holding our data\n* soupCol: the string name of the column holding our soup (this should already be ready to go - you shouldn't be creating your soup inside this function)\n* vectorizer: an initialized vectorizer. This will either be a TfidfVectorizer or a CountVectorizer\n* vectorType: a string representing either Tfidf or Count to indicate which type of vectorizer we are using\n\nInside your function, you'll:\n* make sure your soup has no NaN (fill with empty strings)\n* fit_transform your soup into a number matrix\n* if the vector type is 'Tfidf', use the linear_kernel() function to generate a similarity matrix\n* if the vector type is 'Count', use the cosine_similarity() function to generate a similarity matrix\n* return the sparse similarity matrix\n\n","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"8c46e7","input":"<font color=\"blue\">Hint: if you run the cell below, the first movie returned should be Monty Python and the Holy Grail</font>","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"94eb5a","input":"## **Question 3** - How many rows of data are there? <font color=\"magenta\">1 point</font>\n\n","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"a011c6","input":"## **Question 12** - Test Your fetchSimilarityMatrix Function <font color=\"magenta\">2 points</font>\nUsing the ted data we read in for you above, initialize a CountVectorizer that uses 'english' stop words, lowercase, and all the features. Call the fetchSimilarityMatrix function, using the column 'topics' for your soup.\n\nWhat is the value [0,2] position in your matrix (rounded to 2 digits)?\n","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"b17efd","input":"## **Question 15** Create Your Movie Similarity Matrix (Manually Graded) <font color=\"magenta\">2 points</font>\nInstantiate a CountVectorizer instance, converting to lowercase and removing 'english' stop words and a maximum of 1000 features. Using this instance and your fetchSimilarityMatrix function, fetch the appropriate similarity matrix for the movie df's \"soup\" column.\n\n","pos":37,"type":"cell"}
{"cell_type":"markdown","id":"b842b2","input":"# Preparing to Build a Content-Based Recommender\nIn this section of the homework, you will prepare to build a content-based recommender that can flexibly use either CountVectorizer or TfidfVectorizer. We're including  our lemmatization setup code for you. Run the cell below then proceed to part a.","pos":25,"type":"cell"}
{"cell_type":"markdown","id":"bc68f8","input":"## **Question 9** - Testing Your Function <font color=\"magenta\">2 points</font>\n\nRun your build_chart with the following parameters:\n\n* genre 1 = horror\n* genre 2 = mystery\n* production company = Paramount Pictures\n* max budget = 1500000\n* n = 7\n* filter *before* scoring\n\nWhat is the final movie in your chart? \n* The Evil Dead\n* Night of the Living Dead\n* Saw\n* Eraserhead\n* Rebecca\n","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"d35ad6","input":"<font color=\"blue\">Hint: Running the code below should return 0.2</font>","pos":29,"type":"cell"}
{"cell_type":"markdown","id":"d8d94d","input":"## **Question 8** - Creating the User Input Function (Manually graded) <font color=\"magenta\">5 points</font>\nWe finally have all the pieces to create a function that returns the top N movies based on the IMDB score and the filter you wrote. We're going to to modify/expand on the build_chart function from the lesson. Once again, we'll give you the function definition in the cell below. We are also giving you the weighted_rating function. Be sure to run that cell.\n\nYour build_chart function should take in:\n* the dataframe to filter\n* the filter function (you've already written this)\n* the rater function (provided below)\n* a parameter called \"filter_location\" which should be either the string 'before' or the string 'after' (filter before or after computing m and C and scoring) \n* a number of movies to return. \n\nThe function should return the top 'n' rows of a dataframe sorted in descending order of the score column. It will return whatever columns you pass in.","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"e88c34","input":"## **Question 6** - Fetch the List of Unique Genres (multiple choice) <font color=\"magenta\">2 points</font>\nUsing the examples from the lesson, generate a *string* of unique genres. *Sort* the genres alphabetically.\n\nWhat is the 3rd word in the sorted string list?\n\n* fantasy\n* animation\n* comedy\n* adventure\n* crime\n\n\n","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"e8ea20","input":"## **Question 20** Soup + Overview <font color=\"magenta\">2 points</font>\n\nNow add the overview to your soup. Since we do not want the genres and keywords down-weighted for describing multiple movies, use a CountVectorizer with lemmatization and the lemmatized_stop_words. Once again, limit your features to 1000. (We're limiting features here just to speed up processing time.) Again find recommendations for 'Spider-Man 3.'\n\nWhat is the top movie?\n\n* Spider-Man\n* The Amazing Spider-Man 2\n* Avatar\n* Spider-Man\n* Krull","pos":49,"type":"cell"}
{"cell_type":"markdown","id":"eed0b9","input":"## **Question 7** - Count the Number of Unique Production Companies <font color=\"magenta\">2 points</font>\nUsing the examples from the lesson, generate a numpy array of production companies and determine the length of that array. How many unique production companies are there?\n\n","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"f43107","input":"# General Multiple Choice Questions\n## **Question 1** <font color=\"magenta\">2 points</font>\nWhen would you use dot-product similarity function?\n\n* To calculate the similarity matrix for a Tfidf Vector Matrix \n* To calculate the similarity matrix for a Count Vector Matrix \n* To standardize text to root words \n* To combine columns of text before vectorization\n\n## **Question 2** <font color=\"magenta\">2 points</font>\nWhat is lemmatization?\n\n* Shortening words by removing suffixes and prefixes \n* Standardizing text to their root words \n* Generating a matrix of word counts \n* Chunking text into multi-word phrases \n\n\n\n","pos":2,"type":"cell"}
{"id":0,"time":1625000148808,"type":"user"}
{"last_load":1625000149392,"type":"file"}