{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/user/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#Not included in Quiz/Solutions\n",
    "# execute to import notebook styling for tables and width etc.\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# computational imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize    \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet as wn\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Week 13 Homework - Recommender Systems 1\n",
    "\n",
    "### When asking questions about homework in Piazza please use a tag in the subject line like HW1.3 to refer to Homework 1, Question 3.  So the subject line might be **HW1.3 question**.  Note there are no spaces in \"HW1.3\".  This really helps keep Piazza easily searchable for everyone!\n",
    "\n",
    "For full credit, all code in this notebook must be both executed in this notebook and copied to the Canvas quiz where indicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# General Multiple Choice Questions\n",
    "## **Question 1** <font color=\"magenta\">2 points</font>\n",
    "When would you use dot-product similarity function?\n",
    "\n",
    "* To calculate the similarity matrix for a Tfidf Vector Matrix \n",
    "* To calculate the similarity matrix for a Count Vector Matrix \n",
    "* To standardize text to root words \n",
    "* To combine columns of text before vectorization\n",
    "\n",
    "## **Question 2** <font color=\"magenta\">2 points</font>\n",
    "What is lemmatization?\n",
    "\n",
    "* Shortening words by removing suffixes and prefixes \n",
    "* Standardizing text to their root words \n",
    "* Generating a matrix of word counts \n",
    "* Chunking text into multi-word phrases \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build a Knowledge-Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You will be using the data set **tmdb-simplified.csv** to build a simple knowledge-based recommender system. This data set can be found in the data folder in the same folder as this notebook. \n",
    "\n",
    "**You will need to use the option encoding = \"ISO-8859-1\" in the read_csv function in order to open this file.** \n",
    "\n",
    "* Read in the file to a variable called \"movies\" and review the data.\n",
    "* Apply literal_eval to the genres, keywords, and production_companies columns. (They are already lists, not dictionaries.)\n",
    "* Filter out movies that have have nothing or zero in the budget.\n",
    "* Determine how many rows are in this dataframe. \n",
    "\n",
    "**Note: This code is ungraded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 3** - How many rows of data are there? <font color=\"magenta\">1 point</font>\n",
    "\n",
    "<body style=\"background-color:aquamarine;\">\n",
    "You won't get the right answer if you don't filter out rows with NaNs and zero values for budget. <br><br>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 4** - Prep Work & Building a Filter Function (manually graded) <font color=\"magenta\">5 points</font>\n",
    "\n",
    "Before we build the recommender function that allows for user input, we're going to write a filter function that takes in manual (coded) input and filters our dataframe. Your function should take in parameters for the dataframe, two genres, a production company, and max budget. The filter should identify movies that meet the following criteria:\n",
    "\n",
    "* Have either genre\n",
    "* Are NOT made by the production company (the production company is not in the list of production companies)\n",
    "* Have a budget that is less than or equal to the max budget.\n",
    "\n",
    "The function should return the filtered dataframe. \n",
    "\n",
    "We've given you the function definition. Fill in the code.\n",
    "\n",
    "Use the examples given in the lesson and Banik's book as a guide. (Do not explode. Use the lesson approach.) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def filterMovies(df, genre1, genre2, company, budgetmax):\n",
    "    '''\n",
    "    Parameters:\n",
    "    df: The pandas dataframe to filter\n",
    "    genre1: A possible genre\n",
    "    genre2: Another possible genre\n",
    "    company: A production company that can not be in the production company column\n",
    "    budgetmax: The maximum budget allowed\n",
    "\n",
    "    Returns: a filtered dataframe\n",
    "    '''\n",
    "    ##############\n",
    "    #write your code here\n",
    "    ##############\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color='blue'>Hint: If you call your function with the following parameters, you should be left with 27 movies:</font>\n",
    "\n",
    "    * genres of 'action' and 'adventure' \n",
    "    * production company: 'Beijing New Picture Film Co. Ltd.'\n",
    "    * max budget: 1000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 5** Calling Your Filter Function <font color=\"magenta\">2 points</font>\n",
    "Call your function using the following parameters:\n",
    "\n",
    "* genres of 'action' and 'crime'\n",
    "* the production company 'Columbia Pictures'\n",
    "* max budget of 2 million (2000000). \n",
    "\n",
    "Report how many movies are left.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add  your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 6** - Fetch the List of Unique Genres (multiple choice) <font color=\"magenta\">2 points</font>\n",
    "Using the examples from the lesson, generate a *string* of unique genres. *Sort* the genres alphabetically.\n",
    "\n",
    "What is the 3rd word in the sorted string list?\n",
    "\n",
    "* fantasy\n",
    "* animation\n",
    "* comedy\n",
    "* adventure\n",
    "* crime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 7** - Count the Number of Unique Production Companies <font color=\"magenta\">2 points</font>\n",
    "Using the examples from the lesson, generate a numpy array of production companies and determine the length of that array. How many unique production companies are there?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 8** - Creating the User Input Function (Manually graded) <font color=\"magenta\">5 points</font>\n",
    "We finally have all the pieces to create a function that returns the top N movies based on the IMDB score and the filter you wrote. We're going to to modify/expand on the build_chart function from the lesson. Once again, we'll give you the function definition in the cell below. We are also giving you the weighted_rating function. Be sure to run that cell.\n",
    "\n",
    "Your build_chart function should take in:\n",
    "* the dataframe to filter\n",
    "* the filter function (you've already written this)\n",
    "* the rater function (provided below)\n",
    "* a parameter called \"filter_location\" which should be either the string 'before' or the string 'after' (filter before or after computing m and C and scoring) \n",
    "* a number of movies to return.\n",
    "* use the 80th percentile to compute m\n",
    "\n",
    "The function should return the top 'n' rows of a dataframe sorted in descending order of the score column. It will return whatever columns you pass in.\n",
    "\n",
    "<body style=\"background-color:aquamarine;\">\n",
    "Unlike the lesson, we do not want you to filter out the movies with low vote counts! <br><br>\n",
    "There are two approaches to writing the build_chart function presented in the lesson.  <br><br> The first prompts the user to input the values used for filtering, <br> the second approach allows the values to be passed as arguments to the build_chart function. <br><br> We recommend the second approach as it's much easier for testing and development. <br><br>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#not included in quiz/solutions\n",
    "#################\n",
    "# Provided code. Run this cell \n",
    "#################\n",
    "\n",
    "# Function to compute the IMDB weighted rating for each movie\n",
    "def weighted_rating(x, m, C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    # Compute the weighted score\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "def build_chart(df, filter_func, rater, filter_location, n=10):\n",
    "    '''\n",
    "    Parameters\n",
    "    df: the dataframe to that will be filtered, scored, sorted (not necessarily in that order)\n",
    "    filter: the function that's being used to filter (in this case, it would be the filterMovies function)\n",
    "    rater: the function used to rate or score each movie (in this case, it would be the weighted_rating function)\n",
    "    filter_location: either the string 'before' or the string 'after.' If 'before' is passed, the filter will be applied before scoring. If after, it will be applied after.\n",
    "    n: the number of rows to return. Defaults to 10\n",
    "\n",
    "    Returns\n",
    "    The top n rows of the sorted dataframe\n",
    "    '''\n",
    "    #Add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color=\"blue\">Hint: if you run the cell below, the first movie returned should be Monty Python and the Holy Grail</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cocalc": {
     "outputs": {
      "1": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "action"
      },
      "2": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream"
      },
      "3": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "adventure"
      },
      "4": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream"
      },
      "5": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "Beijing New Picture Film Co. Ltd."
      },
      "6": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream"
      },
      "7": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "1000000"
      },
      "8": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "120"
      }
     }
    },
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#not included in quiz/solutions\n",
    "#Use the following: 'action', 'adventure', 'Beijing New Picture Film Co. Ltd.', 1000000, filtered after\n",
    "build_chart(movies, filterMovies, weighted_rating, 'after', 5) # modify to pass filtering values ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 9** - Testing Your Function <font color=\"magenta\">2 points</font>\n",
    "\n",
    "Feel free to modify your build_chart function to allow the inputs to be passed to the function as we did in the lesson.  It makes for easier testing.\n",
    "\n",
    "Run your build_chart with the following parameters:\n",
    "\n",
    "* genre 1 = horror\n",
    "* genre 2 = mystery\n",
    "* production company = Paramount Pictures\n",
    "* max budget = 1500000\n",
    "* n = 7\n",
    "* filter *before* scoring\n",
    "\n",
    "What is the final movie in your chart? \n",
    "* The Evil Dead\n",
    "* Night of the Living Dead\n",
    "* Saw\n",
    "* Eraserhead\n",
    "* Rebecca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cocalc": {
     "outputs": {
      "1": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "horror"
      },
      "2": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream"
      },
      "3": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "mystery"
      },
      "5": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "Paramount Pictures"
      },
      "6": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream"
      }
     }
    },
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 10** - Filter After <font color=\"magenta\">2 points</font>\n",
    "\n",
    "Now use the same parameters, but perform the filter after you apply the scores. \n",
    "\n",
    "What is the final movie in your chart?\n",
    "* The Evil Dead\n",
    "* Night of the Living Dead\n",
    "* Insidious\n",
    "* Eraserhead\n",
    "* Rebecca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cocalc": {
     "outputs": {
      "1": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "horror"
      },
      "3": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "mystery"
      },
      "4": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream"
      },
      "5": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "Paramount Pictures"
      },
      "7": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "1500000"
      }
     }
    },
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preparing to Build a Content-Based Recommender\n",
    "In this section of the homework, you will prepare to build a content-based recommender that can flexibly use either CountVectorizer or TfidfVectorizer. We're including  our lemmatization setup code for you. Run the cell below then proceed to part a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#not included in quiz/solutions\n",
    "#################################\n",
    "# This cell does all the set up work - you only need to run this once per notebook\n",
    "#################################\n",
    "\n",
    "#Create a helper function to get part of speech\n",
    "def get_wordnet_pos(word, pretagged = False):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    if pretagged:\n",
    "        tag = word[1].upper() \n",
    "    else:\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    \n",
    "    tag_dict = {\"J\": wn.ADJ,\n",
    "                \"N\": wn.NOUN,\n",
    "                \"V\": wn.VERB,\n",
    "                \"R\": wn.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wn.NOUN)\n",
    "\n",
    "#create a tokenizer that uses lemmatization (word shortening)\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        \n",
    "        #get the sentences\n",
    "        sents = sent_tokenize(articles)\n",
    "        #get the parts of speech for sentence tokens\n",
    "        sent_pos = [nltk.pos_tag(word_tokenize(s)) for s in sents]\n",
    "        #flatten the list\n",
    "        pos = [item for sublist in sent_pos for item in sublist]\n",
    "        #lemmatize based on POS (otherwise, all words are nouns)\n",
    "        lems = [self.wnl.lemmatize(t[0], get_wordnet_pos(t, True)) for t in pos if t[0] not in string.punctuation]\n",
    "        #clean up in-word punctuation\n",
    "        lems_clean = [''.join(c for c in s if c not in string.punctuation) for s in lems]\n",
    "        return lems_clean \n",
    "\n",
    "\n",
    "    \n",
    "#lemmatize the stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_stop_words = [lemmatizer.lemmatize(w) for w in text.ENGLISH_STOP_WORDS]\n",
    "#extend the stop words with any other words you want to add, these are bits of contractions\n",
    "lemmatized_stop_words.extend(['ve','nt','ca','wo','ll'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 11** - Create the fetchSimilarityMatrix Function (Manually Graded) <font color=\"magenta\">5 points</font>\n",
    "We know that we have two kinds of vectorization we can do, and each requires a slightly different similarity matrix. Let's create a wrapper function that has the following parameters:\n",
    "\n",
    "* df: the dataframe holding our data\n",
    "* soupCol: the string name of the column holding our soup (this should already be ready to go - you shouldn't be creating your soup inside this function)\n",
    "* vectorizer: an initialized vectorizer. This will either be a TfidfVectorizer or a CountVectorizer\n",
    "* vectorType: a string representing either Tfidf or Count to indicate which type of vectorizer we are using\n",
    "\n",
    "Inside your function, you'll:\n",
    "* make sure your soup has no NaN (fill with empty strings)\n",
    "* fit_transform your soup into a number matrix\n",
    "* if the vector type is 'Tfidf', use the linear_kernel() function to generate a similarity matrix\n",
    "* if the vector type is 'Count', use the cosine_similarity() function to generate a similarity matrix\n",
    "* return the sparse similarity matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "\n",
    "def fetchSimilarityMatrix(df, soupCol, vectorizer, vectorType='Tfidf'):\n",
    "    '''\n",
    "    Parameters\n",
    "    df: the dataframe containing a soup column to tranform\n",
    "    soupCol: The string title of the soup column (or any column containing strings for which you want similarities)\n",
    "    vectorizer: an initialized vectorizer, with all pre-processing you desire\n",
    "    vectorType: 'Tfidf' or 'Count' - representing the type of vectorizer you used.\n",
    "\n",
    "    Returns\n",
    "    Sparse Similarity Matrix\n",
    "    '''\n",
    "\n",
    "    #Add your code here\n",
    "    \n",
    "    # 1. remove NaN from df for the designated column\n",
    "    # 2. compute the count or tfidf matrix using the vectorizer you passed in (use fit_transform)\n",
    "\n",
    "    #apply the appropriate vectorizer\n",
    "    if(vectorType=='Tfidf'):\n",
    "        print('Using Linear Kernel (Tfidf)')\n",
    "        # 3.  compute the sim matrix as shown in the lesson for a tfidf matrix, call it sim\n",
    "    else:\n",
    "        print('Using Cosine_similarity')\n",
    "        # 4.  compute the sim matrix as shown in the lesson for a count matrix, call it sim\n",
    "    return(sim)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color=\"blue\">Hint: Running the code below should return 0.2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Kernel (Tfidf)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hint code: not included in quiz/solutions\n",
    "# Read in some ted talk data\n",
    "ted = pd.read_csv('data/ted-simplified.csv')\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Use the LemmaTokenizer defined above, convert to lowercase, and remove stopwords, and only use the top 100 features.\n",
    "tfidf = TfidfVectorizer(tokenizer=LemmaTokenizer(), lowercase=True, stop_words=lemmatized_stop_words, max_features = 100)\n",
    "\n",
    "sim = fetchSimilarityMatrix(ted, 'description', tfidf, 'Tfidf')\n",
    "round(sim[1,0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 12** - Test Your fetchSimilarityMatrix Function <font color=\"magenta\">2 points</font>\n",
    "Using the ted data we read in for you above, initialize a CountVectorizer that uses 'english' stop words, lowercase, and all the features. Call the fetchSimilarityMatrix function, using the column 'topics' for your soup.\n",
    "\n",
    "What is the value [0,2] position in your matrix (rounded to 2 digits)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 13** - Preparing the Movies Metadata Soup (Manually Graded) <font color=\"magenta\">5 points</font>\n",
    "\n",
    "For this problem we'll be using the same data set **tmdb-simplified.csv** to build a meta-data based recommender by creating a \"soup\" based on: \n",
    "\n",
    "- all genres\n",
    "- all keywords\n",
    "- all production companies\n",
    "\n",
    "You will need to sanitize the production companies and the keywords (but not genres). Review the self-assessment solution for code to sanitize.\n",
    "\n",
    "Make sure that you concatenate the columns in the order listed (genres, then keywords, then production companies).\n",
    "\n",
    "Do not reload the data, just use the datframe you created and filtered in Question 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 14** What is the soup for Spider-Man 3? <font color=\"magenta\">2 points</font>\n",
    "\n",
    "<body style=\"background-color:aquamarine;\">\n",
    "If your soup text has text that looks like this:  \"d u a l i d e n t i t y\" it's probably because you applied .join() <br>\n",
    "to a string and not a list of strings.  Make sure .join() is only applied to lists of strings.\n",
    "</body>\n",
    "\n",
    "There are lots of different ways to extract text from a Pandas dataframe. You can use whatever way you choose, just make sure that you're able to see the complete text. Spider-Man 3 should be the 6th row in your dataframe (so with zero-based indexes, that would be [5]. We recommend that you confirm that you're reviewing the correct row. Once you're sure you're looking at the correct row, select which of the following is the correct soup for Spider-Man 3.\n",
    "\n",
    "* fantasy action adventure dualidentity amnesia sandstorm columbiapictures lauraziskinproductions marvelenterprises\n",
    "* fantasy action adventure dualidentityamnesiasandstorm columbiapictures lauraziskinproductions marvelenterprises \n",
    "* fantasy action adventure dual identity amnesia sandstorm Columbia Pictures Laura Ziskin Productions Marvel Enterprises \n",
    "* fantasy action adventure d u a l i d e n t i t y a m n e s i a s a n d s t o r m columbiapictures lauraziskinproductions marvelenterprises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 15** Create Your Movie Similarity Matrix (Manually Graded) <font color=\"magenta\">2 points</font>\n",
    "Instantiate a CountVectorizer instance, converting to lowercase and removing 'english' stop words and a maximum of 1000 features. Using this instance and your fetchSimilarityMatrix function, fetch the appropriate similarity matrix for the movie df's \"soup\" column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 16** Determine Similarity between two movies <font color=\"magenta\">1 points</font>\n",
    "There are many ways to use the matrix to determine the similarity between any two movies. In the cell below, we determine the similarity between 'Spider-Man 3' and 'The Dark Knight Rises' rounded to 2 decimal places.  Do not use LemmaTokenizer this time.\n",
    "\n",
    "<font color=\"blue\">Hint: it should be 0.11</font>\n",
    "\n",
    "Based on this sample code, determine the similarity between 'Primer' and 'Avatar', rounded to 2 decimal places.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hint code\n",
    "simdf = pd.DataFrame(sim, index=movies['title'], columns=movies['title'])\n",
    "round(simdf['Spider-Man 3']['The Dark Knight Rises'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 17** Generating Recommendations from the MetaData Soup <font color=\"magenta\">2 points</font>\n",
    "Finally! We have all our pieces and we can run our meta-data based content recommender. Use the pieces that you've done so far and the content_recommender function from the lesson (copied for you below) to determine the top 5 movies related to the \"title\" (that's your seed column) of \"Spider-Man 3\" - based on the similarity matrix you've already generated above.\n",
    "\n",
    "What is the top movie?\n",
    "\n",
    "* The Amazing Spider Man\n",
    "* The Moneky King 2\n",
    "* Spider-Man 2\n",
    "* The Broadway Melody\n",
    "* Krull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#not included in quiz/solutions\n",
    "def content_recommender(df, seed, seedCol, sim_matrix,  topN=5): \n",
    "    #get the indices based off the seedCol\n",
    "    indices = pd.Series(df.index, index=df[seedCol]).drop_duplicates()\n",
    "    \n",
    "    # Obtain the index of the item that matches our seed\n",
    "    idx = indices[seed]\n",
    "    \n",
    "    # Get the pairwsie similarity scores of all items and convert to tuples\n",
    "    sim_scores = list(enumerate(sim_matrix[idx]))\n",
    "    \n",
    "    #delete the item that was passed in\n",
    "    del sim_scores[idx]\n",
    "    \n",
    "    # Sort the items based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the scores of the top-n most similar items.\n",
    "    sim_scores = sim_scores[:topN]\n",
    "    \n",
    "    # Get the item indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Return the topN most similar items\n",
    "    return df.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 18** - Using Just the Overview <font color=\"magenta\">2 points</font>\n",
    "Instead of using the soup, generate a similarity matrix using the 'overview' column. Since this is freeform text, use the Tfidf vectorizer. Pre-process the text by lemmatizing the words, using the lemmatized_stop_words. Again, limit to 1000 features.  Generate the top 5 recommendations for 'Spider-Man 3' again.\n",
    "\n",
    "<font color=\"blue\">Hint: You should only need a few lines of code here...</font>\n",
    "\n",
    "What is the top movie?\n",
    "\n",
    "* The Amazing Spider Man\n",
    "* The Monkey King 2\n",
    "* Spider-Man 2\n",
    "* The Broadway Melody\n",
    "* Krull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 19** - Using N-Grams of the Overview <font color=\"magenta\">2 points</font>\n",
    "Generate a similarity matrix using just 3 word phrases (n-grams) of the 'overview' column. Since this is freeform text, use the Tfidf vectorizer. Pre-process the text by lemmatizing the words, using the lemmatized_stop_words. Again, limit to 1000 features.  Generate the top 5 recommendations for 'Spider-Man 3' again.\n",
    "\n",
    "<font color=\"blue\">Hint: You should only need a few lines of code here...</font>\n",
    "\n",
    "What is the top movie?\n",
    "\n",
    "* The Amazing Spider Man\n",
    "* Pirates of the Caribbean: At World's End\n",
    "* John Carter\n",
    "* Spider-Man\n",
    "* Avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **Question 20** Soup + Overview <font color=\"magenta\">2 points</font>\n",
    "\n",
    "Now add the overview to your soup. Since we do not want the genres and keywords down-weighted for describing multiple movies, use a CountVectorizer with lemmatization and the lemmatized_stop_words. Once again, limit your features to 1000. (We're limiting features here just to speed up processing time.) Again find recommendations for 'Spider-Man 3.'\n",
    "\n",
    "What is the top movie?\n",
    "\n",
    "* Spider-Man\n",
    "* The Amazing Spider-Man 2\n",
    "* Avatar\n",
    "* Escape from Planet Earth\n",
    "* Krull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Add your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260.509px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}