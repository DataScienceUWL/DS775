{"backend_state":"init","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"15a8fa","input":"","pos":22,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"3782a1","input":"","metadata":{"hidden":true},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"38990a","input":"","pos":10,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4a5931","input":"######\npop_size = 100 # should be even due to the way we'll implement crossover\nind_size = 10 # determines number of input variables for Rastrigin and each individual\n######\n#lower = -5.12 # lower and upper bounds on the real variables\n#upper = 5.12\ntourn_size = 3 # tournament size for selection\ncx_prob = 0.8 # probability a pair of parents crossover to produce two children\nmut_prob = 0.2 # probability an individual mutates\nind_prob = 0.1 # probability each variable in an individual mutates\n#sigma = (upper-lower)/6 # standard deviation (scale) for gaussian mutations\n###### maybe here\nnum_iter = 2000 # number of genetic algorithm mutations\nupdate_iter = 100 # how often to display output\n######\n\nstats = np.zeros((num_iter+1,3)) # for collecting statistics\n\n######\n# objective or fitness function\ndef rastrigin(x):\n    x = np.array(x) # force a numpy arrray here so that the math below works\n    return np.sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x) )\n######\n\n###### may need to also enforce that the variables are integers and not floats\n#initialize population and fitness np.random.randint(0,2,size=20,dtype=bool)\npop = np.random.uniform(low=lower, high=upper, size = (ind_size,pop_size))\nfitness = np.zeros(pop_size)\nfor j in range(pop_size):\n    fitness[j] = rastrigin(pop[:,j])\n######\n\n# initialize stats and output\nbest_fitness = min(fitness)\nstats[0,:] = np.array([0,best_fitness, best_fitness])\nprint('Iteration | Best this iter |    Best ever')\n\nfor iter in range(num_iter):\n    # tournament selection\n    sorted_pos = fitness.argsort() # sort pop by increasing fitness\n    fitness = fitness[sorted_pos]\n    pop = pop[:,sorted_pos]\n    select_pop = np.zeros((ind_size,pop_size)) # initialize selected population\n    for j in range(pop_size):\n        subset_pos = np.random.choice(pop_size,tourn_size,replace=False) # select without replacement\n        smallest_pos = np.min(subset_pos) # choose index corresponding to lowest fitness\n        select_pop[:,j] = pop[:,smallest_pos]\n\n    # one-point crossover (mating)\n    cx_pop = np.zeros((ind_size,pop_size)) # initialize crossover population\n    for j in range(int(pop_size/2)):  # pop_size must be even\n        #######\n        parent1, parent2 = select_pop[:,2*j], select_pop[:,2*j+1]\n        child1, child2 = parent1.copy(), parent2.copy()\n        if np.random.uniform() < cx_prob: # crossover occurs\n            cx_point = np.random.randint(1,ind_size) # crossover point between 0 and ind_size-2\n            child1[0:cx_point], child2[0:cx_point] = parent2[0:cx_point], parent1[0:cx_point]\n        cx_pop[:,2*j] = child1\n        cx_pop[:,2*j+1] = child2\n        ######\n\n    # gaussian mutation (rewritten to remove nested loop for speed)\n    mut_pop = np.zeros((ind_size,pop_size)) # initialize mutation population\n    for j in range(pop_size):\n        individual = cx_pop[:,j].copy() # copy is necessary to avoid conflicts in memory\n        if np.random.uniform()<mut_prob:\n            ###### swap the ith entry with a randomly selected entry with prob ind_prob\n            individual = individual + np.random.normal(0,sigma,ind_size)*(np.random.uniform(size=ind_size)<ind_prob)\n            individual = np.maximum(individual,lower) # clip to lower bound\n            individual = np.minimum(individual,upper) # clip to upper bound\n            ######\n        mut_pop[:,j] = individual.copy() # copy is necessary to avoid conflicts in memory\n\n    # fitness evaluation with local search\n    pop = mut_pop.copy()\n    for j in range(pop_size):\n        fitness[j] = rastrigin(pop[:,j])\n\n    # collect stats and output to screen\n    min_fitness = min(fitness) # best for this iteration\n    if min_fitness < best_fitness: # best for all iterations\n        best_fitness = min_fitness\n        index = np.argmin(fitness)\n        best_x = pop[:,index]\n\n    stats[iter+1,:] = np.array([iter+1,min_fitness, best_fitness])\n    if (iter+1) % update_iter == 0:\n        print(f\"{stats[iter+1,0]:9.0f} | {stats[iter+1,1]:14.3e} | {stats[iter+1,2]:12.3e}\")\n\n######\nprint(f\"The minimum value found of the Rastrigin function is {best_fitness:.4f}\")\nprint(\"The location of that minimum is:\")\n######\nprint('(',', '.join(f\"{x:.4f}\" for x in best_x),')')","pos":5,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ab302e","input":"","pos":20,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"fa1c6c","input":"","pos":14,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"4b3892","input":"# imports, add to this as needed\n\n# change to matplotlib notebook for classic view\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nfrom scipy.optimize import minimize\nimport json\nfrom simanneal import Annealer","metadata":{"code_folding":[]},"pos":0,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"07e21b","input":"pop_size = 100 # should be even due to the way we'll implement crossover\nind_size = 10 # determines number of input variables for Rastrigin and each individual\nlower = -5.12 # lower and upper bounds on the real variables\nupper = 5.12\ntourn_size = 3 # tournament size for selection\ncx_prob = 0.8 # probability a pair of parents crossover to produce two children\nmut_prob = 0.2 # probability an individual mutates\nind_prob = 0.1 # probability each variable in an individual mutates\nsigma = (upper-lower)/6 # standard deviation (scale) for gaussian mutations\nnum_iter = 2000 # number of genetic algorithm mutations\nupdate_iter = 100 # how often to display output\n\nstats = np.zeros((num_iter+1,3)) # for collecting statistics\n\n# objective or fitness function\ndef rastrigin(x):\n    x = np.array(x) # force a numpy arrray here so that the math below works\n    return np.sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x) )\n\n#initialize population and fitness\npop = np.random.uniform(low=lower, high=upper, size = (ind_size,pop_size))\nfitness = np.zeros(pop_size)\nfor j in range(pop_size):\n    fitness[j] = rastrigin(pop[:,j])\n\n# initialize stats and output\nbest_fitness = min(fitness)\nstats[0,:] = np.array([0,best_fitness, best_fitness])\nprint('Iteration | Best this iter |    Best ever')\n\nfor iter in range(num_iter):\n    ### CHANGE - local search goes here\n    #    - sort pop by increasing fitness\n    #    - take first three individuals with lowest fitness and replace them by the minimizing location resulting \n    #      from using scipy.optimize.minimize with bounds applied to each individual each individual\n    \n    # tournament selection\n    sorted_pos = fitness.argsort() # sort pop by increasing fitness\n    fitness = fitness[sorted_pos]\n    pop = pop[:,sorted_pos]\n    select_pop = np.zeros((ind_size,pop_size)) # initialize selected population\n    for j in range(pop_size):\n        subset_pos = np.random.choice(pop_size,tourn_size,replace=False) # select without replacement\n        smallest_pos = np.min(subset_pos) # choose index corresponding to lowest fitness\n        select_pop[:,j] = pop[:,smallest_pos]\n\n    ### CHANGE this to blended crossover\n    # one-point crossover (mating)\n    cx_pop = np.zeros((ind_size,pop_size)) # initialize crossover population\n    for j in range(int(pop_size/2)):  # pop_size must be even\n        parent1, parent2 = select_pop[:,2*j], select_pop[:,2*j+1]\n        child1, child2 = parent1.copy(), parent2.copy()\n        if np.random.uniform() < cx_prob: # crossover occurs\n            cx_point = np.random.randint(1,ind_size) # crossover point between 0 and ind_size-2\n            child1[0:cx_point], child2[0:cx_point] = parent2[0:cx_point], parent1[0:cx_point]\n        cx_pop[:,2*j] = child1\n        cx_pop[:,2*j+1] = child2\n\n    # gaussian mutation (rewritten to remove nested loop for speed)\n    mut_pop = np.zeros((ind_size,pop_size)) # initialize mutation population\n    for j in range(pop_size):\n        individual = cx_pop[:,j].copy() # copy is necessary to avoid conflicts in memory\n        if np.random.uniform()<mut_prob:\n            individual = individual + np.random.normal(0,sigma,ind_size)*(np.random.uniform(size=ind_size)<ind_prob)\n            individual = np.maximum(individual,lower) # clip to lower bound\n            individual = np.minimum(individual,upper) # clip to upper bound\n        mut_pop[:,j] = individual.copy() # copy is necessary to avoid conflicts in memory\n\n    # fitness evaluation with local search\n    pop = mut_pop.copy()\n    for j in range(pop_size):\n        fitness[j] = rastrigin(pop[:,j])\n\n    # collect stats and output to screen\n    min_fitness = min(fitness) # best for this iteration\n    if min_fitness < best_fitness: # best for all iterations\n        best_fitness = min_fitness\n        index = np.argmin(fitness)\n        best_x = pop[:,index]\n\n    stats[iter+1,:] = np.array([iter+1,min_fitness, best_fitness])\n    if (iter+1) % update_iter == 0:\n        print(f\"{stats[iter+1,0]:9.0f} | {stats[iter+1,1]:14.3e} | {stats[iter+1,2]:12.3e}\")\n        \nprint(f\"The minimum value found of the Rastrigin function is {best_fitness:.4f}\")\nprint(\"The location of that minimum is:\")\nprint('(',', '.join(f\"{x:.4f}\" for x in best_x),')')","output":{"0":{"name":"stdout","output_type":"stream","text":"Iteration | Best this iter |    Best ever\n"},"1":{"name":"stdout","output_type":"stream","text":"      100 |      1.748e+00 |    1.748e+00\n"},"10":{"name":"stdout","output_type":"stream","text":"     1000 |      5.916e-02 |    5.673e-02\n"},"11":{"name":"stdout","output_type":"stream","text":"     1100 |      5.916e-02 |    5.673e-02\n"},"12":{"name":"stdout","output_type":"stream","text":"     1200 |      4.901e-02 |    4.901e-02\n"},"13":{"name":"stdout","output_type":"stream","text":"     1300 |      4.841e-02 |    4.841e-02\n"},"14":{"name":"stdout","output_type":"stream","text":"     1400 |      3.600e-02 |    3.600e-02\n"},"15":{"name":"stdout","output_type":"stream","text":"     1500 |      1.953e-02 |    1.953e-02\n"},"16":{"name":"stdout","output_type":"stream","text":"     1600 |      1.953e-02 |    1.953e-02\n"},"17":{"name":"stdout","output_type":"stream","text":"     1700 |      1.953e-02 |    1.353e-02\n"},"18":{"name":"stdout","output_type":"stream","text":"     1800 |      1.435e-02 |    1.353e-02\n"},"19":{"name":"stdout","output_type":"stream","text":"     1900 |      8.399e-03 |    8.399e-03\n"},"2":{"name":"stdout","output_type":"stream","text":"      200 |      1.468e+00 |    1.183e+00\n"},"20":{"name":"stdout","output_type":"stream","text":"     2000 |      5.694e-03 |    5.694e-03\nThe minimum value found of the Rastrigin function is 0.0057\nThe location of that minimum is:\n( 0.0006, 0.0006, 0.0023, -0.0024, -0.0025, -0.0018, 0.0011, 0.0024, 0.0006, -0.0004 )\n"},"3":{"name":"stdout","output_type":"stream","text":"      300 |      5.602e-01 |    5.602e-01\n"},"4":{"name":"stdout","output_type":"stream","text":"      400 |      4.824e-01 |    4.824e-01\n"},"5":{"name":"stdout","output_type":"stream","text":"      500 |      1.369e-01 |    1.369e-01\n"},"6":{"name":"stdout","output_type":"stream","text":"      600 |      7.566e-02 |    7.566e-02\n"},"7":{"name":"stdout","output_type":"stream","text":"      700 |      7.566e-02 |    7.566e-02\n"},"8":{"name":"stdout","output_type":"stream","text":"      800 |      7.002e-02 |    7.002e-02\n"},"9":{"name":"stdout","output_type":"stream","text":"      900 |      6.840e-02 |    5.673e-02\n"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"6ca5bd","input":"with open(\"data/Caps48.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\noptimal_tour = tsp[\"OptTour\"]\nopt_dist = tsp[\"OptDistance\"]/1000 # converted to kilometers\nxy = np.array(tsp[\"Coordinates\"])\n\ndef plot_tour(best_tour, xy_meters, best_dist, height, width):\n\n    meters_to_pxl = 0.0004374627441064968\n    intercept_x = 2.464\n    intercept_y = 1342.546\n    xy_pixels = np.zeros(xy_meters.shape)\n    xy_pixels[:,0] = meters_to_pxl * xy_meters[:,0] + intercept_x\n    xy_pixels[:,1] = -meters_to_pxl * xy_meters[:,1] + intercept_y\n\n    fig, ax = plt.subplots(1, 1, figsize=(height, width))\n    im = plt.imread('images/caps48.png')\n    implot = ax.imshow(im)\n    plt.setp(ax.get_xticklabels(), visible=False)\n    plt.setp(ax.get_yticklabels(), visible=False)\n    ax.tick_params(axis='both', which='both', length=0)\n\n    loop_tour = np.append(best_tour, best_tour[0])\n    ax.plot(xy_pixels[loop_tour, 0],\n            xy_pixels[loop_tour, 1],\n            c='b',\n            linewidth=1,\n            linestyle='-')\n    plt.title('Best Distance {:d} km'.format(int(best_dist)))\n\n# this is an example of how to plot a tour\nplot_tour(optimal_tour, xy, opt_dist, 9, 6)","output":{"0":{"data":{"image/png":"5843f2a69a2e53ef755ea84ad7ccecdea1d3cb0c","text/plain":"<Figure size 648x432 with 1 Axes>"},"exec_count":3,"metadata":{"image/png":{"height":352,"width":516}},"output_type":"execute_result"}},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"a0aacc","input":"# rastrigin definition\ndef rastrigin(x):\n    x = np.array(x) # force a numpy arrray here so that the math below works\n    # pass a single vector of length n (=dim) to evaluate Rastrigin\n    return sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x))","metadata":{"hidden":true},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"6da2d7","input":"# generate random weights and values for a knapsack problem\n# DO NOT CHANGE ANYTHING in this block of code\nimport numpy as np\nnum_items = 20\nnp.random.seed(seed=123) \nvalues = np.random.randint(low=5, high=50, size=num_items)\nweights = np.random.randint(low=1, high=10, size=num_items)\nmax_weight = 50\nnp.random.seed() # use system clock to reset the seed so future random numbers will appear random","metadata":{"hidden":true},"pos":8,"type":"cell"}
{"cell_type":"markdown","id":"015ca5","input":"**HW5.1b** -\n\nUse the Genetic Algorithm described in the text to find a tour with total distance less than 19,000 km.\n\n* Initialize the population with permuations\n* Implement the Ordered Crossover operator described in the lesson.\n* Implement the Shuffling Indices (random city swaps) described in the lesson.\n* Experiment with the algorithm parameters to find a good tour.  Add a line at the top to make the results reproducible: `np.random.seed(123)`.  You can change the seed to get different results, but the same seed with the same parameters should produce the same tour.\n* Feel free to discuss parameter choices with other students on Piazza.\n* Include a plot of your tour.\n* To get you started we've copied the GA code from the lesson and added ###### before and after places you'll need to make changes.\n\n<font color = \"blue\"> *** 10 points -  answer in cell below *** (don't delete this cell) </font>","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"056ffa","input":"**HW5.1a** -\n\nThere isn't much to this part.  Adapt the code in the lesson to use the `simanneal` package to find a tour with total distance less than 19,000 km.  Plot your tour.  You may have to experiment with the temperature schedule to achieve a good result.  Without hacking the `simanneal` code it's impossible to set a random number seed to make reproducible results so just give this a good try.  You can tell us about your best solution even if it isn't the latest solution you found.  A plot isn't required, but it is useful for inspecting the tour to see if it is at least sensible.\n\n<font color = \"blue\"> *** 4 points -  answer in cell below *** (don't delete this cell) </font>","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"180c2d","input":"<font color = \"green\">\nreplace this text with answer, your answer should be green   \n</font>","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"1e8541","input":"Use the `simanneal` package to apply simulated annealing to finding a good solution to this knapsack problem.  Remember that the knapsack problem is a maximization problem so you'll have to work with the appropriate negate\n\nFor this problem we have the constraint that total weight $\\leq 50$ and we'll take two different approaches to ensuring our solutions satisfy the constraint.  (The two constraint approaches are also discussed in the supplemental notebooks in the extras folder.  Note that we are no longer using the DEAP package for the genetic algorithm that is mentioned in the supplements.)\n\n**NOTE:**  The optimal backpack has total value 435 and total weight 50.  All of the algorithms below should be able to easily find this solution.\n\n**HW5.2a** - The first approach is called a **hard constraint** wherein we reject all possible solutions that don't satisfy the constraint.  You'll implement this in the move() method.  \n* copy `self.state` with `new_state = self.state.copy()`\n* make a move on `new_state` (toggle a random item like in HW 4)\n* if the total weight of `new_state` is $\\leq 50$ then `set self.state = new_state`\n* else don't change `self.state`.\n\nFind a \"good\" solution to the knapsack problem by using `simanneal` with a hard constraint.\n\n<font color = \"blue\"> *** 5 points -  answer in cell below *** (don't delete this cell) </font>","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"22c565","input":"<font color = \"green\">\nreplace this text with answer, your answer should be green   \n</font>","metadata":{"hidden":true},"pos":16,"type":"cell"}
{"cell_type":"markdown","id":"2d8db8","input":"**HW5.2c** - Use the soft constraint approach to solve the knapsack problem with the genetic algorithm (use the negated, penalized objective function).  Use OnePoint Crossover for mating.  Mutation should be toggling (flipping) each variable with probability `ind_prob`. Use tournament selection.  Include your solution in the cell below.\n\n<font color = \"blue\"> *** 6 points -  answer in cell below *** (don't delete this cell) </font>","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"3c51ce","input":"**HW5.3d** - \n\nBriefly summarize the results of the the three algorithms above.  Which seems to work best in terms of accuracy and in terms of efficiency?\n\n<font color = \"blue\"> *** 2 points -  answer in cell below *** (don't delete this cell) </font>","pos":25,"type":"cell"}
{"cell_type":"markdown","id":"58047c","input":"# **HW5.3** - The 10-dimensional Rastrigin Function with Local Search\n\nThe Rastrigin function was first explored in Lesson 4 and was also used in the Genetic Algorithm example in Lesson 5.  Here is the definition of the function:","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"5be2c0","input":"**HW5.2b** - The second approach is called a **soft constraint** because its possible to find a solution that doesn't satisfy the constraint.  Soft constraints are implemented by including a penalty in the objective function when the proposed solution doesn't satisfy the constraint.  To do this you'll modify the function called by the energy() method:\n```\ndef knapsack_value_penalty(x, values, weights, max_tot_weight):\n    # x is a vector of booleans of which items to include\n    tot_value = sum(values[x])\n    penalty = sum(values)*min( max_tot_weight - sum(weights[x]), 0) \n    return tot_value+penalty\n```\nThe penalty here is negative when the total weight is too large so that the optimizer knows it hasn't found a good maximizing solution.\n\nFind a \"good\" solution to the knapsack problem by using simanneal with a soft constraint.\n\n<font color = \"blue\"> *** 5 points -  answer in cell below *** (don't delete this cell) </font>","metadata":{"hidden":true},"pos":11,"type":"cell"}
{"cell_type":"markdown","id":"5d3d5d","input":"**HW5.2d** - Which of the three algorithms above seems to work the best.  Do you think you've found the knapsack with highest possible value (the global max)?  Why or why not?\n\n<font color = \"blue\"> *** 2 points -  answer in cell below *** (don't delete this cell) </font>","metadata":{"hidden":true},"pos":15,"type":"cell"}
{"cell_type":"markdown","id":"5d834d","input":"**HW5.3c** - Now include local search with the genetic algorithm approach developed in Lesson 5.\n\nYou're going to make two changes here.\n\n* Replace one point crossover with blended crossover (described in the lesson) with $\\alpha = 0.2$.  You should make sure the resulting children satisfy the bounds.  \n* Add local search to the genetic algorithm.  At the top of the main loop, before tournament selection.\n\nWe've copied the code from the lesson and added comments on where to make the modifications.  To get your code working you should reduce the pop_size and iterations.  Experiment to get a good result.\n\n\n<font color = \"blue\"> *** 6 points -  answer in cell below *** (don't delete this cell) </font>","metadata":{"hidden":true},"pos":23,"type":"cell"}
{"cell_type":"markdown","id":"6e2d3d","input":"**HW5.3b** - Now include local search in your `simanneal` solution.  To do this you'll need to modify the move() method. After you've add the random change and clipped to bounds, then start a local search from the current self.state using scipy.optimize.minimize (include the bounds) and set self.state to the resulting location found by the local search.  You can tell the minimize function to optimize self.energy starting from self.state.  To speed this up you can make the local searches with low precision by adding `tol=0.1` to the minimize() function call.  At the very end you can do one final local search without the added `tol=0.1` to improve your final answer.\n\n<font color = \"blue\"> *** 5 points -  answer in cell below *** (don't delete this cell) </font>","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"6fef3d","input":"# **HW5.2** - The Knapsack Problem","pos":6,"type":"cell"}
{"cell_type":"markdown","id":"75f2a6","input":"This function can be applied to an `x` that is any iterable of any length.  We'll be working with numpy arrays.  For the 10 dimensional problems your numpy array should be a vector with 10 floating point numbers.  We'll enforce bounds that $-5.12 \\leq x_i \\leq 5.12$ so all of the entries in $x$ should be between those bounds.  Your goal is find the global minimizer at (0,0,0,...) where the function value is also zero.\n\n**HW5.3a** - Use the `simanneal` package.  The self-assessment solutions should be helpful here. This solution does not involve local search.\n\n<font color = \"blue\"> *** 5 points -  answer in cell below *** (don't delete this cell) </font>","metadata":{"hidden":true},"pos":19,"type":"cell"}
{"cell_type":"markdown","id":"cba68a","input":"***Note:  this is a new version of HW5 that we wrote in Summer 2020 (added a few hints and fixes on 10/7/20).  Please fire away with questions on Piazza as we know the first draft of anything often needs clarification!***\n\n# **HW5.1** - The Traveling Salesman Problem\n\nIn Lesson 4 we saw how to use local search to seek solutions to the TSP problem with 48 cities.  In this homework problem you'll use the `simanneal` package and the genetic algorithm to search for solutions.  The json file Caps48.json in the data folder has both the distance matrix and the optimal tour.  Your goal is to identify tours with total distance under 19,000 kilometers with each algorithm.\n\nThe following cell shows you how to visualize a tour of the 48 cities (and reminds you how to use the json file).  You should plot your solutions to see if they seem reasonable.  A good solution will avoid long detours and shouldn't intersect itself.  We plot the best possible solution here:","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"f8b184","input":"We first encountered this problem in the Lesson 4 Homework.\n\nThe knapsack problem is a classical combinatorial optimization problem that will be good for practicing with the ideas of discrete local search and multistart.  Given a set of items, each with a weight and a value, determine which items to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible.  In the 0-1 version of the knapsack problem, the decision variables are binary (or boolean) and represent whether or not to include each item in the collection.  We'll start with 20 items and you need to determine the collection of items that maximizes the value and keeps the total weight no more than 50 (that is $\\leq 50$).","metadata":{"hidden":true},"pos":7,"type":"cell"}
{"id":0,"time":1615563033454,"type":"user"}
{"last_load":1615566575826,"type":"file"}