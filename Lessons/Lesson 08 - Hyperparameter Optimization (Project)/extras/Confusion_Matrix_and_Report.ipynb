{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Predicting Opioid Abuse from Perception of Risk\n",
    "\n",
    "The data for this project uses 2016 National Survey on Drug Use and Health to attempt to predict opioid abuse risk based on responses from a small number of survey questions regarding the perceived risk of alcohol, tobacco, and substance use. The intent was to create a screening tool for participants in Division of Extension education programs that could flag individuals that might be more at risk, so additional targeted interventions could be provided. \n",
    "\n",
    "Extensive data cleaning was performed in R, resulting in a dataset with 40241 adults with no history of opioid abuse and 2381 adults with a history of opioid abuse. \n",
    "\n",
    "Let's read in the data and one-hot-encode the category variables for sklearn.\n",
    "\n",
    "We'll also make a much smaller data set for demonstration purposes. Otherwise, this code runs extremely slowly. If you wanted more accurate results, the entire dataset should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Size 4000\n",
      "Final Testing Size 1000\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#read in the data\n",
    "X = pd.read_csv('../data/opioid_data.csv')\n",
    "#grab the y column (1 = opioid user, 0 = not a user)\n",
    "y = np.array(X['isUser'])\n",
    "#drop the y column \n",
    "X = X.drop(columns = ['isUser'])\n",
    "\n",
    "#one hot encode the categories\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "X = onehot_encoder.fit_transform(X)\n",
    "\n",
    "# split into test and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#for testing, split twice to get a much smaller dataset - just 5000\n",
    "#comment out this line to run with the entire data set\n",
    "x_train_toss, X, y_train_toss, y = train_test_split(X, y, test_size = 5000, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Just to confirm how many records we're dealing with....\n",
    "print('Final Training Size', len(X_train))\n",
    "print('Final Testing Size', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For every 1 opioid user in our dataset, we have approximately 17 non opioid users. Given that our sample is so imbalanced, we'll need to use some mechanism to try to even the scales. Luckily, sklearn has ways of handling that. For instance, in LogisticRegression, we can pass the class_weight parameter to obtain a \"balanced\" problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## An example classifier\n",
    "Let's do a simple logistic regression. We'll compare our accuracy score for a model that does not account for our imbalanced data with one that does account for it.\n",
    "\n",
    "Note that all we need to do to make it balanced is to use the class_weight parameter with the value of balanced. We found the needed parameter by consulting the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">documentation for sklearn LogisticRegression</a>.\n",
    "\n",
    "The documentation states that \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data. In other words, it more strongly weights the minority class, so that the classifier does a better job of finding those needles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Accuracy) - Imbalanced: 0.946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Accuracy) - Balanced: 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# we do need to go higher than the default iterations for the solver to get convergence\n",
    "# and the explicity declaration of the solver avoids a warning message, otherwise\n",
    "# the parameters are defaults.\n",
    "\n",
    "#without balancing\n",
    "logreg_model_imbalanced = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "#fit\n",
    "logreg_model_imbalanced.fit(X_train, y_train)\n",
    "# Use score method to get accuracy of model\n",
    "score_imbalanced = logreg_model_imbalanced.score(X_test, y_test) # this is accuracy\n",
    "print('Score (Accuracy) - Imbalanced:', score_imbalanced)\n",
    "\n",
    "#with balancing\n",
    "logreg_model = LogisticRegression(solver='lbfgs',max_iter=1000, class_weight='balanced')\n",
    "#fit\n",
    "logreg_model.fit(X_train, y_train)\n",
    "# Use score method to get accuracy of  the balanced model\n",
    "score = logreg_model.score(X_test, y_test) # this is accuracy\n",
    "\n",
    "print('Score (Accuracy) - Balanced:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Our imbalanced score sure looks good, doesn't it? Hm... Let's look at another metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Accuracy vs. Area Under the Curve\n",
    "Accuracy is how many of the predicted values matched the actual values. Area Under the Curve is a different measure for scoring classifiers. An AUC of .5 would indicate random guessing, or the inability of your classifier to separate the two groups, whereas an AUC of 1 would indicate a perfect classifier. \n",
    "\n",
    "We'll also track AUC for our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Curve (imbalanced): 0.5\n",
      "Area Under the Curve (balanced): 0.6760825307336935\n"
     ]
    }
   ],
   "source": [
    "#get auc\n",
    "y_pred = logreg_model_imbalanced.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('Area Under the Curve (imbalanced):', auc)\n",
    "\n",
    "#get auc\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('Area Under the Curve (balanced):', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Even though our accuracy was really high for the model that didn't take the imbalanced nature of the data into account, when we look at area under the curve, we can see that the model actually did no better than random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Confusion Matrix and Statistics\n",
    "A confusion matrix is a quick way to look at how well your classifier did, and from it we can derive some more statistics. Specifically, we'll be looking at sensitivity (true positive rate), specificity (true negative rate), and precision (positive predictive value).\n",
    "\n",
    "Sklearn provides a quick and easy way to get the statistics via the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user              0             54\n",
       "true:not user          0            946"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced Statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.946,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9722507708119219,\n",
       "  'support': 946},\n",
       " '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54},\n",
       " 'accuracy': 0.946,\n",
       " 'macro avg': {'precision': 0.473,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.48612538540596095,\n",
       "  'support': 1000},\n",
       " 'weighted avg': {'precision': 0.8949159999999999,\n",
       "  'recall': 0.946,\n",
       "  'f1-score': 0.9197492291880782,\n",
       "  'support': 1000}}"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>280</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             35             19\n",
       "true:not user        280            666"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9722627737226277,\n",
       "  'recall': 0.7040169133192389,\n",
       "  'f1-score': 0.8166768853464133,\n",
       "  'support': 946},\n",
       " '1': {'precision': 0.1111111111111111,\n",
       "  'recall': 0.6481481481481481,\n",
       "  'f1-score': 0.18970189701897017,\n",
       "  'support': 54},\n",
       " 'accuracy': 0.701,\n",
       " 'macro avg': {'precision': 0.5416869424168694,\n",
       "  'recall': 0.6760825307336935,\n",
       "  'f1-score': 0.5031893911826917,\n",
       "  'support': 1000},\n",
       " 'weighted avg': {'precision': 0.9257605839416058,\n",
       "  'recall': 0.701,\n",
       "  'f1-score': 0.7828202359767313,\n",
       "  'support': 1000}}"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtaining the confusion matrix and making it look nice\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "#get predictions from the imbalanced model\n",
    "y_pred = logreg_model_imbalanced.predict(X_test)\n",
    "\n",
    "# must put true before predictions in confusion matrix function\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=[1,0]), \n",
    "    index=['true:user', 'true:not user'], \n",
    "    columns=['pred:user','pred:not user']\n",
    ")\n",
    "print('Imbalanced Confusion Matrix:')\n",
    "display(cmtx)\n",
    "\n",
    "#we can also get the classification report directly from sklearn.\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "print('Imbalanced Statistics:')\n",
    "display(cr)\n",
    "\n",
    "\n",
    "#get predictions from the balanced model\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# must put true before predictions in confusion matrix function\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=[1,0]), \n",
    "    index=['true:user', 'true:not user'], \n",
    "    columns=['pred:user','pred:not user']\n",
    ")\n",
    "print('Balanced Confusion Matrix:')\n",
    "display(cmtx)\n",
    "\n",
    "#we can also get the classification report directly from sklearn.\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "print('Balanced Statistics:')\n",
    "display(cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When we look at our confusion matrix and statistics, we can see why our area under the curve was so bad for the imbalanced model. It just predicted everyone was not an opioid user. This is the behavior we expected. But, you can see that the model that used class weights to balance the data did a much better job. It overpredicted the number of users, but it did also correctly predict most of the users in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}