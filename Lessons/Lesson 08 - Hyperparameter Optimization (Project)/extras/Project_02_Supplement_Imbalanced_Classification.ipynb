{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Project 2 Supplement\n",
    "## Optimizing Classification Parameters with Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Whenever you're doing machine learning with a classification model, you need to be aware of imbalanced data. Imbalanced data is data where the majority of the response (y) values in your data fall into one class. In the data you were given for the project, we'd artificially balanced the data - giving you roughly equal good and bad loans. In real life, there would be far more good loans than bad loans, far more real credit card transactions than fraudulent ones, far more negative cancer tests than positive ones, etc. Classification problems are often looking for that proverbial \"needle in the haystack.\" \n",
    "\n",
    "The problem is that if we're using accuracy as our metric with imbalanced data, the classifier can always guess the majority class, and we'll have pretty decent accuracy. For example, the data that we're using in this example is survey data from the 2016 National Survey on Drug Use and Health. The purpose of the classifier is to predict opioid users, which account for just 6% of the survey respondents. If the classifier predicted \"not an opioid user\" for every respondent, it would be correct 94% of the time. That's a pretty good accuracy score! Of course, it doesn't tell us anything about what we actually want to know.\n",
    "\n",
    "Let's see what can be done about this imbalanced data with parameter optimization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Predicting Opioid Abuse from Perception of Risk\n",
    "\n",
    "The data for this project uses 2016 National Survey on Drug Use and Health to attempt to predict opioid abuse risk based on responses from a small number of survey questions regarding the perceived risk of alcohol, tobacco, and substance use. The intent was to create a screening tool for participants in Division of Extension education programs that could flag individuals that might be more at risk, so additional targeted interventions could be provided. \n",
    "\n",
    "Extensive data cleaning was performed in R, resulting in a dataset with 40241 adults with no history of opioid abuse and 2381 adults with a history of opioid abuse. \n",
    "\n",
    "Let's read in the data and one-hot-encode the category variables for sklearn.\n",
    "\n",
    "We'll also make a much smaller data set for demonstration purposes. Otherwise, this code runs extremely slowly. If you wanted more accurate results, the entire dataset should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Size 4000\n",
      "Final Testing Size 1000\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#read in the data\n",
    "X = pd.read_csv('./data/opioid_data.csv')\n",
    "#grab the y column (1 = opioid user, 0 = not a user)\n",
    "y = np.array(X['isUser'])\n",
    "#drop the y column \n",
    "X = X.drop(columns = ['isUser'])\n",
    "\n",
    "#one hot encode the categories\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "X = onehot_encoder.fit_transform(X)\n",
    "\n",
    "# split into test and training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "#for testing, split twice to get a much smaller dataset - just 5000\n",
    "#comment out this line to run with the entire data set\n",
    "x_train_toss, X, y_train_toss, y = train_test_split(X, y, test_size = 5000, random_state = 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Just to confirm how many records we're dealing with....\n",
    "print('Final Training Size', len(X_train))\n",
    "print('Final Testing Size', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For every 1 opioid user in our dataset, we have approximately 17 non opioid users. Given that our sample is so imbalanced, we'll need to use some mechanism to try to even the scales. Luckily, sklearn has ways of handling that. For instance, in LogisticRegression, we can pass the class_weight parameter to obtain a \"balanced\" problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## An example classifier\n",
    "Let's do a simple logistic regression. We'll compare our accuracy score for a model that does not account for our imbalanced data with one that does account for it.\n",
    "\n",
    "Note that all we need to do to make it balanced is to use the class_weight parameter with the value of balanced. We found the needed parameter by consulting the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">documentation for sklearn LogisticRegression</a>.\n",
    "\n",
    "The documentation states that \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data. In other words, it more strongly weights the minority class, so that the classifier does a better job of finding those needles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (Accuracy) - Imbalanced: 0.946\n",
      "Score (Accuracy) - Balanced: 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# we do need to go higher than the default iterations for the solver to get convergence\n",
    "# and the explicity declaration of the solver avoids a warning message, otherwise\n",
    "# the parameters are defaults.\n",
    "\n",
    "#without balancing\n",
    "logreg_model_imbalanced = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "#fit\n",
    "logreg_model_imbalanced.fit(X_train, y_train)\n",
    "# Use score method to get accuracy of model\n",
    "score_imbalanced = logreg_model_imbalanced.score(X_test, y_test) # this is accuracy\n",
    "print('Score (Accuracy) - Imbalanced:', score_imbalanced)\n",
    "\n",
    "#with balancing\n",
    "logreg_model = LogisticRegression(solver='lbfgs',max_iter=1000, class_weight='balanced')\n",
    "#fit\n",
    "logreg_model.fit(X_train, y_train)\n",
    "# Use score method to get accuracy of  the balanced model\n",
    "score = logreg_model.score(X_test, y_test) # this is accuracy\n",
    "\n",
    "print('Score (Accuracy) - Balanced:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Our imbalanced score sure looks good, doesn't it? Hm... Let's look at another metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Accuracy vs. Area Under the Curve\n",
    "Accuracy is how many of the predicted values matched the actual values. Area Under the Curve is a different measure for scoring classifiers. An AUC of .5 would indicate random guessing, or the inability of your classifier to separate the two groups, whereas an AUC of 1 would indicate a perfect classifier. \n",
    "\n",
    "We'll also track AUC for our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Curve (imbalanced): 0.5\n",
      "Area Under the Curve (balanced): 0.6760825307336935\n"
     ]
    }
   ],
   "source": [
    "#get auc\n",
    "y_pred = logreg_model_imbalanced.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('Area Under the Curve (imbalanced):', auc)\n",
    "\n",
    "#get auc\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print('Area Under the Curve (balanced):', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Even though our accuracy was really high for the model that didn't take the imbalanced nature of the data into account, when we look at area under the curve, we can see that the model actually did no better than random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Confusion Matrix and Statistics\n",
    "A confusion matrix is a quick way to look at how well your classifier did, and from it we can derive some more statistics. Specifically, we'll be looking at sensitivity (true positive rate), specificity (true negative rate), and precision (positive predictive value).\n",
    "\n",
    "Sklearn provides a quick and easy way to get the statistics via the classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user              0             54\n",
       "true:not user          0            946"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced Statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.946,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9722507708119219,\n",
       "  'support': 946},\n",
       " '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54},\n",
       " 'accuracy': 0.946,\n",
       " 'macro avg': {'precision': 0.473,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.48612538540596095,\n",
       "  'support': 1000},\n",
       " 'weighted avg': {'precision': 0.8949159999999999,\n",
       "  'recall': 0.946,\n",
       "  'f1-score': 0.9197492291880782,\n",
       "  'support': 1000}}"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>280</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             35             19\n",
       "true:not user        280            666"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9722627737226277,\n",
       "  'recall': 0.7040169133192389,\n",
       "  'f1-score': 0.8166768853464133,\n",
       "  'support': 946},\n",
       " '1': {'precision': 0.1111111111111111,\n",
       "  'recall': 0.6481481481481481,\n",
       "  'f1-score': 0.18970189701897017,\n",
       "  'support': 54},\n",
       " 'accuracy': 0.701,\n",
       " 'macro avg': {'precision': 0.5416869424168694,\n",
       "  'recall': 0.6760825307336935,\n",
       "  'f1-score': 0.5031893911826917,\n",
       "  'support': 1000},\n",
       " 'weighted avg': {'precision': 0.9257605839416058,\n",
       "  'recall': 0.701,\n",
       "  'f1-score': 0.7828202359767313,\n",
       "  'support': 1000}}"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtaining the confusion matrix and making it look nice\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "#get predictions from the imbalanced model\n",
    "y_pred = logreg_model_imbalanced.predict(X_test)\n",
    "\n",
    "# must put true before predictions in confusion matrix function\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=[1,0]), \n",
    "    index=['true:user', 'true:not user'], \n",
    "    columns=['pred:user','pred:not user']\n",
    ")\n",
    "print('Imbalanced Confusion Matrix:')\n",
    "display(cmtx)\n",
    "\n",
    "#we can also get the classification report directly from sklearn.\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "print('Imbalanced Statistics:')\n",
    "display(cr)\n",
    "\n",
    "\n",
    "#get predictions from the balanced model\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# must put true before predictions in confusion matrix function\n",
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=[1,0]), \n",
    "    index=['true:user', 'true:not user'], \n",
    "    columns=['pred:user','pred:not user']\n",
    ")\n",
    "print('Balanced Confusion Matrix:')\n",
    "display(cmtx)\n",
    "\n",
    "#we can also get the classification report directly from sklearn.\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "print('Balanced Statistics:')\n",
    "display(cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When we look at our confusion matrix and statistics, we can see why our area under the curve was so bad for the imbalanced model. It just predicted everyone was not an opioid user. This is the behavior we expected. But, you can see that the model that used class weights to balance the data did a much better job. It overpredicted the number of users, but it did also correctly predict most of the users in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tracking our Results\n",
    "\n",
    "We're going to run 10 different models and track our statistics for each model. We'll set up a dataframe and a function to update the dataframe after each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Fits</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LogReg - Baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RFC - Baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GNB - Baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ridge - Baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Grid Search</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Random Search</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Bayesian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - TPOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TPOT-General</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Fits Accuracy   AUC Sensitivity Precision  \\\n",
       "LogReg - Baseline         None     None  None        None      None   \n",
       "RFC - Baseline            None     None  None        None      None   \n",
       "GNB - Baseline            None     None  None        None      None   \n",
       "Ridge - Baseline          None     None  None        None      None   \n",
       "XGB - Baseline            None     None  None        None      None   \n",
       "XGB - Grid Search         None     None  None        None      None   \n",
       "XGB - Random Search       None     None  None        None      None   \n",
       "XGB - Bayesian            None     None  None        None      None   \n",
       "XGB - TPOT                None     None  None        None      None   \n",
       "TPOT-General              None     None  None        None      None   \n",
       "\n",
       "                    Specificity  \n",
       "LogReg - Baseline          None  \n",
       "RFC - Baseline             None  \n",
       "GNB - Baseline             None  \n",
       "Ridge - Baseline           None  \n",
       "XGB - Baseline             None  \n",
       "XGB - Grid Search          None  \n",
       "XGB - Random Search        None  \n",
       "XGB - Bayesian             None  \n",
       "XGB - TPOT                 None  \n",
       "TPOT-General               None  "
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up a dataframe for storing results for the classification models\n",
    "import pandas as pd\n",
    "\n",
    "blanks = [None for i in range(0, 10)]\n",
    "c_df = pd.DataFrame({'Model Fits': blanks, \n",
    "                     'Accuracy': blanks, \n",
    "                     'AUC': blanks,\n",
    "                      'Sensitivity': blanks, \n",
    "                      'Precision': blanks,\n",
    "                       'Specificity': blanks}, \n",
    "                     index=[\n",
    "                            'LogReg - Baseline',\n",
    "                            'RFC - Baseline',\n",
    "                            'GNB - Baseline',\n",
    "                            'Ridge - Baseline',\n",
    "                            'XGB - Baseline',\n",
    "                            'XGB - Grid Search', 'XGB - Random Search', 'XGB - Bayesian','XGB - TPOT',\n",
    "                            'TPOT-General'])\n",
    "\n",
    "\n",
    "#create a function for updating the grid\n",
    "def updateResults(df, approach, fits, score, auc, sens, prec, spec):\n",
    "    df.loc[approach, 'Model Fits'] = fits\n",
    "    df.loc[approach, 'Accuracy'] = score\n",
    "    df.loc[approach, 'AUC'] = auc\n",
    "    df.loc[approach, 'Sensitivity'] = sens\n",
    "    df.loc[approach, 'Precision'] = prec\n",
    "    df.loc[approach, 'Specificity'] = spec\n",
    "    return(df)\n",
    "\n",
    "c_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Since we'll be running the same code for each model, let's wrap it in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#wrapping it all up in a function\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def my_classifier_results(model): \n",
    "    #get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    #get the classification report\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = cr['accuracy'] #total number of correct predictions (positive or negative)\n",
    "    sensitivity = cr['1']['recall'] #true positive rate - accurately predicting a user when they are - 1 is best\n",
    "    precision = cr['1']['precision'] #positive predictive value - 1 is best\n",
    "    specificity = cr['0']['recall'] #true negative rate - accurately predicting not a user when they aren't\n",
    "    #get the area under curve\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print('Model accuracy score from test data: {:0.4f}'.format(accuracy))\n",
    "    print('Model AUC from test data: {:0.4f}'.format(auc))\n",
    "    print('Sensitivity (true positive rate) on test data: {:0.2f}'.format(sensitivity))\n",
    "    print('Precision (positive predictive value) on test data: {:0.2f}'.format(precision))\n",
    "    print('Specificity (true negative rate) on test data: {:0.2f}'.format(specificity))\n",
    "    cmtx = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred, labels=[1,0]), \n",
    "    index=['true:user', 'true:not user'], \n",
    "    columns=['pred:user','pred:not user']\n",
    "    )\n",
    "    display(cmtx)\n",
    "    \n",
    "    return(accuracy, auc, sensitivity, precision, specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Logistic Regession Baseline\n",
    "This is the same bit of code we already saw as an example above, but now we're using our function to do the work for us, and updating our tracking dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.7010\n",
      "Model AUC from test data: 0.6761\n",
      "Sensitivity (true positive rate) on test data: 0.65\n",
      "Precision (positive predictive value) on test data: 0.11\n",
      "Specificity (true negative rate) on test data: 0.70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>280</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             35             19\n",
       "true:not user        280            666"
      ]
     },
     "execution_count": 10,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the logistic regressgion baseline\n",
    "logreg_model = LogisticRegression(solver='lbfgs',max_iter=1000, class_weight='balanced')    \n",
    "\n",
    "#fit the model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(logreg_model)\n",
    "c_df = updateResults(c_df, 'LogReg - Baseline', 1, score, auc, sens, prec, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Random Forest Classifier Baseline\n",
    "For random forest, we're again using the class_weight parameter, but since random forests work a bit differently than logistic regression, we're using a different parameter - balanced_subsample. This means that each of the trees within the forest will have their weights balanced within that tree.\n",
    "\n",
    "You can read more about it in the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.9430\n",
      "Model AUC from test data: 0.4984\n",
      "Sensitivity (true positive rate) on test data: 0.00\n",
      "Precision (positive predictive value) on test data: 0.00\n",
      "Specificity (true negative rate) on test data: 1.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>3</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user              0             54\n",
       "true:not user          3            943"
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the randomforestclassifer uses a balanced_subsample\n",
    "rfc_model = RandomForestClassifier(n_estimators=100, class_weight='balanced_subsample')    \n",
    "\n",
    "#fit the model\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "#calculate score\n",
    "\n",
    "score, auc, sens, prec, spec = my_classifier_results(rfc_model)\n",
    "c_df = updateResults(c_df, 'RFC - Baseline', 1, score, auc, sens, prec, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gaussian Naive Bayes Classifier - Baseline\n",
    "The <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\">Gaussian Naive Bayes classifier</a> doesn't have a simple balanced parameter for sample_weights. Instead, we have to create a vector with a weight for each of our rows of data. We know that for every 1 positive respondent, we have 17 negative respondents. So we need to weight the positives with a 17 and the negatives with a one. We'll use a list comprehension to generate our vector of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.0790\n",
      "Model AUC from test data: 0.5045\n",
      "Sensitivity (true positive rate) on test data: 0.98\n",
      "Precision (positive predictive value) on test data: 0.05\n",
      "Specificity (true negative rate) on test data: 0.03\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>920</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             53              1\n",
       "true:not user        920             26"
      ]
     },
     "execution_count": 12,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_model = GaussianNB()    \n",
    "\n",
    "#the GNB model requires an array of weights - use a list comprehension and cast to numpy array\n",
    "sample_weights = np.array([17 if i == 1 else 1 for i in y_train])\n",
    "\n",
    "#fit the model\n",
    "gnb_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(gnb_model)\n",
    "c_df = updateResults(c_df, 'GNB - Baseline', 1, score, auc, sens, prec, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Ridge Baseline\n",
    "The <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\">ridge classifier</a> uses ridge regression. Remember that ridge regression uses a tuning parameter (alpha) to shrink coefficients towards zero. We could alter the alpha parameter, but we'll leave it at the default of 1. It also supports using \"balanced\" with class_weight to handle imbalanced classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.6950\n",
      "Model AUC from test data: 0.6642\n",
      "Sensitivity (true positive rate) on test data: 0.63\n",
      "Precision (positive predictive value) on test data: 0.11\n",
      "Specificity (true negative rate) on test data: 0.70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>285</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             34             20\n",
       "true:not user        285            661"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier   \n",
    "\n",
    "ridge_model = RidgeClassifier(class_weight='balanced')\n",
    "\n",
    "\n",
    "#fit the model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(ridge_model)\n",
    "c_df = updateResults(c_df, 'Ridge - Baseline', 1, score, auc, sens, prec, spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XGBoost - Baseline\n",
    "Finally, <a href=\"https://xgboost.readthedocs.io/en/latest/python/python_api.html\">XGBoost</a> works like the Guassian Naive Bayes classifier - it requires a vector of weights. We've already created it, so here we'll just use it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.7350\n",
      "Model AUC from test data: 0.6591\n",
      "Sensitivity (true positive rate) on test data: 0.57\n",
      "Precision (positive predictive value) on test data: 0.11\n",
      "Specificity (true negative rate) on test data: 0.74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>242</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             31             23\n",
       "true:not user        242            704"
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "#fit the model - passing in the sample_weights\n",
    "xgb_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(xgb_model)\n",
    "c_df = updateResults(c_df, 'XGB - Baseline', 1, score, auc, sens, prec, spec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XGBoost with Grid Search\n",
    "\n",
    "We've finally gotten all of our baseline classifiers done. Let's optimize some parameters!\n",
    "\n",
    "We'll start by optimizing XGBoost with Grid Search.\n",
    "\n",
    "These searches tend to take quite a while. This is a large data set. I'm using <a href=\"https://scikit-learn.org/stable/glossary.html#term-n-jobs\">n_jobs</a> in my grid search. This allows the computer to spin up parallel processes. This will only work if your computer has multiple cores. But if it does, it can certainly make this run faster. If your computer does not have multiple cores available, just make n_jobs = 1.\n",
    "\n",
    "While you're running the code below, let's take a minute to discuss the parameters. We're using the default booster for XGBoost, which is the Tree Booster. Grid search will search every combination of parameters we give it, so the more parameters we include, the more models will be fit (and the longer it will take to run the code). You can review all the possible parameters and what they mean in the <a href=\"https://xgboost.readthedocs.io/en/latest/parameter.html?highlight=learning_rate#parameters-for-tree-booster\">documentation</a>. That's where you also find the possible range of each parameter.\n",
    "\n",
    "Your job is to pick enough numbers within each range to give you a good search space, without picking so many as to make the code impossibly long to run. I've found that 2 or 3 of each parameter is enough to find a decently fitting model. After you have run this and found your best model, if any of the parameters are at the minimum or maximum of what you searched, you might want to try a lower or higher number in the range and search again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=3)]: Done 960 out of 960 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.8590\n",
      "Model AUC from test data: 0.5239\n",
      "Sensitivity (true positive rate) on test data: 0.15\n",
      "Precision (positive predictive value) on test data: 0.08\n",
      "Specificity (true negative rate) on test data: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>95</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user              8             46\n",
       "true:not user         95            851"
      ]
     },
     "execution_count": 15,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run GridSearchCV with our model to find better hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#########################\n",
    "#grid search\n",
    "#########################\n",
    "params = {\n",
    "    \"learning_rate\": [0.01, 0.1], #pick floats from 0 to 1\n",
    "    \"max_depth\": [2, 4, 6], #pick integers in range [0,inf] (but you'd usually want at least 1)\n",
    "    \"n_estimators\": [10, 100], #number of trees. Default is 100\n",
    "    \"subsample\": [0.8, 1], #pick floats from 0 to 1\n",
    "    \"min_child_weight\": [1, 3], #pick numbers 0 to inf\n",
    "    \"reg_lambda\": [1, 3], #pick numbers from 0 to inf\n",
    "    \"reg_alpha:\": [1, 3] #pick numbers from 0 to inf\n",
    "}\n",
    "\n",
    "# setup the grid search\n",
    "grid_search = GridSearchCV(xgb_model,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=3,\n",
    "                           return_train_score=True)\n",
    "\n",
    "\n",
    "#fit the model\n",
    "grid_search.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(grid_search)\n",
    "c_df = updateResults(c_df, 'XGB - Grid Search', 960, score, auc, sens, prec, spec)\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XGBoost with Random Search\n",
    "Once again, I'm using n_jobs with random search. We're doing 5-fold cross validation. We have the same parameters here, but since we're randomly combining different parameters, we can use more options. For some of our parameters, instead of picking a few numbers in a list, we're telling the the algorithm to randomly choose from a list of integers or from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=2)]: Done 125 out of 125 | elapsed:   44.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score from test data: 0.8740\n",
      "Model AUC from test data: 0.5667\n",
      "Sensitivity (true positive rate) on test data: 0.22\n",
      "Precision (positive predictive value) on test data: 0.12\n",
      "Specificity (true negative rate) on test data: 0.91\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>84</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             12             42\n",
       "true:not user         84            862"
      ]
     },
     "execution_count": 16,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.5, 1.],\n",
    "    \"max_depth\": randint(1, 10),\n",
    "    \"n_estimators\": randint(10, 100),\n",
    "    \"subsample\": uniform(0.05, 0.95),  # so uniform on [.05,.05+.95] = [.05,1.]\n",
    "    \"min_child_weight\": randint(1, 20),\n",
    "    \"reg_alpha\": uniform(0, 5),\n",
    "    \"reg_lambda\": uniform(0, 5)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_model,\n",
    "    param_distributions=params,\n",
    "    random_state=8675309,\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=2,\n",
    "    return_train_score=True)\n",
    "\n",
    "#fit the model\n",
    "random_search.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(random_search)\n",
    "c_df = updateResults(c_df, 'XGB - Random Search', 125, score, auc, sens, prec, spec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XGBoost with Bayesian Optimization\n",
    "\n",
    "Bayesian optimization requires a different set up for our parameters. Note that the parameters themselves are the same. But, we have to make an hp_bounds object. Float numbers are of type \"continuous\" while integers are of type \"discrete.\" For each parameter, we give a domain - which is the high and low from which values will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 0.50s\n",
      "num acquisition: 2, time elapsed: 1.19s\n",
      "num acquisition: 3, time elapsed: 4.45s\n",
      "num acquisition: 4, time elapsed: 7.85s\n",
      "num acquisition: 5, time elapsed: 15.69s\n",
      "num acquisition: 6, time elapsed: 16.27s\n",
      "num acquisition: 7, time elapsed: 16.94s\n",
      "num acquisition: 8, time elapsed: 17.59s\n",
      "num acquisition: 9, time elapsed: 18.30s\n",
      "Model accuracy score from test data: 0.6560\n",
      "Model AUC from test data: 0.6610\n",
      "Sensitivity (true positive rate) on test data: 0.67\n",
      "Precision (positive predictive value) on test data: 0.10\n",
      "Specificity (true negative rate) on test data: 0.66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>326</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             36             18\n",
       "true:not user        326            620"
      ]
     },
     "execution_count": 17,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(8675309)  # seed courtesy of Tommy Tutone\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "hp_bounds = [{\n",
    "    'name': 'learning_rate',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0.001, 1.0)\n",
    "}, {\n",
    "    'name': 'max_depth',\n",
    "    'type': 'discrete',\n",
    "    'domain': (1, 10)\n",
    "}, {\n",
    "    'name': 'n_estimators',\n",
    "    'type': 'discrete',\n",
    "    'domain': (10, 100)\n",
    "}, {\n",
    "    'name': 'subsample',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0.05, 1.0)\n",
    "}, {\n",
    "    'name': 'min_child_weight',\n",
    "    'type': 'discrete',\n",
    "    'domain': (1, 20)\n",
    "}, {\n",
    "    'name': 'reg_alpha',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0, 5)\n",
    "}, {\n",
    "    'name': 'reg_lambda',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0, 5)\n",
    "}]\n",
    "\n",
    "\n",
    "# Optimization objective\n",
    "def cv_score(hyp_parameters):\n",
    "    hyp_parameters = hyp_parameters[0]\n",
    "    xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                 learning_rate=hyp_parameters[0],\n",
    "                                 max_depth=int(hyp_parameters[1]),\n",
    "                                 n_estimators=int(hyp_parameters[2]),\n",
    "                                 subsample=hyp_parameters[3],\n",
    "                                 min_child_weight=int(hyp_parameters[4]),\n",
    "                                 reg_alpha=hyp_parameters[5],\n",
    "                                 reg_lambda=hyp_parameters[6])\n",
    "    scores = cross_val_score(xgb_model,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=KFold(n_splits=5))\n",
    "    return np.array(scores.mean())  # return average of 5-fold scores\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_score,\n",
    "                                 domain=hp_bounds,\n",
    "                                 model_type='GP',\n",
    "                                 acquisition_type='EI',\n",
    "                                 acquisition_jitter=0.05,\n",
    "                                 exact_feval=True,\n",
    "                                 maximize=True,\n",
    "                                 verbosity=True)\n",
    "\n",
    "optimizer.run_optimization(max_iter=20,verbosity=True)\n",
    "\n",
    "best_hyp_set = {}\n",
    "for i in range(len(hp_bounds)):\n",
    "    if hp_bounds[i]['type'] == 'continuous':\n",
    "        best_hyp_set[hp_bounds[i]['name']] = optimizer.x_opt[i]\n",
    "    else:\n",
    "        best_hyp_set[hp_bounds[i]['name']] = int(optimizer.x_opt[i])\n",
    "        \n",
    "bayopt_search = xgb.XGBClassifier(objective=\"binary:logistic\",**best_hyp_set)        \n",
    "\n",
    "#fit the model\n",
    "bayopt_search.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(bayopt_search)\n",
    "c_df = updateResults(c_df, 'XGB - Bayesian', 125, score, auc, sens, prec, spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### XGBoost with TPOT Classifier\n",
    "\n",
    "With a single model type, TPOT looks a whole lot like our regular xgboost setup with random search. The syntax is slightly different, but the concepts are the same. We've added one extra parameter here to account for our imbalanced classes - the 'scale_pos_weight' parameter. Again, we're telling the classifier that we have about 17 negative cases for each positive case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=440, style=ProgressStyle(descript"
      ]
     },
     "execution_count": 18,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.6722895925843752\n",
      "Generation 2 - Current best internal CV score: 0.6729643337671076\n",
      "Generation 3 - Current best internal CV score: 0.6729643337671076\n",
      "Generation 4 - Current best internal CV score: 0.6729643337671076\n",
      "Generation 5 - Current best internal CV score: 0.6739639442156862\n",
      "Generation 6 - Current best internal CV score: 0.6769774396561972\n",
      "Generation 7 - Current best internal CV score: 0.6771318365736375\n",
      "Generation 8 - Current best internal CV score: 0.6771318365736375\n",
      "Generation 9 - Current best internal CV score: 0.6791073854986531\n",
      "Generation 10 - Current best internal CV score: 0.6791073854986531\n",
      "\n",
      "Best pipeline: XGBClassifier(XGBClassifier(input_matrix, learning_rate=0.001, max_depth=9, min_child_weight=8, n_estimators=100, nthread=2, objective=binary:logistic, reg_alpha=3, reg_lambda=3, scale_pos_weight=17, subsample=0.6000000000000001), learning_rate=0.001, max_depth=7, min_child_weight=12, n_estimators=100, nthread=2, objective=binary:logistic, reg_alpha=4, reg_lambda=4, scale_pos_weight=17, subsample=0.7000000000000001)\n",
      "Model accuracy score from test data: 0.7820\n",
      "Model AUC from test data: 0.5530\n",
      "Sensitivity (true positive rate) on test data: 0.30\n",
      "Precision (positive predictive value) on test data: 0.08\n",
      "Specificity (true negative rate) on test data: 0.81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>180</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             16             38\n",
       "true:not user        180            766"
      ]
     },
     "execution_count": 18,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot_config = {\n",
    "    'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'reg_alpha': range(1, 6),\n",
    "        'reg_lambda': range(1, 6),\n",
    "        'nthread': [2],\n",
    "        'objective': ['binary:logistic'],\n",
    "        'scale_pos_weight': [17] #trying to force tpot and xgboost to handle the imbalanced classes....\n",
    "    }\n",
    "}\n",
    "\n",
    "tpot = TPOTClassifier(generations=10,\n",
    "                     population_size=40,\n",
    "                     verbosity=2,\n",
    "                     config_dict=tpot_config,\n",
    "                     cv=3,\n",
    "                     scoring='balanced_accuracy',\n",
    "                     random_state=8675309)\n",
    "\n",
    "\n",
    "#fit the model\n",
    "tpot.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec, spec = my_classifier_results(tpot)\n",
    "c_df = updateResults(c_df, 'XGB - TPOT', 400, score, auc, sens, prec, spec)\n",
    "tpot.export('tpot_XGBclassifier-opioid.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### AutoML with TPOT Classifier\n",
    "\n",
    "With imbalanced classes, even using the balanced_accuracy scoring method, TPOT chooses algorithms that perform horribly if you give it just the default config. A custom config using just methods that can handle imbalanced classes, and setting the parameter that they use for imbalanced classes, is necessary to get a reasonable result.\n",
    "\n",
    "How did we figure this out? Well, like many packages in Python, the code that makes up the package is available on <a href=\"https://github.com/EpistasisLab/tpot\">github</a>. We're using the default classifier configuration. We can see all the models that the default classifier will attempt to run in the <a href=\"https://github.com/EpistasisLab/tpot/blob/master/tpot/config/classifier.py\">classifier config file</a>. Not all the models have mechanisms for dealing with imbalanced data. So, the config dictionary below includes just the models that have a mechanism for balancing classes. For each of them, we've added the parameter required to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=440, style=ProgressStyle(descript"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.6716822468374519\n",
      "Generation 2 - Current best internal CV score: 0.6716822468374519\n",
      "Generation 3 - Current best internal CV score: 0.6740268775392209\n",
      "Generation 4 - Current best internal CV score: 0.6740268775392209\n",
      "Generation 5 - Current best internal CV score: 0.6792025126199815\n",
      "Generation 6 - Current best internal CV score: 0.6792025126199815\n",
      "Generation 7 - Current best internal CV score: 0.67945712073083\n",
      "Generation 8 - Current best internal CV score: 0.6815589591157618\n",
      "Generation 9 - Current best internal CV score: 0.6815589591157618\n",
      "Generation 10 - Current best internal CV score: 0.6855140125014586\n",
      "\n",
      "Best pipeline: RandomForestClassifier(LinearSVC(CombineDFs(input_matrix, CombineDFs(LinearSVC(input_matrix, C=5.0, class_weight=balanced, dual=True, loss=hinge, penalty=l2, tol=0.01), input_matrix)), C=0.01, class_weight=balanced, dual=False, loss=squared_hinge, penalty=l2, tol=0.0001), bootstrap=True, class_weight=balanced, criterion=entropy, max_features=0.3, min_samples_leaf=13, min_samples_split=15, n_estimators=100)\n",
      "Model accuracy score from test data: 0.8460\n",
      "Model AUC from test data: 0.5345\n",
      "Sensitivity (true positive rate) on test data: 0.19\n",
      "Precision (positive predictive value) on test data: 0.08\n",
      "Specificity (true negative rate) on test data: 0.88\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:user</th>\n",
       "      <th>pred:not user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>true:user</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>true:not user</td>\n",
       "      <td>110</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pred:user  pred:not user\n",
       "true:user             10             44\n",
       "true:not user        110            836"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "classifier_config_dict = {\n",
    "\n",
    "\n",
    "\n",
    "    'sklearn.tree.DecisionTreeClassifier': {\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.RandomForestClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'criterion': [\"gini\", \"entropy\"],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf':  range(1, 21),\n",
    "        'bootstrap': [True, False],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "\n",
    "    #'sklearn.ensemble.GradientBoostingClassifier' - has no paramter for imbalanced data\n",
    "\n",
    "    #'sklearn.neighbors.KNeighborsClassifier' - has no parameter for imbalanced data\n",
    "\n",
    "    'sklearn.svm.LinearSVC': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'loss': [\"hinge\", \"squared_hinge\"],\n",
    "        'dual': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.LogisticRegression': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'dual': [True, False],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "\n",
    "    'xgboost.XGBClassifier': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'nthread': [1],\n",
    "        'scale_pos_weight': [17]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "tpot_auto = TPOTClassifier(generations=10,\n",
    "                     population_size=40,\n",
    "                     verbosity=2,\n",
    "                     cv=3,\n",
    "                    config_dict=classifier_config_dict,\n",
    "                     scoring='balanced_accuracy',\n",
    "                     random_state=8675309)\n",
    "\n",
    "#fit the model\n",
    "tpot_auto.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "#calculate score\n",
    "score, auc, sens, prec,spec = my_classifier_results(tpot_auto)\n",
    "c_df = updateResults(c_df, 'TPOT-General', 1600, score, auc, sens, prec, spec)\n",
    "tpot.export('tpot_optimal_pipeline-opioid.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "When working with imbalanced data, you definitely do not want to use accuracy as your primary measure. When sorting by accuracy, we can see that RFC - Baseline is the \"best\" choice. But the sensitivity and precision are both terrible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Fits</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>RFC - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.498414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Random Search</td>\n",
       "      <td>125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.566714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.911205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Grid Search</td>\n",
       "      <td>960</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.523863</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.0776699</td>\n",
       "      <td>0.899577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TPOT-General</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.534453</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0833333</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - TPOT</td>\n",
       "      <td>400</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.553011</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>0.809725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.65913</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.113553</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LogReg - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.676083</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.704017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ridge - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.664181</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.106583</td>\n",
       "      <td>0.698732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Bayesian</td>\n",
       "      <td>125</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.661029</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0994475</td>\n",
       "      <td>0.655391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GNB - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.504483</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.0544707</td>\n",
       "      <td>0.0274841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Fits Accuracy       AUC Sensitivity  Precision  \\\n",
       "RFC - Baseline               1    0.943  0.498414           0          0   \n",
       "XGB - Random Search        125    0.874  0.566714    0.222222      0.125   \n",
       "XGB - Grid Search          960    0.859  0.523863    0.148148  0.0776699   \n",
       "TPOT-General              1600    0.846  0.534453    0.185185  0.0833333   \n",
       "XGB - TPOT                 400    0.782  0.553011    0.296296  0.0816327   \n",
       "XGB - Baseline               1    0.735   0.65913    0.574074   0.113553   \n",
       "LogReg - Baseline            1    0.701  0.676083    0.648148   0.111111   \n",
       "Ridge - Baseline             1    0.695  0.664181     0.62963   0.106583   \n",
       "XGB - Bayesian             125    0.656  0.661029    0.666667  0.0994475   \n",
       "GNB - Baseline               1    0.079  0.504483    0.981481  0.0544707   \n",
       "\n",
       "                    Specificity  \n",
       "RFC - Baseline         0.996829  \n",
       "XGB - Random Search    0.911205  \n",
       "XGB - Grid Search      0.899577  \n",
       "TPOT-General           0.883721  \n",
       "XGB - TPOT             0.809725  \n",
       "XGB - Baseline         0.744186  \n",
       "LogReg - Baseline      0.704017  \n",
       "Ridge - Baseline       0.698732  \n",
       "XGB - Bayesian         0.655391  \n",
       "GNB - Baseline        0.0274841  "
      ]
     },
     "execution_count": 23,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "While RFC - baseline did have a parameter that should have accounted for the imbalanced data, it did not handle the imbalanced data well at all.\n",
    "\n",
    "Let's sort the dataframe by AUC and see where we're at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Fits</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>LogReg - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.676083</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.704017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ridge - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.664181</td>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.106583</td>\n",
       "      <td>0.698732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Bayesian</td>\n",
       "      <td>125</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.661029</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0994475</td>\n",
       "      <td>0.655391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.65913</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.113553</td>\n",
       "      <td>0.744186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Random Search</td>\n",
       "      <td>125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.566714</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.911205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - TPOT</td>\n",
       "      <td>400</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.553011</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.0816327</td>\n",
       "      <td>0.809725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TPOT-General</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.534453</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.0833333</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB - Grid Search</td>\n",
       "      <td>960</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.523863</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.0776699</td>\n",
       "      <td>0.899577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GNB - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.504483</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.0544707</td>\n",
       "      <td>0.0274841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RFC - Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.498414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model Fits Accuracy       AUC Sensitivity  Precision  \\\n",
       "LogReg - Baseline            1    0.701  0.676083    0.648148   0.111111   \n",
       "Ridge - Baseline             1    0.695  0.664181     0.62963   0.106583   \n",
       "XGB - Bayesian             125    0.656  0.661029    0.666667  0.0994475   \n",
       "XGB - Baseline               1    0.735   0.65913    0.574074   0.113553   \n",
       "XGB - Random Search        125    0.874  0.566714    0.222222      0.125   \n",
       "XGB - TPOT                 400    0.782  0.553011    0.296296  0.0816327   \n",
       "TPOT-General              1600    0.846  0.534453    0.185185  0.0833333   \n",
       "XGB - Grid Search          960    0.859  0.523863    0.148148  0.0776699   \n",
       "GNB - Baseline               1    0.079  0.504483    0.981481  0.0544707   \n",
       "RFC - Baseline               1    0.943  0.498414           0          0   \n",
       "\n",
       "                    Specificity  \n",
       "LogReg - Baseline      0.704017  \n",
       "Ridge - Baseline       0.698732  \n",
       "XGB - Bayesian         0.655391  \n",
       "XGB - Baseline         0.744186  \n",
       "XGB - Random Search    0.911205  \n",
       "XGB - TPOT             0.809725  \n",
       "TPOT-General           0.883721  \n",
       "XGB - Grid Search      0.899577  \n",
       "GNB - Baseline        0.0274841  \n",
       "RFC - Baseline         0.996829  "
      ]
     },
     "execution_count": 24,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df.sort_values(by=['AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sorting the dataframe this way, our formerly \"best\" model based on accuracy is now the bottom of the pile (not surprisingly). \n",
    "\n",
    "With the small dataset, the logistic regression baseline comes out on top. With the full dataset, the TPOT auto-tuning algorithm comes out on top.\n",
    "\n",
    "None of these models have a great AUC. This model is probably not particularly useful. What it probably needs is a different selection of predictors. But we'll leave that for another day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}