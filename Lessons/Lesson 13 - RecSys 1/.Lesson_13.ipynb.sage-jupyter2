{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-7cb8c2c5-bd31-450f-9b7f-9d374a832e8f.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"260.517px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"217c8c","input":"# enter your code here","pos":30,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8d1bbf","input":"ax = sns.heatmap(pd.DataFrame(tfidf_matrix.todense(), index=snip['title'], columns=feature_names))","pos":62,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8dd30f","input":"# enter your code here","pos":92,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"af8606","input":"# enter your code here","pos":33,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b274cb","input":"# enter your code here","pos":25,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b59cc8","input":"# enter your code here","pos":89,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"cd81df","input":"# enter your code here","pos":47,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"dd8b9f","input":"def getUniqueListFromColumn(df, col, returntype = 'string', sort=True):\n    #enter your code here\n    \n\n#This line calls your code. Try it with array instead of string, or not sorted, too\ngetUniqueListFromColumn(sa1_df, 'Flavors', 'string', True)","pos":13,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"bcaa3c","input":"# EXECUTE FIRST\n\n# computational imports\nimport numpy as np\nimport pandas as pd\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk import word_tokenize\n#nltk.download('averaged_perceptron_tagger')\nfrom sklearn.feature_extraction import text\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.corpus import wordnet as wn\nimport string\n\n# plotting imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nfrom scipy.spatial import distance\n\n# display imports\nfrom IPython.display import display, IFrame\nfrom IPython.core.display import HTML","metadata":{"code_folding":[0]},"pos":0,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"8df9e2","input":"df['score1'] = df.apply(weighted_rating, args=(m,C), axis=1)\ndf.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n      <th>score1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n      <td>7.626600</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n      <td>6.820534</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>949</td>\n      <td>Heat</td>\n      <td>60000000.0</td>\n      <td>[Action, Crime, Drama, Thriller]</td>\n      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n      <td>187436818</td>\n      <td>170.0</td>\n      <td>7.7</td>\n      <td>1886</td>\n      <td>1995</td>\n      <td>7.505628</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>710</td>\n      <td>GoldenEye</td>\n      <td>58000000.0</td>\n      <td>[Adventure, Action, Thriller]</td>\n      <td>James Bond must unmask the mysterious head of ...</td>\n      <td>352194034</td>\n      <td>130.0</td>\n      <td>6.6</td>\n      <td>1194</td>\n      <td>1995</td>\n      <td>6.506521</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>21032</td>\n      <td>Balto</td>\n      <td>0.0</td>\n      <td>[Family, Animation, Adventure]</td>\n      <td>An outcast half-wolf risks his life to prevent...</td>\n      <td>11348324</td>\n      <td>78.0</td>\n      <td>7.1</td>\n      <td>423</td>\n      <td>1995</td>\n      <td>6.712105</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       id      title      budget                            genres  \\\n0     862  Toy Story  30000000.0       [Animation, Comedy, Family]   \n1    8844    Jumanji  65000000.0      [Adventure, Fantasy, Family]   \n5     949       Heat  60000000.0  [Action, Crime, Drama, Thriller]   \n9     710  GoldenEye  58000000.0     [Adventure, Action, Thriller]   \n12  21032      Balto         0.0    [Family, Animation, Adventure]   \n\n                                             overview    revenue  runtime  \\\n0   Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1   When siblings Judy and Peter discover an encha...  262797249    104.0   \n5   Obsessive master thief, Neil McCauley leads a ...  187436818    170.0   \n9   James Bond must unmask the mysterious head of ...  352194034    130.0   \n12  An outcast half-wolf risks his life to prevent...   11348324     78.0   \n\n    vote_average  vote_count  year    score1  \n0            7.7        5415  1995  7.626600  \n1            6.9        2413  1995  6.820534  \n5            7.7        1886  1995  7.505628  \n9            6.6        1194  1995  6.506521  \n12           7.1         423  1995  6.712105  "},"exec_count":10,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"65dcc3","input":"#fetch c from the already filtered data\nC2 = df['vote_average'].mean()\nprint(f\"C is {C2}\")\n\ndf['score2'] = df.apply(weighted_rating, args=(m,C2), axis=1)\ndf.head()","output":{"0":{"name":"stdout","output_type":"stream","text":"C is 6.805500000000003\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n      <th>score1</th>\n      <th>score2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n      <td>7.626600</td>\n      <td>7.659741</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n      <td>6.820534</td>\n      <td>6.890962</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>949</td>\n      <td>Heat</td>\n      <td>60000000.0</td>\n      <td>[Action, Crime, Drama, Thriller]</td>\n      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n      <td>187436818</td>\n      <td>170.0</td>\n      <td>7.7</td>\n      <td>1886</td>\n      <td>1995</td>\n      <td>7.505628</td>\n      <td>7.593389</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>710</td>\n      <td>GoldenEye</td>\n      <td>58000000.0</td>\n      <td>[Adventure, Action, Thriller]</td>\n      <td>James Bond must unmask the mysterious head of ...</td>\n      <td>352194034</td>\n      <td>130.0</td>\n      <td>6.6</td>\n      <td>1194</td>\n      <td>1995</td>\n      <td>6.506521</td>\n      <td>6.636188</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>21032</td>\n      <td>Balto</td>\n      <td>0.0</td>\n      <td>[Family, Animation, Adventure]</td>\n      <td>An outcast half-wolf risks his life to prevent...</td>\n      <td>11348324</td>\n      <td>78.0</td>\n      <td>7.1</td>\n      <td>423</td>\n      <td>1995</td>\n      <td>6.712105</td>\n      <td>6.989183</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       id      title      budget                            genres  \\\n0     862  Toy Story  30000000.0       [Animation, Comedy, Family]   \n1    8844    Jumanji  65000000.0      [Adventure, Fantasy, Family]   \n5     949       Heat  60000000.0  [Action, Crime, Drama, Thriller]   \n9     710  GoldenEye  58000000.0     [Adventure, Action, Thriller]   \n12  21032      Balto         0.0    [Family, Animation, Adventure]   \n\n                                             overview    revenue  runtime  \\\n0   Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1   When siblings Judy and Peter discover an encha...  262797249    104.0   \n5   Obsessive master thief, Neil McCauley leads a ...  187436818    170.0   \n9   James Bond must unmask the mysterious head of ...  352194034    130.0   \n12  An outcast half-wolf risks his life to prevent...   11348324     78.0   \n\n    vote_average  vote_count  year    score1    score2  \n0            7.7        5415  1995  7.626600  7.659741  \n1            6.9        2413  1995  6.820534  6.890962  \n5            7.7        1886  1995  7.505628  7.593389  \n9            6.6        1194  1995  6.506521  6.636188  \n12           7.1         423  1995  6.712105  6.989183  "},"exec_count":11,"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"6bd47e","input":"def build_chart(gen_df, percentile=0.8):\n    \n    #Ask for preferred genres\n    print(\"Input preferred genre\")\n    genre = input()\n    \n    #Ask for lower limit of duration\n    print(\"Input shortest duration\")\n    low_time = int(input())\n    \n    #Ask for upper limit of duration\n    print(\"Input longest duration\")\n    high_time = int(input())\n    \n    #Ask for lower limit of timeline\n    print(\"Input earliest year\")\n    low_year = int(input())\n    \n    #Ask for upper limit of timeline\n    print(\"Input latest year\")\n    high_year = int(input())\n    \n    #Define a new movies variable to store the preferred movies. Copy the contents of gen_df to movies\n    movies = gen_df.copy()\n    \n    #Filter based on the condition\n    movies = movies[(movies['genres'].apply(lambda x: genre in x)) & #updated filtering based on a list.\n                    (movies['runtime'] >= low_time) & \n                    (movies['runtime'] <= high_time) & \n                    (movies['year'] >= low_year) & \n                    (movies['year'] <= high_year)]\n    \n    #Compute the values of C and m for the filtered movies\n    C = movies['vote_average'].mean()\n    m = movies['vote_count'].quantile(percentile)\n    \n    #Only consider movies that have higher than m votes. Save this in a new dataframe q_movies\n    q_movies = movies.copy().loc[movies['vote_count'] >= m]\n    \n    #Calculate score using the IMDB formula\n    q_movies['score'] = q_movies.apply(lambda x: (x['vote_count']/(x['vote_count']+m) * x['vote_average']) \n                                       + (m/(m+x['vote_count']) * C)\n                                       ,axis=1)\n\n    #Sort movies in descending order of their scores\n    q_movies = q_movies.sort_values('score', ascending=False)\n    \n    return q_movies","pos":35,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"1a813b","input":"out_movies = build_chart(df, .8)","metadata":{"cocalc":{"outputs":{"1":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"Family"},"2":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"3":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"80"},"4":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"5":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"120"},"6":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"7":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"1980"},"8":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"9":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"2000"}}}},"output":{"0":{"name":"stdout","output_type":"stream","text":"Input preferred genre\n"},"1":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"Family"},"2":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"3":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"80"},"4":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"5":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"120"},"6":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"7":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"1980"},"8":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream"},"9":{"name":"input","opts":{"password":false,"prompt":""},"output_type":"stream","value":"2000"}},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"20a777","input":"#set the score rank column\nout_movies['scoreRank'] = np.arange(len(out_movies))\n#sort by score1 and set the score1rank column\nout_movies = out_movies.sort_values('score1', ascending=False)\nout_movies['score1Rank'] = np.arange(len(out_movies))\n#sort by score2 and set the score2rank column\nout_movies = out_movies.sort_values('score2', ascending=False)\nout_movies['score2Rank'] = np.arange(len(out_movies))\n#resort by score\nout_movies = out_movies.sort_values('score', ascending=False)\n\n#display the final result with just name and scores\nout_movies[['title','score1Rank', 'score2Rank', 'scoreRank' ]]","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>score1Rank</th>\n      <th>score2Rank</th>\n      <th>scoreRank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1225</th>\n      <td>Back to the Future</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>The Lion King</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Toy Story</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>Beauty and the Beast</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1902</th>\n      <td>Back to the Future Part II</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>581</th>\n      <td>Aladdin</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>Mulan</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>Toy Story 2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1065</th>\n      <td>E.T. the Extra-Terrestrial</td>\n      <td>8</td>\n      <td>8</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1903</th>\n      <td>Back to the Future Part III</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1972</th>\n      <td>The Little Mermaid</td>\n      <td>9</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>579</th>\n      <td>Home Alone</td>\n      <td>11</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jumanji</td>\n      <td>12</td>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2242</th>\n      <td>A Bug's Life</td>\n      <td>13</td>\n      <td>13</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2837</th>\n      <td>Home Alone 2: Lost in New York</td>\n      <td>14</td>\n      <td>14</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                               title  score1Rank  score2Rank  scoreRank\n1225              Back to the Future           0           0          0\n359                    The Lion King           1           1          1\n0                          Toy Story           2           2          2\n588             Beauty and the Beast           4           4          3\n1902      Back to the Future Part II           5           5          4\n581                          Aladdin           6           6          5\n1798                           Mulan           3           3          6\n2997                     Toy Story 2           7           7          7\n1065      E.T. the Extra-Terrestrial           8           8          8\n1903     Back to the Future Part III          10          10          9\n1972              The Little Mermaid           9           9         10\n579                       Home Alone          11          11         11\n1                            Jumanji          12          12         12\n2242                    A Bug's Life          13          13         13\n2837  Home Alone 2: Lost in New York          14          14         14"},"exec_count":14,"output_type":"execute_result"}},"pos":39,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"f872e9","input":"def build_chart(gen_df, percentile=0.8, genre = None, low_time = None, high_time = None, low_year = None, high_year = None):\n    \n    #Ask for preferred genres\n    if genre is None:\n        print(\"Input preferred genre\")\n        genre = input()\n    \n    #Ask for lower limit of duration\n    if low_time is None:\n        print(\"Input shortest duration\")\n        low_time = int(input())\n    \n    #Ask for upper limit of duration\n    if high_time is None:\n        print(\"Input longest duration\")\n        high_time = int(input())\n    \n    #Ask for lower limit of timeline\n    if low_year is None:\n        print(\"Input earliest year\")\n        low_year = int(input())\n    \n    #Ask for upper limit of timeline\n    if high_year is None:\n        print(\"Input latest year\")\n        high_year = int(input())\n    \n    #Define a new movies variable to store the preferred movies. Copy the contents of gen_df to movies\n    movies = gen_df.copy()\n    \n    #Filter based on the condition\n    movies = movies[(movies['genres'].apply(lambda x: genre in x)) & #updated filtering based on a list.\n                    (movies['runtime'] >= low_time) & \n                    (movies['runtime'] <= high_time) & \n                    (movies['year'] >= low_year) & \n                    (movies['year'] <= high_year)]\n    \n    #Compute the values of C and m for the filtered movies\n    C = movies['vote_average'].mean()\n    m = movies['vote_count'].quantile(percentile)\n    \n    #Only consider movies that have higher than m votes. Save this in a new dataframe q_movies\n    q_movies = movies.copy().loc[movies['vote_count'] >= m]\n    \n    #Calculate score using the IMDB formula\n    q_movies['score'] = q_movies.apply(lambda x: (x['vote_count']/(x['vote_count']+m) * x['vote_average']) \n                                       + (m/(m+x['vote_count']) * C)\n                                       ,axis=1)\n\n    #Sort movies in descending order of their scores\n    q_movies = q_movies.sort_values('score', ascending=False)\n    \n    return q_movies","pos":42,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"f5dd45","input":"out_movies = build_chart(df, .8, 'Family', 80, 120, 1980, 2000)\n# or can call with named arguments\n# out_movies = build_chart(df, percentile = .8, genre = 'Family', low_time = 80, high_time = 120, low_year = 1980, high_year = 2000)\nout_movies","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n      <th>score1</th>\n      <th>score2</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1225</th>\n      <td>105</td>\n      <td>Back to the Future</td>\n      <td>19000000.0</td>\n      <td>[Adventure, Comedy, Science Fiction, Family]</td>\n      <td>Eighties teenager Marty McFly is accidentally ...</td>\n      <td>381109762</td>\n      <td>116.0</td>\n      <td>8.0</td>\n      <td>6239</td>\n      <td>1985</td>\n      <td>7.924125</td>\n      <td>7.953060</td>\n      <td>7.668069</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>8587</td>\n      <td>The Lion King</td>\n      <td>45000000.0</td>\n      <td>[Family, Animation, Drama]</td>\n      <td>A young lion cub named Simba can't wait to be ...</td>\n      <td>788241776</td>\n      <td>89.0</td>\n      <td>8.0</td>\n      <td>5520</td>\n      <td>1994</td>\n      <td>7.914678</td>\n      <td>7.947216</td>\n      <td>7.635362</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n      <td>7.626600</td>\n      <td>7.659741</td>\n      <td>7.404163</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>10020</td>\n      <td>Beauty and the Beast</td>\n      <td>25000000.0</td>\n      <td>[Romance, Family, Animation, Fantasy, Music]</td>\n      <td>Follow the adventures of Belle, a bright young...</td>\n      <td>377350553</td>\n      <td>84.0</td>\n      <td>7.5</td>\n      <td>3029</td>\n      <td>1991</td>\n      <td>7.388816</td>\n      <td>7.446034</td>\n      <td>7.131240</td>\n    </tr>\n    <tr>\n      <th>1902</th>\n      <td>165</td>\n      <td>Back to the Future Part II</td>\n      <td>40000000.0</td>\n      <td>[Adventure, Comedy, Family, Science Fiction]</td>\n      <td>Marty and Doc are at it again in this wacky se...</td>\n      <td>332000000</td>\n      <td>108.0</td>\n      <td>7.4</td>\n      <td>3926</td>\n      <td>1989</td>\n      <td>7.318772</td>\n      <td>7.363715</td>\n      <td>7.120400</td>\n    </tr>\n    <tr>\n      <th>581</th>\n      <td>812</td>\n      <td>Aladdin</td>\n      <td>28000000.0</td>\n      <td>[Animation, Family, Comedy, Adventure, Fantasy...</td>\n      <td>Princess Jasmine grows tired of being forced t...</td>\n      <td>504050219</td>\n      <td>90.0</td>\n      <td>7.4</td>\n      <td>3495</td>\n      <td>1992</td>\n      <td>7.309437</td>\n      <td>7.359544</td>\n      <td>7.097541</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>10674</td>\n      <td>Mulan</td>\n      <td>90000000.0</td>\n      <td>[Animation, Family, Adventure]</td>\n      <td>A tomboyish girl disguises herself as a young ...</td>\n      <td>304320254</td>\n      <td>88.0</td>\n      <td>7.6</td>\n      <td>2089</td>\n      <td>1998</td>\n      <td>7.433346</td>\n      <td>7.513507</td>\n      <td>7.095613</td>\n    </tr>\n    <tr>\n      <th>2997</th>\n      <td>863</td>\n      <td>Toy Story 2</td>\n      <td>90000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Andy heads off to Cowboy Camp, leaving his toy...</td>\n      <td>497366869</td>\n      <td>92.0</td>\n      <td>7.3</td>\n      <td>3914</td>\n      <td>1999</td>\n      <td>7.224659</td>\n      <td>7.269731</td>\n      <td>7.051035</td>\n    </tr>\n    <tr>\n      <th>1065</th>\n      <td>601</td>\n      <td>E.T. the Extra-Terrestrial</td>\n      <td>10500000.0</td>\n      <td>[Science Fiction, Adventure, Family, Fantasy]</td>\n      <td>After a gentle alien becomes stranded on Earth...</td>\n      <td>792965326</td>\n      <td>115.0</td>\n      <td>7.3</td>\n      <td>3359</td>\n      <td>1982</td>\n      <td>7.213090</td>\n      <td>7.265083</td>\n      <td>7.024131</td>\n    </tr>\n    <tr>\n      <th>1903</th>\n      <td>196</td>\n      <td>Back to the Future Part III</td>\n      <td>40000000.0</td>\n      <td>[Adventure, Comedy, Family, Science Fiction]</td>\n      <td>The final installment of the Back to the Futur...</td>\n      <td>244527583</td>\n      <td>118.0</td>\n      <td>7.1</td>\n      <td>2978</td>\n      <td>1990</td>\n      <td>7.018635</td>\n      <td>7.076755</td>\n      <td>6.876769</td>\n    </tr>\n    <tr>\n      <th>1972</th>\n      <td>10144</td>\n      <td>The Little Mermaid</td>\n      <td>40000000.0</td>\n      <td>[Animation, Family]</td>\n      <td>This colorful adventure tells the story of an ...</td>\n      <td>222300000</td>\n      <td>83.0</td>\n      <td>7.2</td>\n      <td>1921</td>\n      <td>1989</td>\n      <td>7.067388</td>\n      <td>7.153738</td>\n      <td>6.864910</td>\n    </tr>\n    <tr>\n      <th>579</th>\n      <td>771</td>\n      <td>Home Alone</td>\n      <td>18000000.0</td>\n      <td>[Comedy, Family]</td>\n      <td>Eight-year-old Kevin McCallister makes the mos...</td>\n      <td>476684675</td>\n      <td>103.0</td>\n      <td>7.1</td>\n      <td>2487</td>\n      <td>1990</td>\n      <td>7.004066</td>\n      <td>7.072593</td>\n      <td>6.851064</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n      <td>6.820534</td>\n      <td>6.890962</td>\n      <td>6.731489</td>\n    </tr>\n    <tr>\n      <th>2242</th>\n      <td>9487</td>\n      <td>A Bug's Life</td>\n      <td>120000000.0</td>\n      <td>[Adventure, Animation, Comedy, Family]</td>\n      <td>On behalf of \"oppressed bugs everywhere,\" an i...</td>\n      <td>363258859</td>\n      <td>95.0</td>\n      <td>6.8</td>\n      <td>2379</td>\n      <td>1998</td>\n      <td>6.729197</td>\n      <td>6.800533</td>\n      <td>6.672868</td>\n    </tr>\n    <tr>\n      <th>2837</th>\n      <td>772</td>\n      <td>Home Alone 2: Lost in New York</td>\n      <td>18000000.0</td>\n      <td>[Comedy, Family, Adventure, Crime]</td>\n      <td>Instead of flying to Florida with his folks, K...</td>\n      <td>358991681</td>\n      <td>120.0</td>\n      <td>6.3</td>\n      <td>2459</td>\n      <td>1992</td>\n      <td>6.278295</td>\n      <td>6.347529</td>\n      <td>6.385019</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         id                           title       budget  \\\n1225    105              Back to the Future   19000000.0   \n359    8587                   The Lion King   45000000.0   \n0       862                       Toy Story   30000000.0   \n588   10020            Beauty and the Beast   25000000.0   \n1902    165      Back to the Future Part II   40000000.0   \n581     812                         Aladdin   28000000.0   \n1798  10674                           Mulan   90000000.0   \n2997    863                     Toy Story 2   90000000.0   \n1065    601      E.T. the Extra-Terrestrial   10500000.0   \n1903    196     Back to the Future Part III   40000000.0   \n1972  10144              The Little Mermaid   40000000.0   \n579     771                      Home Alone   18000000.0   \n1      8844                         Jumanji   65000000.0   \n2242   9487                    A Bug's Life  120000000.0   \n2837    772  Home Alone 2: Lost in New York   18000000.0   \n\n                                                 genres  \\\n1225       [Adventure, Comedy, Science Fiction, Family]   \n359                          [Family, Animation, Drama]   \n0                           [Animation, Comedy, Family]   \n588        [Romance, Family, Animation, Fantasy, Music]   \n1902       [Adventure, Comedy, Family, Science Fiction]   \n581   [Animation, Family, Comedy, Adventure, Fantasy...   \n1798                     [Animation, Family, Adventure]   \n2997                        [Animation, Comedy, Family]   \n1065      [Science Fiction, Adventure, Family, Fantasy]   \n1903       [Adventure, Comedy, Family, Science Fiction]   \n1972                                [Animation, Family]   \n579                                    [Comedy, Family]   \n1                          [Adventure, Fantasy, Family]   \n2242             [Adventure, Animation, Comedy, Family]   \n2837                 [Comedy, Family, Adventure, Crime]   \n\n                                               overview    revenue  runtime  \\\n1225  Eighties teenager Marty McFly is accidentally ...  381109762    116.0   \n359   A young lion cub named Simba can't wait to be ...  788241776     89.0   \n0     Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n588   Follow the adventures of Belle, a bright young...  377350553     84.0   \n1902  Marty and Doc are at it again in this wacky se...  332000000    108.0   \n581   Princess Jasmine grows tired of being forced t...  504050219     90.0   \n1798  A tomboyish girl disguises herself as a young ...  304320254     88.0   \n2997  Andy heads off to Cowboy Camp, leaving his toy...  497366869     92.0   \n1065  After a gentle alien becomes stranded on Earth...  792965326    115.0   \n1903  The final installment of the Back to the Futur...  244527583    118.0   \n1972  This colorful adventure tells the story of an ...  222300000     83.0   \n579   Eight-year-old Kevin McCallister makes the mos...  476684675    103.0   \n1     When siblings Judy and Peter discover an encha...  262797249    104.0   \n2242  On behalf of \"oppressed bugs everywhere,\" an i...  363258859     95.0   \n2837  Instead of flying to Florida with his folks, K...  358991681    120.0   \n\n      vote_average  vote_count  year    score1    score2     score  \n1225           8.0        6239  1985  7.924125  7.953060  7.668069  \n359            8.0        5520  1994  7.914678  7.947216  7.635362  \n0              7.7        5415  1995  7.626600  7.659741  7.404163  \n588            7.5        3029  1991  7.388816  7.446034  7.131240  \n1902           7.4        3926  1989  7.318772  7.363715  7.120400  \n581            7.4        3495  1992  7.309437  7.359544  7.097541  \n1798           7.6        2089  1998  7.433346  7.513507  7.095613  \n2997           7.3        3914  1999  7.224659  7.269731  7.051035  \n1065           7.3        3359  1982  7.213090  7.265083  7.024131  \n1903           7.1        2978  1990  7.018635  7.076755  6.876769  \n1972           7.2        1921  1989  7.067388  7.153738  6.864910  \n579            7.1        2487  1990  7.004066  7.072593  6.851064  \n1              6.9        2413  1995  6.820534  6.890962  6.731489  \n2242           6.8        2379  1998  6.729197  6.800533  6.672868  \n2837           6.3        2459  1992  6.278295  6.347529  6.385019  "},"exec_count":16,"output_type":"execute_result"}},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"e9b38a","input":"#create a small dataframe\ndf = pd.DataFrame({'ID': ['Doc 1', 'Doc 2', 'Doc 3'], \n                   'Abstract': ['She is a queen bee.', 'There is no king.', 'The queen rules her bees.']})\n\n#use the document name as the index\ncorpus_index = df['ID']","pos":49,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"cb9b83","input":"#create a Count Vectorizer that explicitly converts to lowercase and removes stopwords.\nvec1 = CountVectorizer(lowercase=True, stop_words='english')\n\n#Construct the required count matrix by applying the fit_transform method on the Abstract\ncount_matrix = vec1.fit_transform(df['Abstract'])\n\n#display the matrix as a pandas dataframe\npd.DataFrame(count_matrix.todense(), index=corpus_index, columns=vec1.get_feature_names())","output":{"0":{"name":"stderr","output_type":"stream","text":"/home/user/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bee</th>\n      <th>bees</th>\n      <th>king</th>\n      <th>queen</th>\n      <th>rules</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Doc 1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Doc 2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Doc 3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       bee  bees  king  queen  rules\nID                                  \nDoc 1    1     0     0      1      0\nDoc 2    0     0     1      0      0\nDoc 3    0     1     0      1      1"},"exec_count":18,"output_type":"execute_result"}},"pos":51,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"597240","input":"#create a Count Vectorizer that explicitly converts to lowercase and removes stopwords and looks at 1 and 2 word n-grams.\nvec2 = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2))\n\n#Construct the required count matrix by applying the fit_transform method on the Abstract\ncount_matrix = vec2.fit_transform(df['Abstract'])\n\n#display the matrix as a pandas dataframe\npd.DataFrame(count_matrix.todense(), index=corpus_index, columns=vec2.get_feature_names())","output":{"0":{"name":"stderr","output_type":"stream","text":"/home/user/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bee</th>\n      <th>bees</th>\n      <th>king</th>\n      <th>queen</th>\n      <th>queen bee</th>\n      <th>queen rules</th>\n      <th>rules</th>\n      <th>rules bees</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Doc 1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Doc 2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Doc 3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       bee  bees  king  queen  queen bee  queen rules  rules  rules bees\nID                                                                      \nDoc 1    1     0     0      1          1            0      0           0\nDoc 2    0     0     1      0          0            0      0           0\nDoc 3    0     1     0      1          0            1      1           1"},"exec_count":19,"output_type":"execute_result"}},"pos":53,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"b004c5","input":"#read in the file\ndf = pd.read_csv('data/movies_metadata_clean.csv')\nprint(f'The shape of the dataframe is {df.shape}')\ndf.head()","output":{"0":{"name":"stdout","output_type":"stream","text":"The shape of the dataframe is (5000, 10)\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>['Animation', 'Comedy', 'Family']</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>['Adventure', 'Fantasy', 'Family']</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15602</td>\n      <td>Grumpier Old Men</td>\n      <td>0.0</td>\n      <td>['Romance', 'Comedy']</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>0</td>\n      <td>101.0</td>\n      <td>6.5</td>\n      <td>92</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>['Comedy', 'Drama', 'Romance']</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>Father of the Bride Part II</td>\n      <td>0.0</td>\n      <td>['Comedy']</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>76578911</td>\n      <td>106.0</td>\n      <td>5.7</td>\n      <td>173</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id                        title      budget  \\\n0    862                    Toy Story  30000000.0   \n1   8844                      Jumanji  65000000.0   \n2  15602             Grumpier Old Men         0.0   \n3  31357            Waiting to Exhale  16000000.0   \n4  11862  Father of the Bride Part II         0.0   \n\n                               genres  \\\n0   ['Animation', 'Comedy', 'Family']   \n1  ['Adventure', 'Fantasy', 'Family']   \n2               ['Romance', 'Comedy']   \n3      ['Comedy', 'Drama', 'Romance']   \n4                          ['Comedy']   \n\n                                            overview    revenue  runtime  \\\n0  Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n2  A family wedding reignites the ancient feud be...          0    101.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n4  Just when George Banks has recovered from his ...   76578911    106.0   \n\n   vote_average  vote_count  year  \n0           7.7        5415  1995  \n1           6.9        2413  1995  \n2           6.5          92  1995  \n3           6.1          34  1995  \n4           5.7         173  1995  "},"exec_count":2,"output_type":"execute_result"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"9f5148","input":"#################################\n# This cell does all the set up work - you only need to run this once per notebook\n#################################\nnltk.download('wordnet')\nnltk.download('punkt')\n\n#Create a helper function to get part of speech\ndef get_wordnet_pos(word, pretagged = False):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    if pretagged:\n        tag = word[1].upper() \n    else:\n        tag = nltk.pos_tag([word])[0][1][0].upper()\n    \n    tag_dict = {\"J\": wn.ADJ,\n                \"N\": wn.NOUN,\n                \"V\": wn.VERB,\n                \"R\": wn.ADV}\n\n    return tag_dict.get(tag, wn.NOUN)\n\n#create a tokenizer that uses lemmatization (word shortening)\nclass LemmaTokenizer(object):\n    def __init__(self):\n        self.wnl = WordNetLemmatizer()\n    def __call__(self, articles):\n        \n        #get the sentences\n        sents = sent_tokenize(articles)\n        #get the parts of speech for sentence tokens\n        sent_pos = [nltk.pos_tag(word_tokenize(s)) for s in sents]\n        #flatten the list\n        pos = [item for sublist in sent_pos for item in sublist]\n        #lemmatize based on POS (otherwise, all words are nouns)\n        lems = [self.wnl.lemmatize(t[0], get_wordnet_pos(t, True)) for t in pos if t[0] not in string.punctuation]\n        #clean up in-word punctuation\n        lems_clean = [''.join(c for c in s if c not in string.punctuation) for s in lems]\n        return lems_clean \n\n\n    \n#lemmatize the stop words\nlemmatizer = WordNetLemmatizer()\nlemmatized_stop_words = [lemmatizer.lemmatize(w) for w in text.ENGLISH_STOP_WORDS]\n#extend the stop words with any other words you want to add, these are bits of contractions\nlemmatized_stop_words.extend(['ve','nt','ca','wo','ll'])\n","output":{"0":{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n"},"1":{"name":"stderr","output_type":"stream","text":"[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /home/user/nltk_data...\n"},"2":{"name":"stderr","output_type":"stream","text":"[nltk_data]   Package punkt is already up-to-date!\n"}},"pos":55,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"bda9ea","input":"#create the vectorizer using the lemmaTokenizer - note that we also need the lemmatized version of the stop words for this to work\nvec3 = CountVectorizer(tokenizer=LemmaTokenizer(), lowercase=True, stop_words=lemmatized_stop_words) \n\n#Construct the required count matrix by applying the fit_transform method on the Abstract\ncount_matrix3 = vec3.fit_transform(df['Abstract'])\n\npd.DataFrame(count_matrix3.todense(), index=corpus_index, columns=vec3.get_feature_names())","output":{"0":{"name":"stderr","output_type":"stream","text":"/home/user/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bee</th>\n      <th>king</th>\n      <th>queen</th>\n      <th>rule</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Doc 1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Doc 2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Doc 3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       bee  king  queen  rule\nID                           \nDoc 1    1     0      1     0\nDoc 2    0     1      0     0\nDoc 3    1     0      1     1"},"exec_count":21,"output_type":"execute_result"}},"pos":56,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"3796b7","input":"#remember what's in snip\nsnip = snip.copy()\ndisplay(snip)\n\n#Define a TF-IDF Vectorizer Object. Use the LemmaTokenizer defined above, convert to lowercase, and remove stopwords.\ntfidf = TfidfVectorizer(tokenizer=LemmaTokenizer(), lowercase=True, stop_words=lemmatized_stop_words, max_features = 100)\n\n#if we had any empty overview fields, we'd need to replace NaN with an empty string. \n# we don't in our snip dataset, but we'll step through it as a good practice\nsnip['overview'] = snip['overview'].fillna('')\n\n#Construct the required TF-IDF matrix by applying the fit_transform method on the overview feature\ntfidf_matrix = tfidf.fit_transform(snip['overview'])\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15602</td>\n      <td>Grumpier Old Men</td>\n      <td>0.0</td>\n      <td>[Romance, Comedy]</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>0</td>\n      <td>101.0</td>\n      <td>6.5</td>\n      <td>92</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>Father of the Bride Part II</td>\n      <td>0.0</td>\n      <td>[Comedy]</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>76578911</td>\n      <td>106.0</td>\n      <td>5.7</td>\n      <td>173</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id                        title      budget  \\\n0    862                    Toy Story  30000000.0   \n1   8844                      Jumanji  65000000.0   \n2  15602             Grumpier Old Men         0.0   \n3  31357            Waiting to Exhale  16000000.0   \n4  11862  Father of the Bride Part II         0.0   \n\n                         genres  \\\n0   [Animation, Comedy, Family]   \n1  [Adventure, Fantasy, Family]   \n2             [Romance, Comedy]   \n3      [Comedy, Drama, Romance]   \n4                      [Comedy]   \n\n                                            overview    revenue  runtime  \\\n0  Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n2  A family wedding reignites the ancient feud be...          0    101.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n4  Just when George Banks has recovered from his ...   76578911    106.0   \n\n   vote_average  vote_count  year  \n0           7.7        5415  1995  \n1           6.9        2413  1995  \n2           6.5          92  1995  \n3           6.1          34  1995  \n4           5.7         173  1995  "},"exec_count":22,"output_type":"execute_result"},"1":{"data":{"text/plain":"(5, 100)"},"exec_count":22,"output_type":"execute_result"}},"pos":58,"type":"cell"}
{"cell_type":"code","exec_count":23,"id":"682a84","input":"#this extracts all the words (features) in the matrix - we'll use this for our columns\nfeature_names = tfidf.get_feature_names()\n#this extracts the IDs of the movies - we'll use this for our rows\ncorpus_index = snip['title']\n#this puts both into a dataframe. \n#The tfidf_matrix is usually a sparse matrix, meaning not all row/col combinations have a value. Using todense() puts a zero in that row/col slot\npd.DataFrame(tfidf_matrix.todense(), index=corpus_index, columns=feature_names)\n","output":{"0":{"name":"stderr","output_type":"stream","text":"/home/user/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>26</th>\n      <th>adult</th>\n      <th>afraid</th>\n      <th>alan</th>\n      <th>alarming</th>\n      <th>ancient</th>\n      <th>andy</th>\n      <th>arrival</th>\n      <th>aside</th>\n      <th>...</th>\n      <th>trapped</th>\n      <th>unwittingly</th>\n      <th>vannah</th>\n      <th>waiting</th>\n      <th>way</th>\n      <th>wedding</th>\n      <th>wife</th>\n      <th>woman</th>\n      <th>woody</th>\n      <th>world</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Toy Story</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.145084</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.435251</td>\n      <td>0.000000</td>\n      <td>0.145084</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.435251</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Jumanji</th>\n      <td>0.222113</td>\n      <td>0.165827</td>\n      <td>0.165827</td>\n      <td>0.000000</td>\n      <td>0.331654</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.165827</td>\n      <td>0.165827</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.165827</td>\n    </tr>\n    <tr>\n      <th>Grumpier Old Men</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.201541</td>\n      <td>0.201541</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.162602</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Waiting to Exhale</th>\n      <td>0.286912</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.214206</td>\n      <td>0.214206</td>\n      <td>0.214206</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.214206</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Father of the Bride Part II</th>\n      <td>0.340747</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.169599</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.136831</td>\n      <td>0.169599</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  100 columns</p>\n</div>","text/plain":"                                             26     adult    afraid      alan  \\\ntitle                                                                           \nToy Story                    0.000000  0.000000  0.000000  0.145084  0.000000   \nJumanji                      0.222113  0.165827  0.165827  0.000000  0.331654   \nGrumpier Old Men             0.000000  0.000000  0.000000  0.000000  0.000000   \nWaiting to Exhale            0.286912  0.000000  0.000000  0.000000  0.000000   \nFather of the Bride Part II  0.340747  0.000000  0.000000  0.000000  0.000000   \n\n                             alarming   ancient      andy   arrival     aside  \\\ntitle                                                                           \nToy Story                    0.000000  0.000000  0.435251  0.000000  0.145084   \nJumanji                      0.000000  0.000000  0.000000  0.000000  0.000000   \nGrumpier Old Men             0.201541  0.201541  0.000000  0.000000  0.000000   \nWaiting to Exhale            0.000000  0.000000  0.000000  0.000000  0.000000   \nFather of the Bride Part II  0.000000  0.000000  0.000000  0.169599  0.000000   \n\n                             ...   trapped  unwittingly    vannah   waiting  \\\ntitle                        ...                                              \nToy Story                    ...  0.000000     0.000000  0.000000  0.000000   \nJumanji                      ...  0.165827     0.165827  0.000000  0.000000   \nGrumpier Old Men             ...  0.000000     0.000000  0.000000  0.000000   \nWaiting to Exhale            ...  0.000000     0.000000  0.214206  0.214206   \nFather of the Bride Part II  ...  0.000000     0.000000  0.000000  0.000000   \n\n                                  way   wedding      wife     woman     woody  \\\ntitle                                                                           \nToy Story                    0.000000  0.000000  0.000000  0.000000  0.435251   \nJumanji                      0.000000  0.000000  0.000000  0.000000  0.000000   \nGrumpier Old Men             0.000000  0.162602  0.000000  0.000000  0.000000   \nWaiting to Exhale            0.214206  0.000000  0.000000  0.214206  0.000000   \nFather of the Bride Part II  0.000000  0.136831  0.169599  0.000000  0.000000   \n\n                                world  \ntitle                                  \nToy Story                    0.000000  \nJumanji                      0.165827  \nGrumpier Old Men             0.000000  \nWaiting to Exhale            0.000000  \nFather of the Bride Part II  0.000000  \n\n[5 rows x 100 columns]"},"exec_count":23,"output_type":"execute_result"}},"pos":60,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"24da05","input":"V = np.array([[12,1], [4,1], [4,7], [-12,-1]])\norigin = np.array([[0, 0, 0, 0],[0, 0, 0, 0]]) # origin point\n\nplt.quiver(*origin, V[:,0], V[:,1], color=['r','b','g','black'], scale=31)\nplt.ylabel('Action')\nplt.xlabel('Comedy')\nplt.title('Movies rated as Action or Comedy')\nplt.show()\n\n","output":{"0":{"data":{"image/png":"db3ec1354a5dd6b099be7fdc26ec9ce50c016b88","text/plain":"<Figure size 864x504 with 1 Axes>"},"exec_count":24,"metadata":{"image/png":{"height":440,"width":735}},"output_type":"execute_result"}},"pos":64,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"36e3ff","input":"print('Remember - the higher the number, the closer the vectors.')\nprint(f'The similarity between the red and blue vectors is {round(1 - distance.cosine(V[0], V[1]), 3)}')\nprint(f'The similarity between the blue and green vectors is {round(1 - distance.cosine(V[1], V[2]), 3)}')\nprint(f'The similarity between the red and green vectors is {round(1 - distance.cosine(V[0], V[2]), 3)}')\nprint(f'The similarity between the red and black vectors is {round(1 - distance.cosine(V[0], V[3]), 3)}')\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Remember - the higher the number, the closer the vectors.\nThe similarity between the red and blue vectors is 0.987\nThe similarity between the blue and green vectors is 0.692\nThe similarity between the red and green vectors is 0.567\nThe similarity between the red and black vectors is -1.0\n"}},"pos":66,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"110bf2","input":"# Compute the cosine similarity matrix\nsim_matrix = linear_kernel(tfidf_matrix, tfidf_matrix)\n\n#let's look at what we've got.\ndpdf = pd.DataFrame(sim_matrix, columns=snip['title'], index=snip['title'])\ncm = sns.color_palette(\"Blues\", as_cmap=True)\ndpdf.style.set_caption('Dot Product with most similar movies highlighted.')\\\n    .background_gradient(cmap=cm)","output":{"0":{"data":{"text/html":"<style type=\"text/css\">\n#T_48c77_row0_col0, #T_48c77_row1_col1, #T_48c77_row2_col2, #T_48c77_row3_col3, #T_48c77_row4_col4 {\n  background-color: #08306b;\n  color: #f1f1f1;\n}\n#T_48c77_row0_col1 {\n  background-color: #f4f9fe;\n  color: #000000;\n}\n#T_48c77_row0_col2, #T_48c77_row0_col4, #T_48c77_row2_col0 {\n  background-color: #f2f7fd;\n  color: #000000;\n}\n#T_48c77_row0_col3, #T_48c77_row2_col1, #T_48c77_row2_col3, #T_48c77_row2_col4, #T_48c77_row3_col0, #T_48c77_row3_col2 {\n  background-color: #f7fbff;\n  color: #000000;\n}\n#T_48c77_row1_col0 {\n  background-color: #ebf3fb;\n  color: #000000;\n}\n#T_48c77_row1_col2 {\n  background-color: #eef5fc;\n  color: #000000;\n}\n#T_48c77_row1_col3, #T_48c77_row4_col2 {\n  background-color: #eaf3fb;\n  color: #000000;\n}\n#T_48c77_row1_col4 {\n  background-color: #e6f0f9;\n  color: #000000;\n}\n#T_48c77_row3_col1 {\n  background-color: #f3f8fe;\n  color: #000000;\n}\n#T_48c77_row3_col4 {\n  background-color: #f1f7fd;\n  color: #000000;\n}\n#T_48c77_row4_col0 {\n  background-color: #e5eff9;\n  color: #000000;\n}\n#T_48c77_row4_col1 {\n  background-color: #e2edf8;\n  color: #000000;\n}\n#T_48c77_row4_col3 {\n  background-color: #e3eef9;\n  color: #000000;\n}\n</style>\n<table id=\"T_48c77\">\n  <caption>Dot Product with most similar movies highlighted.</caption>\n  <thead>\n    <tr>\n      <th class=\"index_name level0\" >title</th>\n      <th id=\"T_48c77_level0_col0\" class=\"col_heading level0 col0\" >Toy Story</th>\n      <th id=\"T_48c77_level0_col1\" class=\"col_heading level0 col1\" >Jumanji</th>\n      <th id=\"T_48c77_level0_col2\" class=\"col_heading level0 col2\" >Grumpier Old Men</th>\n      <th id=\"T_48c77_level0_col3\" class=\"col_heading level0 col3\" >Waiting to Exhale</th>\n      <th id=\"T_48c77_level0_col4\" class=\"col_heading level0 col4\" >Father of the Bride Part II</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >title</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n      <th class=\"blank col4\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_48c77_level0_row0\" class=\"row_heading level0 row0\" >Toy Story</th>\n      <td id=\"T_48c77_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n      <td id=\"T_48c77_row0_col1\" class=\"data row0 col1\" >0.061478</td>\n      <td id=\"T_48c77_row0_col2\" class=\"data row0 col2\" >0.027843</td>\n      <td id=\"T_48c77_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n      <td id=\"T_48c77_row0_col4\" class=\"data row0 col4\" >0.093719</td>\n    </tr>\n    <tr>\n      <th id=\"T_48c77_level0_row1\" class=\"row_heading level0 row1\" >Jumanji</th>\n      <td id=\"T_48c77_row1_col0\" class=\"data row1 col0\" >0.061478</td>\n      <td id=\"T_48c77_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n      <td id=\"T_48c77_row1_col2\" class=\"data row1 col2\" >0.042970</td>\n      <td id=\"T_48c77_row1_col3\" class=\"data row1 col3\" >0.063727</td>\n      <td id=\"T_48c77_row1_col4\" class=\"data row1 col4\" >0.147097</td>\n    </tr>\n    <tr>\n      <th id=\"T_48c77_level0_row2\" class=\"row_heading level0 row2\" >Grumpier Old Men</th>\n      <td id=\"T_48c77_row2_col0\" class=\"data row2 col0\" >0.027843</td>\n      <td id=\"T_48c77_row2_col1\" class=\"data row2 col1\" >0.042970</td>\n      <td id=\"T_48c77_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n      <td id=\"T_48c77_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n      <td id=\"T_48c77_row2_col4\" class=\"data row2 col4\" >0.065645</td>\n    </tr>\n    <tr>\n      <th id=\"T_48c77_level0_row3\" class=\"row_heading level0 row3\" >Waiting to Exhale</th>\n      <td id=\"T_48c77_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n      <td id=\"T_48c77_row3_col1\" class=\"data row3 col1\" >0.063727</td>\n      <td id=\"T_48c77_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n      <td id=\"T_48c77_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n      <td id=\"T_48c77_row3_col4\" class=\"data row3 col4\" >0.097764</td>\n    </tr>\n    <tr>\n      <th id=\"T_48c77_level0_row4\" class=\"row_heading level0 row4\" >Father of the Bride Part II</th>\n      <td id=\"T_48c77_row4_col0\" class=\"data row4 col0\" >0.093719</td>\n      <td id=\"T_48c77_row4_col1\" class=\"data row4 col1\" >0.147097</td>\n      <td id=\"T_48c77_row4_col2\" class=\"data row4 col2\" >0.065645</td>\n      <td id=\"T_48c77_row4_col3\" class=\"data row4 col3\" >0.097764</td>\n      <td id=\"T_48c77_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n    </tr>\n  </tbody>\n</table>\n","text/plain":"<pandas.io.formats.style.Styler at 0x7fdf565450a0>"},"exec_count":26,"output_type":"execute_result"}},"pos":68,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"2a9d39","input":"#create the reverse mapping\nindices = pd.Series(snip.index, index=snip['title']).drop_duplicates()\n#print it \nprint(f'The index series looks like this: \\n{indices}')\n\n#if I wanted to get the index from the title I would do this:\nprint(f'The index for Waiting to Exhale is: {indices[\"Waiting to Exhale\"]}')\n      \n","output":{"0":{"name":"stdout","output_type":"stream","text":"The index series looks like this: \ntitle\nToy Story                      0\nJumanji                        1\nGrumpier Old Men               2\nWaiting to Exhale              3\nFather of the Bride Part II    4\ndtype: int64\nThe index for Waiting to Exhale is: 3\n"}},"pos":70,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"595d19","input":"idx = indices[\"Grumpier Old Men\"]\nsim_matrix[idx]","output":{"0":{"data":{"text/plain":"array([0.02784259, 0.04296977, 1.        , 0.        , 0.0656453 ])"},"exec_count":28,"output_type":"execute_result"}},"pos":72,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"e3a22b","input":"sim_scores = list(enumerate(sim_matrix[idx]))\nsim_scores","output":{"0":{"data":{"text/plain":"[(0, 0.02784259039408617),\n (1, 0.0429697729566262),\n (2, 1.0000000000000002),\n (3, 0.0),\n (4, 0.06564529981325365)]"},"exec_count":29,"output_type":"execute_result"}},"pos":74,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"ab3c5f","input":"# Convince Python that this column should be treated like a list, not a string.\ndf['genres'] = df['genres'].apply(literal_eval)","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"f5733f","input":"del sim_scores[idx]\nsim_scores","output":{"0":{"data":{"text/plain":"[(0, 0.02784259039408617),\n (1, 0.0429697729566262),\n (3, 0.0),\n (4, 0.06564529981325365)]"},"exec_count":30,"output_type":"execute_result"}},"pos":76,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"ee51d8","input":"sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\nsim_scores","output":{"0":{"data":{"text/plain":"[(4, 0.06564529981325365),\n (1, 0.0429697729566262),\n (0, 0.02784259039408617),\n (3, 0.0)]"},"exec_count":31,"output_type":"execute_result"}},"pos":78,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"a48a21","input":"top_two = [i[0] for i in sim_scores[0:2]]\nprint(f'The top two indices are: {top_two}')\n\nsnip.iloc[top_two]","output":{"0":{"name":"stdout","output_type":"stream","text":"The top two indices are: [4, 1]\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>Father of the Bride Part II</td>\n      <td>0.0</td>\n      <td>[Comedy]</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>76578911</td>\n      <td>106.0</td>\n      <td>5.7</td>\n      <td>173</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id                        title      budget  \\\n4  11862  Father of the Bride Part II         0.0   \n1   8844                      Jumanji  65000000.0   \n\n                         genres  \\\n4                      [Comedy]   \n1  [Adventure, Fantasy, Family]   \n\n                                            overview    revenue  runtime  \\\n4  Just when George Banks has recovered from his ...   76578911    106.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n\n   vote_average  vote_count  year  \n4           5.7         173  1995  \n1           6.9        2413  1995  "},"exec_count":32,"output_type":"execute_result"}},"pos":80,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"d14815","input":"def content_recommender(df, seed, seedCol, sim_matrix,  topN=2): \n    #get the indices based off the seedCol\n    indices = pd.Series(df.index, index=df[seedCol]).drop_duplicates()\n    \n    # Obtain the index of the item that matches our seed\n    idx = indices[seed]\n    \n    # Get the pairwsie similarity scores of all items and convert to tuples\n    sim_scores = list(enumerate(sim_matrix[idx]))\n    \n    #delete the item that was passed in\n    del sim_scores[idx]\n    \n    # Sort the items based on the similarity scores\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    \n    # Get the scores of the top-n most similar items.\n    sim_scores = sim_scores[:topN]\n    \n    # Get the item indices\n    movie_indices = [i[0] for i in sim_scores]\n    \n    # Return the topN most similar items\n    return df.iloc[movie_indices]","pos":83,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"edd98b","input":"content_recommender(snip, 'Grumpier Old Men', 'title', sim_matrix, 2)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>Father of the Bride Part II</td>\n      <td>0.0</td>\n      <td>[Comedy]</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>76578911</td>\n      <td>106.0</td>\n      <td>5.7</td>\n      <td>173</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id                        title      budget  \\\n4  11862  Father of the Bride Part II         0.0   \n1   8844                      Jumanji  65000000.0   \n\n                         genres  \\\n4                      [Comedy]   \n1  [Adventure, Fantasy, Family]   \n\n                                            overview    revenue  runtime  \\\n4  Just when George Banks has recovered from his ...   76578911    106.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n\n   vote_average  vote_count  year  \n4           5.7         173  1995  \n1           6.9        2413  1995  "},"exec_count":34,"output_type":"execute_result"}},"pos":85,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"829bf7","input":"#reminder again - what's in snip\nsnip = snip.copy()\ndisplay(snip)\n\n#Function that creates a soup out of the desired metadata\ndef create_soup(x):\n    return ' '.join(x['genres']) + ' ' + x['overview'] \n\n#create a column with the soup in it    \nsnip['soup'] = snip.apply(create_soup, axis=1)   \n\n\nprint(f'The soup for Toy Story is: \\n{snip[\"soup\"][0]}')","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15602</td>\n      <td>Grumpier Old Men</td>\n      <td>0.0</td>\n      <td>[Romance, Comedy]</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>0</td>\n      <td>101.0</td>\n      <td>6.5</td>\n      <td>92</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>Father of the Bride Part II</td>\n      <td>0.0</td>\n      <td>[Comedy]</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>76578911</td>\n      <td>106.0</td>\n      <td>5.7</td>\n      <td>173</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id                        title      budget  \\\n0    862                    Toy Story  30000000.0   \n1   8844                      Jumanji  65000000.0   \n2  15602             Grumpier Old Men         0.0   \n3  31357            Waiting to Exhale  16000000.0   \n4  11862  Father of the Bride Part II         0.0   \n\n                         genres  \\\n0   [Animation, Comedy, Family]   \n1  [Adventure, Fantasy, Family]   \n2             [Romance, Comedy]   \n3      [Comedy, Drama, Romance]   \n4                      [Comedy]   \n\n                                            overview    revenue  runtime  \\\n0  Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n2  A family wedding reignites the ancient feud be...          0    101.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n4  Just when George Banks has recovered from his ...   76578911    106.0   \n\n   vote_average  vote_count  year  \n0           7.7        5415  1995  \n1           6.9        2413  1995  \n2           6.5          92  1995  \n3           6.1          34  1995  \n4           5.7         173  1995  "},"exec_count":35,"output_type":"execute_result"},"1":{"name":"stdout","output_type":"stream","text":"The soup for Toy Story is: \nAnimation Comedy Family Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\n"}},"pos":95,"type":"cell"}
{"cell_type":"code","exec_count":36,"id":"ee8b68","input":"\ncount = CountVectorizer(stop_words='english', lowercase=True)\ncount_matrix = count.fit_transform(snip['soup'])\n\n#Compute the cosine similarity score \ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n\n\n#call our same function, using the same movie. \ncontent_recommender(snip, 'Grumpier Old Men', 'title', cosine_sim2, topN=2)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n      <th>soup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n      <td>Adventure Fantasy Family When siblings Judy an...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n      <td>Comedy Drama Romance Cheated on, mistreated an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id              title      budget                        genres  \\\n1   8844            Jumanji  65000000.0  [Adventure, Fantasy, Family]   \n3  31357  Waiting to Exhale  16000000.0      [Comedy, Drama, Romance]   \n\n                                            overview    revenue  runtime  \\\n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n\n   vote_average  vote_count  year  \\\n1           6.9        2413  1995   \n3           6.1          34  1995   \n\n                                                soup  \n1  Adventure Fantasy Family When siblings Judy an...  \n3  Comedy Drama Romance Cheated on, mistreated an...  "},"exec_count":36,"output_type":"execute_result"}},"pos":97,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"8a9625","input":"#let's fetch just the first 5 rows of our dataframe\nsnip = df[:5]\nprint('The first 5 movies are:')\ndisplay(snip)\n\n#let's create a filter that will be True if \"Family\" is in the list of genres for each movie\nhasFamilyFilter = snip['genres'].apply(lambda x: \"Family\" in x)\nprint(f'Family filter values \\n {hasFamilyFilter}')\n\n#let's create a filter that will be True if \"Drama\" is in the list of genres of each movie\nhasDramaFilter = snip['genres'].apply(lambda x: \"Drama\" in x)\nprint(f'Drama filter values \\n{hasDramaFilter}')\n\n#let's filter our dataset to just those movies that have Family OR Drama. Note the placement of the parenthesis\nprint('These movies have drama OR family.')\ndisplay(snip[(hasFamilyFilter) | (hasDramaFilter)])\n\n#let's filter our dataset to just those movies that have Comedy AND Romance OR have a vote_count > 5000.\n#let's use variables for our two genres\nselected1 = 'Romance'\nselected2 = 'Comedy'\n\n#instead of creating stand-alone filters, we'll filter \"on the fly\" using the apply right in the filter\n#again, pay attention to where the parentheses go\nprint('These movies have (Romance and Comedy) OR more than 5000 votes.')\nsnip[(snip['vote_count'] > 5000) | \n     ((snip['genres'].apply(lambda x: selected1 in x)) & \n      (snip['genres'].apply(lambda x: selected2 in x)))]\n","output":{"0":{"name":"stdout","output_type":"stream","text":"The first 5 movies are:\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15602</td>\n      <td>Grumpier Old Men</td>\n      <td>0.0</td>\n      <td>[Romance, Comedy]</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>0</td>\n      <td>101.0</td>\n      <td>6.5</td>\n      <td>92</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11862</td>\n      <td>Father of the Bride Part II</td>\n      <td>0.0</td>\n      <td>[Comedy]</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>76578911</td>\n      <td>106.0</td>\n      <td>5.7</td>\n      <td>173</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id                        title      budget  \\\n0    862                    Toy Story  30000000.0   \n1   8844                      Jumanji  65000000.0   \n2  15602             Grumpier Old Men         0.0   \n3  31357            Waiting to Exhale  16000000.0   \n4  11862  Father of the Bride Part II         0.0   \n\n                         genres  \\\n0   [Animation, Comedy, Family]   \n1  [Adventure, Fantasy, Family]   \n2             [Romance, Comedy]   \n3      [Comedy, Drama, Romance]   \n4                      [Comedy]   \n\n                                            overview    revenue  runtime  \\\n0  Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n2  A family wedding reignites the ancient feud be...          0    101.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n4  Just when George Banks has recovered from his ...   76578911    106.0   \n\n   vote_average  vote_count  year  \n0           7.7        5415  1995  \n1           6.9        2413  1995  \n2           6.5          92  1995  \n3           6.1          34  1995  \n4           5.7         173  1995  "},"exec_count":4,"output_type":"execute_result"},"2":{"name":"stdout","output_type":"stream","text":"Family filter values \n 0     True\n1     True\n2    False\n3    False\n4    False\nName: genres, dtype: bool\nDrama filter values \n0    False\n1    False\n2    False\n3     True\n4    False\nName: genres, dtype: bool\nThese movies have drama OR family.\n"},"3":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8844</td>\n      <td>Jumanji</td>\n      <td>65000000.0</td>\n      <td>[Adventure, Fantasy, Family]</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>262797249</td>\n      <td>104.0</td>\n      <td>6.9</td>\n      <td>2413</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id              title      budget                        genres  \\\n0    862          Toy Story  30000000.0   [Animation, Comedy, Family]   \n1   8844            Jumanji  65000000.0  [Adventure, Fantasy, Family]   \n3  31357  Waiting to Exhale  16000000.0      [Comedy, Drama, Romance]   \n\n                                            overview    revenue  runtime  \\\n0  Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n1  When siblings Judy and Peter discover an encha...  262797249    104.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n\n   vote_average  vote_count  year  \n0           7.7        5415  1995  \n1           6.9        2413  1995  \n3           6.1          34  1995  "},"exec_count":4,"output_type":"execute_result"},"4":{"name":"stdout","output_type":"stream","text":"These movies have (Romance and Comedy) OR more than 5000 votes.\n"},"5":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>overview</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n      <th>year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>862</td>\n      <td>Toy Story</td>\n      <td>30000000.0</td>\n      <td>[Animation, Comedy, Family]</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>373554033</td>\n      <td>81.0</td>\n      <td>7.7</td>\n      <td>5415</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15602</td>\n      <td>Grumpier Old Men</td>\n      <td>0.0</td>\n      <td>[Romance, Comedy]</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>0</td>\n      <td>101.0</td>\n      <td>6.5</td>\n      <td>92</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31357</td>\n      <td>Waiting to Exhale</td>\n      <td>16000000.0</td>\n      <td>[Comedy, Drama, Romance]</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>81452156</td>\n      <td>127.0</td>\n      <td>6.1</td>\n      <td>34</td>\n      <td>1995</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"      id              title      budget                       genres  \\\n0    862          Toy Story  30000000.0  [Animation, Comedy, Family]   \n2  15602   Grumpier Old Men         0.0            [Romance, Comedy]   \n3  31357  Waiting to Exhale  16000000.0     [Comedy, Drama, Romance]   \n\n                                            overview    revenue  runtime  \\\n0  Led by Woody, Andy's toys live happily in his ...  373554033     81.0   \n2  A family wedding reignites the ancient feud be...          0    101.0   \n3  Cheated on, mistreated and stepped on, the wom...   81452156    127.0   \n\n   vote_average  vote_count  year  \n0           7.7        5415  1995  \n2           6.5          92  1995  \n3           6.1          34  1995  "},"exec_count":4,"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"17a2fb","input":"#in steps\n#convert the genres list in a series of columns\nstep1 = snip.apply(lambda x:pd.Series(x['genres']),axis=1)\nprint(f\"Step 1\\n{step1}\")\n\n#this step converts the rows into columns and \"stacks\" them all together\nstep2 = step1.stack()\nprint(f\"Step 2\\n{step2}\")\n\n#let's get just the unique values from this series\nstep3 = step2.unique()\nprint(f\"Step 3\\n{step3}\")\nprint(f\"Step 3 is a \\n{type(step3)}\")\n\n#numpy arrays can be joined just like lists, so let's join it to create a comma-delimited string\nstep4 = ', '.join(step3)\nprint(f\"Step 4\\n{step4}\")\n\n#let's do it all in one step\nallGenres = ', '.join(snip.apply(lambda x:pd.Series(x['genres']),axis=1).stack().unique())\nallGenres","output":{"0":{"name":"stdout","output_type":"stream","text":"Step 1\n           0        1        2\n0  Animation   Comedy   Family\n1  Adventure  Fantasy   Family\n2    Romance   Comedy      NaN\n3     Comedy    Drama  Romance\n4     Comedy      NaN      NaN\nStep 2\n0  0    Animation\n   1       Comedy\n   2       Family\n1  0    Adventure\n   1      Fantasy\n   2       Family\n2  0      Romance\n   1       Comedy\n3  0       Comedy\n   1        Drama\n   2      Romance\n4  0       Comedy\ndtype: object\nStep 3\n['Animation' 'Comedy' 'Family' 'Adventure' 'Fantasy' 'Romance' 'Drama']\nStep 3 is a \n<class 'numpy.ndarray'>\nStep 4\nAnimation, Comedy, Family, Adventure, Fantasy, Romance, Drama\n"},"1":{"data":{"text/plain":"'Animation, Comedy, Family, Adventure, Fantasy, Romance, Drama'"},"exec_count":5,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"d88d9b","input":"#this is a test dataframe to use\nsa1_df = pd.DataFrame({\n        'Food': ['Cake', 'Pie', 'Ice Cream'],\n        'Flavors': [['Chocolate','Vanilla', 'Marble'], ['Apple', 'Chocolate', 'Cherry'], ['Vanilla', 'Cherry', 'Mint']]\n    })\ndisplay(sa1_df)\n\n#note that Python already thinks we have lists in the flavor column, so we don't need literal_eval\nprint(f\"Each flavor cell is already of type {type(sa1_df['Flavors'][0])}\")","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Food</th>\n      <th>Flavors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cake</td>\n      <td>[Chocolate, Vanilla, Marble]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pie</td>\n      <td>[Apple, Chocolate, Cherry]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ice Cream</td>\n      <td>[Vanilla, Cherry, Mint]</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"        Food                       Flavors\n0       Cake  [Chocolate, Vanilla, Marble]\n1        Pie    [Apple, Chocolate, Cherry]\n2  Ice Cream       [Vanilla, Cherry, Mint]"},"exec_count":6,"output_type":"execute_result"},"1":{"name":"stdout","output_type":"stream","text":"Each flavor cell is already of type <class 'list'>\n"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"2a6643","input":"#fetch C from the whole dataset\nC = df['vote_average'].mean()\nprint(f\"C is {C}\")\n\n#fetch m from the whole dataset\nm = df['vote_count'].quantile(.8)\nprint(f\"m is {m}\")\n\n#filter to movies that have greater than or equal to 80% of the votes\ndf = df[df['vote_count'] >= m]\n\n#see how many movies are left.\ndf.shape","output":{"0":{"name":"stdout","output_type":"stream","text":"C is 6.069160000000003\nm is 255.20000000000027\n"},"1":{"data":{"text/plain":"(1000, 10)"},"exec_count":8,"output_type":"execute_result"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"6279a8","input":"def weighted_rating(x, m, C):\n    v = x['vote_count']\n    R = x['vote_average']\n    # Compute the weighted score\n    return (v/(v+m) * R) + (m/(m+v) * C)","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"05d4c7","input":"### Alternative to prompting for user input\n\nUsing `input()` is fine for an application, but if you're just trying to test your recommender system it's easier to pass in the arguments.  Here we've rewritten so that the default inputs are `None` and the user will be prompted for input, but the arguments can be passed to the function to allow for easier testing.","pos":41,"type":"cell"}
{"cell_type":"markdown","id":"08f2ae","input":"Because we have such a small matrix, we can actually print it and take a peek at what's going on in there. In order to print a tfidf matrix, we need to convert it to something that can be displayed.\n\n*Note: You won't need to do this bit in your homework or self-assessment, but it's helpful in understanding what we have.*","pos":59,"type":"cell"}
{"cell_type":"markdown","id":"0c38a3","input":"Now you can see we have just 4 features, with both document 1 and document 3 containing a reference to \"bee.\" Lemmatization might be important if you're including free-form text. You would not need to use lemmatization if you were using standard metadata, such as keywords or genres. When using that kind of standard vocabulary, you should already have a smaller number of features and the words should be consistent across your rows of data.\n\nLike many things in Data Science, there's no one \"right\" answer about how much to pre-process your data. Sometimes, the best thing you can do is try out different approaches and see which ones seem to work the best.\n\n### Term Frequency-Inverse Document Frequency\nThe Term Frequency Inverse Document Frequency Vectorizer works exactly the same way as the Count Vectorizer. Let's do some data cleaning of the \"overview\" column of our snip data set and create a Tfidf matrix. Since this is free-form text, we'll lemmatize the words, remove stop words and punctuation and convert to lowercase. Let's also use the max_features parameter (available in both Tfidf and Count vectorizers) to limit the features to the top 100.","pos":57,"type":"cell"}
{"cell_type":"markdown","id":"135d71","input":"## *Self-Assessment: Metadata Recommender*\n\nUsing the Ted Talks data, create a content recommender using the \"ratings\" and \"tags\" columns as your features. These columns include multi-word phrases, so use Banik's sanitize function on those two columns. Use a count vectorizer, removing English stop words and converting to lowercase, to create your vectorized matrix. Use cosine_similarity to compute your similarity matrix. Return the top 5 talks most closely related to the **title** \"Humble plants that hide surprising secrets.\"\n","pos":99,"type":"cell"}
{"cell_type":"markdown","id":"1fbcd5","input":"When we print out this matrix, we can see that \"afraid\" is an important word in the description of Toy Story, but not in any of our other movies. But \"wedding\" is important in both Grumpier Old Men and Father of the Bride.\n\nIf we create a heatmap of the features, we can visually scan to see which movies are more similar. Similar movies would have similar patterns of colors. Which movies look most similar? Which movies look the most different?","pos":61,"type":"cell"}
{"cell_type":"markdown","id":"261bf3","input":"# Knowledge-Based Recommender\n\nThe knowledge-based recommender is just a simple ranked chart of data built using some input from the user. Banik describes it as a recommender that:\n1. Gets user input on their preferences.\n2. Extracts all the records that match the conditions set by the user.\n3. Calculates a score to sort the records.\n4. Returns the sorted results.\n\n\n## The Data\nLike most data science projects, preparing/wrangling/cleaning your data for your recommender system can be the hardest part. In the lessons and homework, we'll be providing you data that has already been simplified to some extent, so we can focus more on the concepts of recommender systems. For our knowledge-based recommender, we're going to be using the movies_metadata_clean.csv file in the data directory of the lesson. If you'd like to see how we got to this file from the movies_metadata.csv file used in the book, please review the \"DataCleaning\" notebook in the extras directory.","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"263b2e","input":"### *Self-Assessment: TF-IDF Vectors*","pos":87,"type":"cell"}
{"cell_type":"markdown","id":"27a1e3","input":"Let's test our recommender with Grumpier Old Men and our snipped dataset again.","pos":84,"type":"cell"}
{"cell_type":"markdown","id":"2b1d55","input":"Of note here is the the *length* of the vector doesn't matter when we're dealing with cosine similarity - only the angle between the two vectors matters. So, our red and blue movies score nearly a perfect match, even though the red movie is arguably a more comedic movie than the blue movie. That's just how these similarity measures work.\n\n### Dot Product (linear_kernel) vs. Cosine Similarity\nBanik briefly mentions this, but it bears repeating. If you have data that's already normalized so that all the scores share the same magnitude, such as what happens with TfidfVectorizer (where each score is between 0 and 1), you can use the computationally cheaper dot product calculation using linear_kernel(). If you're using the CountVectorizer, you have to use the cosine similarity function - cosine_similarity() -  which will normalize your data before calculating your vector distances.  e\n\nIf you want to dive into the math of all this, the book \"Practical Recommender Systems\" by Kim Falk does a nice job of explaining and diving much deeper into these concepts.\n\nWith our snip dataset, we've constructed our vector matrix using Tfidf, so we can use the linear_kernel()/dot product method to get our similiarity scores.","pos":67,"type":"cell"}
{"cell_type":"markdown","id":"2d1547","input":"### *Self-Assessment: Pandas*","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"30de58","input":"## Creating a metric\nKnowledge-based recommenders rely on some sort of score for returning their results. There's no right answer for what the score is or how it should be calculated. You'll need to consider the data that you're working with and decide how to calculate a meaningful score. If you are running an e-commerce site, you might use products with the highest percent off sale. If you're recommending library books, you might use a score built off of the number of times the book has been checked out, weighted by the number of weeks since it was first in circulation.\n\nFor this example, we're interested in highly-rated movies. But, it makes sense to consider both the average rating for a movie and the number of people that rated the movie. Say you have a rating scale from 1 to 5 stars. Your highest average rating would be 5 - a perfect score. But does a rating of 5 by one user mean the same thing as a rating of 5 by 100 users? Probably not.\n\nBanik solves this problem by using the IMDB weighted rating. \n\n$$Weighted Rating (WR) = \\left(\\frac{v}{v+m} * R\\right) + \\left(\\frac{m}{v+m}*C\\right)$$\n \nWhere:\n* v is the number of votes garnered by the movie\n* m is the minimum number of votes required for the movie to be in the chart (the prerequisite)\n* R is the mean rating of the movie\n* C is the mean rating of all the movies in the dataset\n\nBanik chose the 80th percentile for the minimum number of votes to be included in the recommender. \n\nNote that Banik chooses m (our minimum number of votes) based on the whole dataset, because IMDB sets this as the minimum threshold for being included in the ratings. So m is both a part of the metric AND a filter.\n\nLet's also base C on the whole dataset to start.\n\nLet's fetch C and m and filter to movies that have vote_counts greater than or equal to the 80th quantile. (This is equivalent to getting the top 20% of votes.) ","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"3a871e","input":"# Content-Based Recommender using MetaData","pos":93,"type":"cell"}
{"cell_type":"markdown","id":"3f1c99","input":"Recommender Systems are a complicated topic. This week's lesson and next week's lesson are intended to just give you a small taste of what recommender systems can do. To truly implement a recommender system, you'd want to dive much deeper. It's a topic worthy of more study. Recommender systems are all around you. Let's explore one recommender system you're probably familiar with, Netflix. \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/L0qVVRJoCf0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nThis week we'll look at two types of recommenders: Knowledge-Based Recommenders and Content-Based Recommenders. These systems are both used to address the \"cold-start\" problem. The cold-start problem is the idea that when you first launch a recommender site, you probably don't have data about what a user likes or how your items have been rated by other users. This lack of data makes it difficult to return really good recommendations, as most of the best recommenders rely on having ratings data. It also makes it impossible to quantify the quality of your recommendations. If you were building recommenders like this in real life, you might want to do some user-testing to validate if your recommender system is making good suggestions. Here, we'll just rely on our own best judgement.","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"3f9a66","input":"Let's write our function to do scoring. Note that unlike Banik's metric, our version takes in x (the row of data) and m & C. Passing all the variables you need into the the function is a best practice that Banik does not follow, but we do.","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"461709","input":"By adding in n-grams, we went from 5 features to 8 features. Note that this is a very small corpus of text. If we were analyzing large bodies of text, adding in n-grams can increase your feature space very quickly. Be cautious about using n-grams if you're working with large datasets. But, if you know your text has a lot of meaningful phrases, it might be an approach worth considering, particularly if you're getting poor results from single words.\n\n#### Lemmatization\nFinally, let's look at lemmatization. Lemmatizing a word means reducing it to its root word. For example, the root word for the verb \"is\" is \"be.\" Roots for nouns are generally the singular form of the word. Root forms of verbs tend to be the present-tense form. Adding lemmatization is a bit more complicated. We need to create a custom tokenizer. The tokenizer is what the vectorizers use to chunk up the text into tokens (typically single words). We'll create a tokenizer that converts the words to their lemmas (root words) before the vectorizer creates the matrix. Don't panic. We're giving you the code here. There are two bits - one cell that you'd only need once and shouldn't have to alter at all, and then the code to actually set up the vectorizer, and call the fit_transform, which would only require passing in different data.","pos":54,"type":"cell"}
{"cell_type":"markdown","id":"4ac464","input":"How many talks are in the TED Talks data frame?","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"4fb754","input":"If we imagine here the the X axis represents \"Comedy\" and the Y axis represents \"Action\", our green arrow might represent a movie that is action-packed and a little bit funny. Our red arrow might be something with just a little action and a lot of comedy. Our blue movie is somewhere right in between. Our black arrow is the exact opposite of our red arrow, and probably represents a slow-moving, serious movie. \n\nWhen we quantify this with cosine similarity, we end up with a number for each pair of movies that's somewhere between -1 (total opposites) and 1 (exactly the same). Let's look at the cosine similiarity between some of our paris of movies.","pos":65,"type":"cell"}
{"cell_type":"markdown","id":"50efe4","input":"Let's also break down what's going on with converting our cosine similarity to a list of tuples. \n\nThe first thing we're doing is getting the row from the matrix that corresponds to the movie we want to review. Let's say we want to review Grumpier Old Men. Let's use the reverse mapping to get the index, and then fetch that row from our matrix.","pos":71,"type":"cell"}
{"cell_type":"markdown","id":"56fdb7","input":"# Content-Based Recommender\n\nThere are a number of different approaches to doing content-based recommenders. What they all share is that they use some method to:\n* select and clean text\n* convert text to a numerical representation\n* use the numerical representation of the text to assign similarity scores between each pair or set of items.\n\nOnce our pairs of items are scored, given one \"seed\" item, we can then recommend items that are similar to that item.\n\nLet's break this down into steps. \n\n## Selecting and Cleaning Text\nBanik talks about either using metadata or descriptions as the text that represents your item. This is a bit of a simplification. Really you could use any text, or any combination of text, that you have available to you. You should put time and effort into deciding what text you'll use. Consider which textual elements best represent the essence of the items you're recommending. Here's where that user testing comes into play. Maybe you write two recommenders - one using metadata and one using descriptions and you get your family and friends to sit down and review the recommendations that they receive using each approach. Is one better than the other? Does one recommend entirely inappropriate things? (We've all heard the stories about recommender systems gone wrong.)\n\nWhatever text you use, you most likely want to do some pre-processing of the text first. This step is referred to as \"cleaning\" the text. There are many, many possible steps you can take here. We'll demonstrate just a few of them. Banik doesn't really discuss this bit, but we think it's too important to gloss over. Here's a non-exhaustive list of things to consider doing to your text, once you've decided which bits of text you're going to use.\n\n1. Converting it to lowercase.\n2. Removing punctuation.\n3. Stemming or Lemmatization.\n4. Using N-grams or combining words.\n5. Identifying and using specific parts of speech.\n\nEntire courses have been written about natural language processing. We can't get into all the details, so we'll focus on just a few steps that you can take that integrate well with scikit learn's CountVectorizer and TfidfVectorizer - converting to lowercase, removing punctuation, lemmatizing (converting words to their \"root\" word), and n-grams. Remember, a CountVectorizer creates a matrix of all the words available in the text, and *counts* each occurrence of each word. Banik does a nice job explaining this so we won't delve too deeply into it here. We'll loop back to TfidfVectorizer in a bit.\n\n### Converting to lowercase, removing stop words, and removing punctuation.\nThese are by far the easiest. The vectorizers automatically remove most punctuation. Converting to lowercase is the default setting for both of the vectorizers. And removing a standard set of stop words can be done just by adding one parameter. We'll add both parameters explicitly just so you can see what happens. First we need some data to play with. Let's set that up. Here we're creating a dataframe with three \"documents\" and setting the index of the documents to the ID column.\n","pos":48,"type":"cell"}
{"cell_type":"markdown","id":"5943e4","input":"Let's wrap this up in a function. We're going to do this slightly differently than Banik did. \n* We'll avoid giving it any variable defaults (which is a good practice unless you're hard-coding the defaults).\n* We'll pass in the string to identify the seed column and get the indices mapping inside the function. (The seed column is whatever column we're using to identify the item we're interested in using to recommend other items. In this case, it's a movie title. But it could be a place name, or a recipe title, or whatever, depending on our recommender.)\n* We'll also pass in the number of results to return. This is hard-coded number, so we will set a default for that.\n* We'll delete the passed-in movie explicitly, instead of assuming it's the first after sorting\n* We'll return the whole dataframe, not just the titles","pos":82,"type":"cell"}
{"cell_type":"markdown","id":"5ddea3","input":"We can see that genres looks like a list. To get Python to treat it like a list, we'll need to apply literal_eval","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"670925","input":"In the absence of numerical ratings here, use the ratio of the number of comments per 1000 views as a metric to sort the TED talks and print the 10 with the highest ratios.  \n\nDisplay only the description, the main speaker, and the number of views.","pos":32,"type":"cell"}
{"cell_type":"markdown","id":"714f33","input":"Select TED talks with these prerequisites:\n\n1. talks with duration of at least 5 minutes (i.e. 300 seconds)\n2. talks with only 1 speaker\n3. talks in the top 90\\% of views (exclude the bottom 10\\%)\n\nAlso inspect the number of talks that made the cut.","pos":29,"type":"cell"}
{"cell_type":"markdown","id":"748b6c","input":"<p><font size=18>Week 13: Recommender Systems 1</font></p>","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"793c42","input":"You can see that after creating the matrix, we end up with five \"features\" - five unique words that hopefully provide some meaning. All of the prepositions, pronouns and articles were removed by applying the stop words. \n\n#### N-Grams\nWhat if we were interested in 2-word phrases. \"Queen bee\" has a different meaning than either queen or bee alone. Multi-word phrases are called n-grams, and the \"n\" can be replaced with any number. We could have bigrams (2-word phrases), trigrams (3-word phrases), and so-on. To use n-grams with either of our scikit-learn vectorizers, we add the ngram_range parameter, and we give it a tuple indicating the shortest and longest phrase we're interested in considering. Let's try an n-gram of 1 or 2 word phrases.","pos":52,"type":"cell"}
{"cell_type":"markdown","id":"7e79f5","input":"Load the data set **ted_clean.csv** and display the first 5 rows. This data set can be found in the data folder for this lesson.  More information about this data set <a href = https://www.kaggle.com/rounakbanik/ted-talks> here </a>.  ","pos":24,"type":"cell"}
{"cell_type":"markdown","id":"81908f","input":"For this example we will use the TED Talks data set that you have already loaded to build a knowledge-based recommender by soliciting the desired publication year and word rating from the user. We've already extracted the year from the publish date and set up the ratings column as a list of words. (You'll still need to apply literal_eval to it, if you didn't already. Do that outside of your function in a separate cell. If you apply literal_eval twice, it will cause an error.) \n\n1. Print a list of the descriptive word ratings for the user to choose from. (*Hint: follow the directions in this lesson.*)\n\n2. Ask the user to enter answers to the following questions:\n\n    - Enter a descriptive word for rating.\n    - Enter the earliest year published for the talk (between 2006 and 2017).\n    - Enter the latest year published for the talk (between 2006 and 2017).\n\n3. Consider only talks with the top 90% of views (after filtering based on user preferences).\n\n4. Display the top 5 recommended talks according to the \"comments per 1000 views\" ratio (calculated AFTER doing steps 2 & 3).\n\n5. Display only the main speaker, the name of the talk, the year published, and the comments per thousand views ratio.\n\n6.  Show the results for the word rating \"obnoxious\" and published years between 2009 and 2014.","pos":46,"type":"cell"}
{"cell_type":"markdown","id":"964d37","input":"### *Self-Assessment: Load and Display*","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"9cc7d0","input":"### Avoiding \"Explode\"\nBanik would have you \"explode\" the genres. He does this to make it easier to filter on the genres column, but it has an unfortunate side effect of making duplicate rows per movie. It's easy to avoid that by using a different method of filtering. Let's see how that works.","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"9df87f","input":"What happens if use C from just the filtered dataframe?","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"a88fa8","input":"### Recommender Function","pos":81,"type":"cell"}
{"cell_type":"markdown","id":"a95369","input":"### Fetching unique values from a column of lists\nThe one other thing we need to be able to do where the exploding helps is to get the list of unique genres. Let's look at how we could do that. We'll do it slightly differently than Banik. And, we'll first break it down into steps so you can see what's happening.","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"a98e72","input":"We'll test our code by requesting movies that have the genres 'Family' and a runtime between 80 and 120 minutes and a year between 1980 and 2000. We'll return the output to a variable so we can review it in different ways.  This time we will simply pass the inputs through the function call:","pos":43,"type":"cell"}
{"cell_type":"markdown","id":"a9c8e6","input":"We have two other versions of scores in the dataset. Let's compare the rankings if we sort in different ways.","pos":38,"type":"cell"}
{"cell_type":"markdown","id":"ac53e0","input":"Compute the dot product score for all of the TED talks in the data frame. Next build the recommender to request the name of a TED talk in the data frame and provide the top 5 recommended talks based on the similarity of the descriptions with the name of the talk supplied.\n\nShow that it works by getting the top 5 recommended talks that are similar to the talk named \"Tyler Cowen: Be suspicious of simple stories\" (from the **name** column of the data frame).","pos":91,"type":"cell"}
{"cell_type":"markdown","id":"b3d4e4","input":"We can see that column 4 and column 1 of our matrix contain our 2 most similar movies. But, what movies are those? We need to go back to our dataframe to figure that out. Let's extract just the indices for our top 2 movies. Finally, we'll use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html\">iloc</a> to find the corresponding movie titles.","pos":79,"type":"cell"}
{"cell_type":"markdown","id":"b5924e","input":"### Computing Cosine Similarity\nVisually looking for similarities doesn't really work well for very many items. Instead, let's determine how similar each movie is to each other movie mathematically. We'll use cosine similarity to do that. Cosine similarity compares the direction of vectors in multi-dimensional space. The less angle between each vector, the higher the cosine-similarity score. What now? Yep, it's a lot to wrap your head around. Just remember that each row of our matrix can be thought of as a vector that can be plotted in multi-dimensional space. It's easier if we think about a 2 dimensional problem. Let's say we had 2 characteristics and 4 movies that we've scored based on those characteristics. If we plot those on a graph and draw a line from the origin (0,0) through their score points, we'd have a vector for each of the characteristics pointing in specific directions. Let's look at an example.","pos":63,"type":"cell"}
{"cell_type":"markdown","id":"b62a16","input":"We can see that the most similar movie to Grumpier Old Men is... Grumpier Old Men. This makes sense - it's the same movie! We don't want that movie in our results, though. Since we know this is a balanced matrix (the indexes are the same for the columns and for the rows), we can just delete the item with our Grumpier Old Men index. Remember, that's 2. Let's see how that works.","pos":75,"type":"cell"}
{"cell_type":"markdown","id":"c00a26","input":"### *Self-Assessment: Prerequisites*","pos":28,"type":"cell"}
{"cell_type":"markdown","id":"c40068","input":"Note that what we get is a matrix (which we've converted to a colored dataframe for display) that scores each movie in relation to another movie. A movie scored with itself will always be a one. Note that in our dataset here, Waiting to Exhale and Grumpier Old Men are our least similar two movies. Does that track with what you see in the heatmap above? Does that track with what you know of those two movies?\n\nWhich two movies are most similar?\n\n## Using the Similarity Matrix\nNow that we have this matrix, we need to be able to use it to identify similar movies. Let's break down some of what Banik does.\n\n### Getting Index from Title\nBanik uses a reverse mapping of indexes and titles to fetch data from the cosine similarity matrix. Let's take a look at what that is doing.","pos":69,"type":"cell"}
{"cell_type":"markdown","id":"c59b6a","input":"You can see that it does indeed make a difference in the score. But would it make a difference in our recommendations?","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"cb2dce","input":"We mentioned at the beginning that you could use any text you have available. But so far, we've only demonstrated using free-form text - like a description, synopsis, or overview. You can also use metadata that comes from more defined and finite lists. Banik demonstrates this with keywords and credits and we have that code for you in the Content Based Recommenders file in this directory. \n\nThere are some things consider when using the metadata to generate your list of features. First, if you have multiple metadata fields, you'll probably want to combine them. Banik calls this combined list of words the \"soup.\" I think he's thinking of alphabet soup here, since we're throwing all the words together and stirring them up. That might be fine if each of your categorical lists of words are single words. But if you have categories that include phrases, you should consider pre-processing the phrases in such a way that the spaces between your words in the phrases are removed. For instance, remembering what you've learned so far, think about what would happen if you had the following records:\n\n| Business      | Keywords                 |\n| ------------- | ------------------------ |\n| McDonald's    | Fast Food, High Volume   |\n| MJ's Finest   | High Prices, Upscale |\n| Panera        | Fast Casual              |\n\nIf we were to vectorize the keywords as-is, we'd end up with the following words: fast, food, high, volume, prices, upscale, casual. But we'd lose the differentiation between high-volume and high-prices and fast-food and fast-casual. Banik uses \"sanitizing\" to prevent this kind of ambiguity. The sanitizing function is available in the book and in the Content Recommender chapter notebook.\n\nWe can also demonstrate the basic principles with our snip dataset. We already have our genres in a list and none of our snip movies have more than 3 genres and each of our genres are only 1 word. So we don't have to generate lists or sanitize anything. We simply need to create a soup of our overview and our genres.\n\nNote: genres is a list, so we'll need to use ' '.join() to turn it into a string. Overview is a string, so we just need to add that string onto the end of the string created after ' '.join()ing the genres. Be sure to add a space in between.","pos":94,"type":"cell"}
{"cell_type":"markdown","id":"d006d8","input":"## Getting User Input\nNow that we've seen the pieces of the knowledge-based recommender, all we need to do is wrap the pieces in a function that accepts user input.\n\nOur function will take in a cleaned dataframe and a percentile to use for m. By default, the percentile will be .8. \n\nNote that the only changes we're making here from Banik's metric is to adjust how we do the genres filter. We'll follow Banik's lead by calculated m after we filter the data to the user's selections.","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"d5f59a","input":"Banik used a count vectorizer instead of a tf-idf vectorizer for his metadata recommender. He does this because using a tf-idf would downweight actors that appear in more than one movie. The same thing would happen with genres. So we'll follow suit and use the count vectorizer here. We'll remove stopwords and convert to lowercase and remove punctuation, but we won't use n-grams or lemmatization here.\n\nYou can read <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">the documentation for count_vectorizer</a> to learn more about it.","pos":96,"type":"cell"}
{"cell_type":"markdown","id":"d73d11","input":"### *Self-Assessment: Create the Knowledge-Based Recommender*","pos":45,"type":"cell"}
{"cell_type":"markdown","id":"d85ae9","input":"The <a href=\"https://book.pythontips.com/en/latest/enumerate.html\">enumerate function</a> loops over some iterable object and returns a counter and the value for each item in the iterable. We can see that what cosine_sim[2] returns is an array, which is an iterable object. We can't directly print the results from enumerate, so we have to wrap it in a list function.\n\nWhat this results in is a list of tuples that correspond to the column number and the cosine similarity score for each movie that we compared to Grumpier Old Men. Which column number would be Grumpier Old Men compared with itself?","pos":73,"type":"cell"}
{"cell_type":"markdown","id":"dfeb08","input":"Great. That got rid of the tuple that corresponded to the column Grumpier Old Men.\n\nThe next thing we do is to sort this list by the score (the second bit of the tuple). We're using a lambda function to do that. Let's see what we get when we sort.","pos":77,"type":"cell"}
{"cell_type":"markdown","id":"e5c092","input":"### *Self-Assessment: Create the Content-Based Recommender Based on Dot Product*","pos":90,"type":"cell"}
{"cell_type":"markdown","id":"e85bb7","input":"### *Self-Assessment: Modularize Fetching Unique Items*\n\nGetting a unique list of items from a Pandas column that contains lists is exactly the kind of thing you might have to do fairly often. Even though Pandas makes this fairly easy, let's modularize the code. Write a function that takes in a dataframe, the name of the column from which to pull unique lists, a type parameter to determine if you should return a numpy array or a string, and a True/False sort parameter to determine if the <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.sort.html\">returned list should be sorted</a>. Use the provided code below to get you started.","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"e8f43e","input":"Let's apply the score to the unfiltered dataframe.","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"ea8d65","input":"## Content-Based Recommender Self Assessment\n\nFor this example we will use the TED Talks data set that you have already loaded to build a content-based recommender based on the descriptions of the talks.  This will correspond to the **plot description-based recommender**.","pos":86,"type":"cell"}
{"cell_type":"markdown","id":"eb9f0e","input":"Did the different methods of computing the score impact the recommendation results in a significant way?","pos":40,"type":"cell"}
{"cell_type":"markdown","id":"ec43fd","input":"We'll test our code by requesting movies that have the genres 'Family' and a runtime between 80 and 120 minutes and a year between 1980 and 2000. We'll return the output to a variable so we can review it in different ways. (Don't worry if your saved code has extra boxes or looks out of order. That's just a bug in CoCalc's output saving.)","pos":36,"type":"cell"}
{"cell_type":"markdown","id":"f6e119","input":"### *Self-Assessment: Compute a Metric, Sort and Print*","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"f81104","input":"When we set up the CountVectorizer, we'll tell it that we want it to convert everything to lowercase and we want to remove stop words. Then we'll fit_transform the text using the Count Vectorizer. That's where the magic happens. Calling fit_transform and passing in our data will create the sparse matrix of words and counts. Finally, we'll just convert it to a dense matrix for easy display.","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"fca724","input":"From the original TED Talks data frame that use in this lesson, create the TF-IDF (term frequency - inverse document frequency) matrix from the descriptions of the talks.  The TF-IDF is high where a rare term is present or frequent in a document and TF-IDF is near zero where a term is absent from a document, or abundant across all documents.\n\nThe feature name in the data frame is **description**.\n\nPreprocess the description column by using lower case letters, removing punctuation, removing the default English stop words, and using only bigrams.\n\nOutput the shape of the TF-IDF matrix you create. The number of rows corresponds to the number of TED talks in the data frame and the number of columns represents the number of unique terms. ","pos":88,"type":"cell"}
{"cell_type":"markdown","id":"fe3460","input":"Even with this tiny dataset, switching between TF-IDF and CountVectorizer and the linear kernel and the cosine-similarity changed our top two results.\n\nIt's worth trying different approaches with your data to determine the right fit.","pos":98,"type":"cell"}
{"id":0,"time":1661546661344,"type":"user"}
{"last_load":1661546664373,"type":"file"}