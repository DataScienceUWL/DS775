{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-439504db-bc3e-4ec8-a01c-0ac2c7789466.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1630371096747,"exec_count":9,"id":"5522fb","input":"from sklearn.gaussian_process import GaussianProcessRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nfrom warnings import catch_warnings\nfrom warnings import simplefilter\nfrom scipy.optimize import minimize_scalar\n\nimport numpy as np\n\ndef objective(x, noise_level = 0.0 ):\n    y = x * np.sin(x) + np.random.normal(loc=0,scale=noise_level)\n    return(float(y))\n\n\nX = np.array([0,2,4,7,9]).reshape(-1,1)\ny = np.asarray([objective(x) for x in X])\n\n# define the model\nmodel = GaussianProcessRegressor()\nmodel.fit(X,y)\n\n# surrogate or approximation for the objective function\ndef surrogate(X, model):\n    # catch any warning generated when making a prediction\n    with catch_warnings():\n        # ignore generated warnings\n        simplefilter(\"ignore\")\n        return model.predict(X, return_std=True)\n    \ndef acquisition_fun_lcb(X, model, kappa):\n    x2 = np.array(X).reshape(-1,1)\n    y,sd = surrogate(x2, model)\n    y = y.reshape(-1,1)\n    sd = sd.reshape(-1,1)\n    out = (y-kappa*sd).flatten()\n    return( out )\n\ndef acquire_next_point(model, kappa):\n    # this approach works only for one-dimensional function\n    result = minimize_scalar(acquisition_fun_lcb, bounds=[0,10],method='bounded',args = (model, kappa) )\n    return result.x[0]\n\ndef plot_bayesian_opt(X,y,model,objective, noise = 0, kappa = 1):\n    X_plot = np.arange(0,10,.05).reshape(-1,1)\n    y_obj = np.asarray([objective(x, noise_level = noise) for x in X_plot])\n    y_surrogate, sd = surrogate(X_plot, model)\n    y_surrogate = y_surrogate.reshape(-1,1)\n    sd = sd.reshape(-1,1)\n    plt.plot(X,y,'m.',markersize=20,linestyle='',label='Sampled Points')\n    plt.plot(X_plot, y_obj,'g--',label='Actual Function')\n    plt.plot(X_plot, y_surrogate,'b',label='Surrogate Function')\n    plt.plot(X_plot, y_surrogate-kappa*sd,'r',label='Acquisition Function')\n    plt.fill_between(X_plot.flatten(),(y_surrogate+kappa*sd).flatten(),(y_surrogate-kappa*sd).flatten(),color='blue',alpha=0.1,label='Uncertainty')\n    \nplot_bayesian_opt(X,y,model,objective,kappa = 10)\nplt.legend()","kernel":"python3","output":{"0":{"data":{"text/plain":"<matplotlib.legend.Legend at 0x7efc7517ffa0>"},"exec_count":9},"1":{"data":{"image/png":"31c050c1072fac773b3c00a34fb781acd6bdbd33","text/plain":"<Figure size 864x504 with 1 Axes>"},"metadata":{"image/png":{"height":411,"width":721}}}},"pos":28.4,"start":1630371096192,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"3fe569","input":"","pos":28,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"03eb2e","input":"np.random.seed(42) #adding random seed here, too, for the noise factor\n#call the optimization.\nres = gp_minimize(neg_objective,                  # the function to minimize\n                  [(0.0,1.0)],      # the bounds on each dimension of x\n                 # acq_func=\"PI\",      # the acquisition function - using PI like above\n                  n_calls=15,         # the number of evaluations of the objective function\n                  n_random_starts=5,  # the number of random initialization points\n                  random_state=42)   # the random seed\n\n\"x=%.4f, f(x)=%.4f\" % (res.x[0], res.fun)","output":{"0":{"data":{"text/plain":"'x=0.8973, f(x)=-0.9735'"},"exec_count":10,"output_type":"execute_result"}},"pos":47,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"36a02e","input":"from skopt.plots import plot_convergence\nplot_convergence(res);","output":{"0":{"data":{"image/png":"4df4297cd1c9f0603aed37fdea51e6f0856babe8","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":11,"metadata":{"image/png":{"height":386,"width":506},"needs_background":"light"},"output_type":"execute_result"}},"pos":49,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"49925f","input":"plt.rcParams[\"figure.figsize\"] = (10, 18)\n\n\ndef f_wo_noise(x):\n    return neg_objective(x, noise=0)\n\nfor n_iter in range(10):\n    # Plot true function.\n    plt.subplot(10, 2, 2*n_iter+1)\n\n    if n_iter == 0:\n        show_legend = True\n    else:\n        show_legend = False\n\n    ax = plot_gaussian_process(res, n_calls=n_iter,\n                               objective=f_wo_noise,\n                               noise_level=noise_level,\n                               show_legend=show_legend, show_title=False,\n                               show_next_point=False, show_acq_func=False)\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"\")\n    # Plot acquisitionFunction(x)\n    plt.subplot(10, 2, 2*n_iter+2)\n    ax = plot_gaussian_process(res, n_calls=n_iter,\n                               show_legend=show_legend, show_title=False,\n                               show_mu=False, show_acq_func=True,\n                               show_observations=False,\n                               show_next_point=True)\n    ax.set_ylabel(\"\")\n    ax.set_xlabel(\"\")\n\n\nplt.show()\n","output":{"0":{"data":{"image/png":"dde103e2d6853aab44860a834775c0726a0ee184","text/plain":"<Figure size 720x1296 with 20 Axes>"},"exec_count":12,"metadata":{"image/png":{"height":1009,"width":603},"needs_background":"light"},"output_type":"execute_result"}},"pos":51,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"539f97","input":"plt.rcParams[\"figure.figsize\"] = (8,6)\n\n# Plot f(x) + contours\n_ = plot_gaussian_process(res, objective=f_wo_noise,\n                          noise_level=noise_level)\n\nplt.show()","output":{"0":{"data":{"image/png":"8d161d11ab3e14b7f485bb31e2c7b632541e7c11","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":13,"metadata":{"image/png":{"height":386,"width":505},"needs_background":"light"},"output_type":"execute_result"}},"pos":53,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"c4c758","input":"import plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport numpy as np\n\nx = np.linspace(-10, 10, 401)     \ny = np.linspace(-10, 10, 401)     \nX, Y = np.meshgrid(x, y) \nZ = (X + 2*Y-7)**2 + (2*X + Y-5)**2\n\ndata = [\n    go.Surface( x = X, y = Y, z = Z, colorscale = 'Jet',\n        contours=go.surface.Contours(\n            z=go.surface.contours.Z(\n              show=True,\n              usecolormap=True,\n              highlightcolor=\"#42f462\",\n              project=dict(z=True)\n            )\n        )\n    )\n]\n\nlayout = go.Layout(title='Booth Function (f(1,3) = 0)',width=600,height=600)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n","output":{"0":{"data":{"iframe":"0d91dc8075196a9c9ee72b860313ddda707154af"},"exec_count":14,"output_type":"execute_result"}},"pos":55,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"ab8f76","input":"#pip install --user --upgrade scikit-learn (have to run this in a .term file and restart kernel if sklearn version below 0.24.2)\nimport sklearn\nprint(sklearn.__version__)","output":{"0":{"name":"stdout","output_type":"stream","text":"0.24.2\n"}},"pos":57,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"d52cb2","input":"np.random.seed(42)\nnoise_level = .1\n\ndef booth_objective(x , noise=noise_level):\n    z = (x[0] + 2*x[1]-7)**2 + (2*x[0] + x[1]-5)**2 + np.random.randn() * noise\n    #because we don't want a negative number, return the absolute for optimization\n    return abs(z)\n\n\n\n\n#call the optimization.\nres = gp_minimize(booth_objective,                  # the function to minimize\n                  [(-10.0, 10.0), (-10.0, 10.0)],      # the bounds on each dimension of x\n                 acq_func=\"PI\",      # the acquisition function - using PI like above\n                  n_calls=20,         # the number of evaluations of the objective function\n                  n_random_starts=5,  # the number of random initialization points\n                  random_state=42)   # the random seed\n\n\n\"x=%.4f, y=%.4f, f(x)=%.4f\" % (res.x[0], res.x[1], res.fun)\nplot_convergence(res);","output":{"0":{"data":{"image/png":"e7c99cc381533585d32fec04e3c3fcba00e57863","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":16,"metadata":{"image/png":{"height":386,"width":501},"needs_background":"light"},"output_type":"execute_result"}},"pos":58,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"870c47","input":"#https://machinelearningmastery.com/what-is-bayesian-optimization/\n#https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html#sphx-glr-auto-examples-bayesian-optimization-py\nfrom scipy.stats import norm\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom warnings import catch_warnings\nfrom warnings import simplefilter\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skopt.plots import plot_gaussian_process\nfrom skopt import gp_minimize","pos":0,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"9dee53","input":"# relies on data loaded in previous section\n\n# import numpy as np\n# from simanneal import Annealer\n\ndef tour_distance(tour, dist_mat):\n    distance = dist_mat[tour[-1]][tour[0]]\n    for gene1, gene2 in zip(tour[0:-1], tour[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\nclass TravellingSalesmanProblem(Annealer):\n\n    # pass extra data (the distance matrix) into the constructor\n    def __init__(self, state, distance_matrix):\n        self.distance_matrix = distance_matrix\n        super(TravellingSalesmanProblem, self).__init__(state)  # important!\n\n    def move(self):\n        self.state = sub_tour_reversal(self.state)\n\n    def energy(self):\n        return tour_distance(self.state, self.distance_matrix)\n\n# load data (this may have to be adapted for different problems)\nwith open(\"data/HillierTSP.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\ninit_tour = np.random.permutation(np.arange(len(distance_matrix))).astype(int).tolist()\n\ntsp = TravellingSalesmanProblem(init_tour, distance_matrix)\ntsp.set_schedule(tsp.auto(minutes=.2)) #set approximate time to find results\n\nbest_tour, best_dist = tsp.anneal()\n\nbest_dist","output":{"0":{"name":"stderr","output_type":"stream","text":" Temperature        Energy    Accept   Improve     Elapsed   Remaining\n\r     0.00000        246.00                         0:00:00            \r"},"1":{"name":"stderr","output_type":"stream","text":"\r   140.00000        335.00    77.35%    30.65%     0:00:00     0:00:02\r\r"},"10":{"name":"stderr","output_type":"stream","text":"\r  1100.00000        338.00    96.90%    41.85%     0:00:01     0:00:02\r\r"},"100":{"name":"stderr","output_type":"stream","text":"\r     6.26903         65.00    25.00%     5.05%     0:00:08     0:00:03\r\r"},"101":{"name":"stderr","output_type":"stream","text":"\r     5.75838         63.00    26.86%     6.52%     0:00:08     0:00:03\r\r"},"102":{"name":"stderr","output_type":"stream","text":"\r     5.28933         65.00    25.29%     5.71%     0:00:08     0:00:03\r\r"},"103":{"name":"stderr","output_type":"stream","text":"\r     4.85848         66.00    23.67%     4.43%     0:00:08     0:00:03\r\r"},"104":{"name":"stderr","output_type":"stream","text":"\r     4.46272         65.00    25.52%     5.90%     0:00:08     0:00:03\r\r"},"105":{"name":"stderr","output_type":"stream","text":"\r     4.09921         63.00    24.57%     5.95%     0:00:08     0:00:03\r\r"},"106":{"name":"stderr","output_type":"stream","text":"\r     3.76530         65.00    24.52%     5.19%     0:00:09     0:00:03\r\r"},"107":{"name":"stderr","output_type":"stream","text":"\r     3.45859         64.00    23.38%     4.10%     0:00:09     0:00:03\r\r"},"108":{"name":"stderr","output_type":"stream","text":"\r     3.17687         65.00    22.71%     4.19%     0:00:09     0:00:02\r\r"},"109":{"name":"stderr","output_type":"stream","text":"\r     2.91809         63.00    21.14%     4.00%     0:00:09     0:00:02\r\r"},"11":{"name":"stderr","output_type":"stream","text":"\r   730.00000        158.00    95.55%    39.30%     0:00:01     0:00:02\r\r"},"110":{"name":"stderr","output_type":"stream","text":"\r     2.68040         68.00    23.62%     4.67%     0:00:09     0:00:02\r\r"},"111":{"name":"stderr","output_type":"stream","text":"\r     2.46206         63.00    20.86%     3.24%     0:00:09     0:00:02\r\r"},"112":{"name":"stderr","output_type":"stream","text":"\r     2.26151         63.00    22.38%     3.90%     0:00:09     0:00:02\r\r"},"113":{"name":"stderr","output_type":"stream","text":"\r     2.07730         65.00    19.62%     3.14%     0:00:09     0:00:02\r\r"},"114":{"name":"stderr","output_type":"stream","text":"\r     1.90809         66.00    19.38%     2.48%     0:00:10     0:00:02\r\r"},"115":{"name":"stderr","output_type":"stream","text":"\r     1.75266         65.00    22.67%     3.29%     0:00:10     0:00:02\r\r"},"116":{"name":"stderr","output_type":"stream","text":"\r     1.60990         66.00    20.29%     2.57%     0:00:10     0:00:02\r\r"},"117":{"name":"stderr","output_type":"stream","text":"\r     1.47876         65.00    17.62%     2.24%     0:00:10     0:00:01\r\r"},"118":{"name":"stderr","output_type":"stream","text":"\r     1.35831         63.00    20.05%     3.00%     0:00:10     0:00:01\r\r"},"119":{"name":"stderr","output_type":"stream","text":"\r     1.24766         65.00    16.38%     1.10%     0:00:10     0:00:01\r\r"},"12":{"name":"stderr","output_type":"stream","text":"\r   490.00000        427.00    93.25%    39.55%     0:00:02     0:00:01\r\r"},"120":{"name":"stderr","output_type":"stream","text":"\r     1.14603         65.00    17.90%     1.52%     0:00:10     0:00:01\r\r"},"121":{"name":"stderr","output_type":"stream","text":"\r     1.05268         63.00    15.52%     1.14%     0:00:10     0:00:01\r\r"},"122":{"name":"stderr","output_type":"stream","text":"\r     0.96694         63.00    13.29%     0.10%     0:00:10     0:00:01\r\r"},"123":{"name":"stderr","output_type":"stream","text":"\r     0.88817         63.00    16.57%     0.29%     0:00:10     0:00:01\r\r"},"124":{"name":"stderr","output_type":"stream","text":"\r     0.81582         64.00    15.43%     0.38%     0:00:11     0:00:01\r\r"},"125":{"name":"stderr","output_type":"stream","text":"\r     0.74937         63.00    15.76%     0.67%     0:00:11     0:00:01\r\r"},"126":{"name":"stderr","output_type":"stream","text":"\r     0.68833         64.00    17.10%     1.48%     0:00:11     0:00:00\r\r"},"127":{"name":"stderr","output_type":"stream","text":"\r     0.63226         64.00    15.57%     0.86%     0:00:11     0:00:00\r\r"},"128":{"name":"stderr","output_type":"stream","text":"\r     0.58076         63.00    15.76%     0.57%     0:00:11     0:00:00\r\r"},"129":{"name":"stderr","output_type":"stream","text":"\r     0.53345         63.00    14.29%     0.00%     0:00:11     0:00:00\r\r"},"13":{"name":"stderr","output_type":"stream","text":"\r   330.00000        250.00    88.70%    38.10%     0:00:02     0:00:01\r\r"},"130":{"name":"stderr","output_type":"stream","text":"\r     0.49000         63.00    13.95%     0.00%     0:00:11     0:00:00\r\r"},"131":{"data":{"text/plain":"63"},"exec_count":2,"output_type":"execute_result"},"14":{"name":"stderr","output_type":"stream","text":"\r   220.00000        157.00    84.75%    34.95%     0:00:02     0:00:01\r\r"},"15":{"name":"stderr","output_type":"stream","text":"\r   150.00000        331.00    78.25%    31.75%     0:00:02     0:00:01\r\r"},"16":{"name":"stderr","output_type":"stream","text":"\r   100.00000         69.00    70.65%    28.10%     0:00:02     0:00:01\r\r"},"17":{"name":"stderr","output_type":"stream","text":"\r    67.00000        155.00    55.35%    20.30%     0:00:02     0:00:01\r\r"},"18":{"name":"stderr","output_type":"stream","text":"\r    45.00000        251.00    44.55%    15.35%     0:00:02     0:00:01\r\r"},"19":{"name":"stderr","output_type":"stream","text":"\r    30.00000        149.00    35.10%     9.75%     0:00:02     0:00:01\r\r"},"2":{"name":"stderr","output_type":"stream","text":"\r   210.00000        242.00    83.45%    34.90%     0:00:00     0:00:02\r\r"},"20":{"name":"stderr","output_type":"stream","text":"\r    20.00000         69.00    26.90%     7.00%     0:00:02     0:00:00\r\r"},"21":{"name":"stderr","output_type":"stream","text":"\r    13.00000         65.00    28.50%     7.55%     0:00:02     0:00:00\r\r"},"22":{"name":"stderr","output_type":"stream","text":"\r     8.70000         64.00    26.65%     5.60%     0:00:02     0:00:00\r\r"},"23":{"name":"stderr","output_type":"stream","text":"\r     5.80000         65.00    25.10%     5.45%     0:00:03     0:00:00\r\r"},"24":{"name":"stderr","output_type":"stream","text":"\r     3.90000         65.00    23.25%     4.25%     0:00:03     0:00:00\r\r"},"25":{"name":"stderr","output_type":"stream","text":"\r     2.60000         64.00    21.10%     3.60%     0:00:03     0:00:00\r\r"},"26":{"name":"stderr","output_type":"stream","text":"\r     1.70000         65.00    20.20%     2.60%     0:00:03     0:00:00\r\r"},"27":{"name":"stderr","output_type":"stream","text":"\r     1.10000         64.00    16.20%     1.20%     0:00:03     0:00:00\r\r"},"28":{"name":"stderr","output_type":"stream","text":"\r     0.73000         63.00    15.30%     0.90%     0:00:03     0:00:00\r\r"},"29":{"name":"stderr","output_type":"stream","text":"\r     0.49000         63.00    14.05%     0.00%     0:00:03    -1:59:59\r\r"},"3":{"name":"stderr","output_type":"stream","text":"\r   320.00000        335.00    89.95%    36.55%     0:00:00     0:00:02\r\r"},"30":{"name":"stderr","output_type":"stream","text":" Temperature        Energy    Accept   Improve     Elapsed   Remaining\n\r  2400.00000         63.00                         0:00:00            \r"},"31":{"name":"stderr","output_type":"stream","text":"\r  2204.50501        248.00    98.67%    41.86%     0:00:00     0:00:11\r\r"},"32":{"name":"stderr","output_type":"stream","text":"\r  2024.93431        419.00    98.48%    41.19%     0:00:00     0:00:10\r\r"},"33":{"name":"stderr","output_type":"stream","text":"\r  1859.99076        156.00    97.57%    41.71%     0:00:00     0:00:10\r\r"},"34":{"name":"stderr","output_type":"stream","text":"\r  1708.48290         65.00    97.52%    41.19%     0:00:00     0:00:10\r\r"},"35":{"name":"stderr","output_type":"stream","text":"\r  1569.31629        434.00    97.43%    41.57%     0:00:01     0:00:10\r\r"},"36":{"name":"stderr","output_type":"stream","text":"\r  1441.48568         68.00    96.95%    41.33%     0:00:01     0:00:09\r\r"},"37":{"name":"stderr","output_type":"stream","text":"\r  1324.06767         63.00    97.38%    41.48%     0:00:01     0:00:09\r\r"},"38":{"name":"stderr","output_type":"stream","text":"\r  1216.21409        609.00    96.90%    40.29%     0:00:01     0:00:09\r\r"},"39":{"name":"stderr","output_type":"stream","text":"\r  1117.14585        332.00    97.24%    40.52%     0:00:01     0:00:09\r\r"},"4":{"name":"stderr","output_type":"stream","text":"\r   480.00000        341.00    93.05%    39.35%     0:00:00     0:00:02\r\r"},"40":{"name":"stderr","output_type":"stream","text":"\r  1026.14734        156.00    96.90%    40.24%     0:00:01     0:00:09\r\r"},"41":{"name":"stderr","output_type":"stream","text":"\r   942.56123        334.00    96.29%    40.90%     0:00:01     0:00:08\r\r"},"42":{"name":"stderr","output_type":"stream","text":"\r   865.78373        160.00    96.00%    39.67%     0:00:01     0:00:08\r\r"},"43":{"name":"stderr","output_type":"stream","text":"\r   795.26024        239.00    95.71%    40.29%     0:00:01     0:00:08\r\r"},"44":{"name":"stderr","output_type":"stream","text":"\r   730.48133        609.00    95.38%    40.52%     0:00:01     0:00:08\r\r"},"45":{"name":"stderr","output_type":"stream","text":"\r   670.97906        251.00    94.43%    39.86%     0:00:01     0:00:08\r\r"},"46":{"name":"stderr","output_type":"stream","text":"\r   616.32363        342.00    94.48%    40.43%     0:00:01     0:00:08\r\r"},"47":{"name":"stderr","output_type":"stream","text":"\r   566.12022        422.00    93.52%    40.52%     0:00:02     0:00:10\r\r"},"48":{"name":"stderr","output_type":"stream","text":"\r   520.00619        155.00    93.76%    39.86%     0:00:02     0:00:10\r\r"},"49":{"name":"stderr","output_type":"stream","text":"\r   477.64844        433.00    92.81%    39.19%     0:00:02     0:00:10\r\r"},"5":{"name":"stderr","output_type":"stream","text":"\r   720.00000        338.00    95.20%    39.75%     0:00:00     0:00:01\r\r"},"50":{"name":"stderr","output_type":"stream","text":"\r   438.74099        161.00    91.81%    38.57%     0:00:02     0:00:10\r\r"},"51":{"name":"stderr","output_type":"stream","text":"\r   403.00279        337.00    92.29%    39.14%     0:00:03     0:00:09\r\r"},"52":{"name":"stderr","output_type":"stream","text":"\r   370.17570        249.00    91.10%    38.81%     0:00:03     0:00:09\r\r"},"53":{"name":"stderr","output_type":"stream","text":"\r   340.02258        244.00    90.00%    38.19%     0:00:03     0:00:09\r\r"},"54":{"name":"stderr","output_type":"stream","text":"\r   312.32561        157.00    89.95%    37.52%     0:00:03     0:00:09\r\r"},"55":{"name":"stderr","output_type":"stream","text":"\r   286.88474        330.00    87.86%    36.86%     0:00:03     0:00:09\r\r"},"56":{"name":"stderr","output_type":"stream","text":"\r   263.51619        255.00    86.48%    36.14%     0:00:03     0:00:09\r\r"},"57":{"name":"stderr","output_type":"stream","text":"\r   242.05115        434.00    86.86%    36.48%     0:00:03     0:00:08\r\r"},"58":{"name":"stderr","output_type":"stream","text":"\r   222.33457        249.00    86.43%    35.62%     0:00:03     0:00:08\r\r"},"59":{"name":"stderr","output_type":"stream","text":"\r   204.22403        160.00    85.10%    35.62%     0:00:03     0:00:08\r\r"},"6":{"name":"stderr","output_type":"stream","text":"\r  1100.00000        152.00    96.70%    40.90%     0:00:01     0:00:01\r\r"},"60":{"name":"stderr","output_type":"stream","text":"\r   187.58871        241.00    82.19%    33.71%     0:00:03     0:00:08\r\r"},"61":{"name":"stderr","output_type":"stream","text":"\r   172.30844        157.00    80.76%    33.29%     0:00:03     0:00:08\r\r"},"62":{"name":"stderr","output_type":"stream","text":"\r   158.27284         64.00    79.05%    32.00%     0:00:04     0:00:08\r\r"},"63":{"name":"stderr","output_type":"stream","text":"\r   145.38053         66.00    78.10%    30.14%     0:00:04     0:00:07\r\r"},"64":{"name":"stderr","output_type":"stream","text":"\r   133.53837        250.00    77.43%    30.76%     0:00:04     0:00:07\r\r"},"65":{"name":"stderr","output_type":"stream","text":"\r   122.66084        332.00    72.81%    28.76%     0:00:04     0:00:07\r\r"},"66":{"name":"stderr","output_type":"stream","text":"\r   112.66935        426.00    73.76%    29.62%     0:00:04     0:00:07\r\r"},"67":{"name":"stderr","output_type":"stream","text":"\r   103.49173        161.00    69.05%    28.19%     0:00:04     0:00:07\r\r"},"68":{"name":"stderr","output_type":"stream","text":"\r    95.06168        156.00    66.62%    26.86%     0:00:04     0:00:07\r\r"},"69":{"name":"stderr","output_type":"stream","text":"\r    87.31831        250.00    64.90%    24.81%     0:00:04     0:00:07\r\r"},"7":{"name":"stderr","output_type":"stream","text":"\r  1600.00000        337.00    97.85%    40.75%     0:00:01     0:00:01\r\r"},"70":{"name":"stderr","output_type":"stream","text":"\r    80.20569        157.00    63.95%    25.33%     0:00:05     0:00:07\r\r"},"71":{"name":"stderr","output_type":"stream","text":"\r    73.67244        149.00    60.14%    22.19%     0:00:05     0:00:07\r\r"},"72":{"name":"stderr","output_type":"stream","text":"\r    67.67136        248.00    56.62%    20.43%     0:00:05     0:00:07\r\r"},"73":{"name":"stderr","output_type":"stream","text":"\r    62.15910        247.00    54.19%    19.76%     0:00:05     0:00:07\r\r"},"74":{"name":"stderr","output_type":"stream","text":"\r    57.09585        248.00    49.29%    18.05%     0:00:05     0:00:07\r\r"},"75":{"name":"stderr","output_type":"stream","text":"\r    52.44504        251.00    49.71%    17.24%     0:00:05     0:00:06\r\r"},"76":{"name":"stderr","output_type":"stream","text":"\r    48.17306         66.00    45.14%    14.57%     0:00:05     0:00:06\r\r"},"77":{"name":"stderr","output_type":"stream","text":"\r    44.24907         69.00    45.52%    14.76%     0:00:05     0:00:06\r\r"},"78":{"name":"stderr","output_type":"stream","text":"\r    40.64470        247.00    40.05%    13.00%     0:00:06     0:00:06\r\r"},"79":{"name":"stderr","output_type":"stream","text":"\r    37.33394         69.00    38.81%    12.14%     0:00:06     0:00:06\r\r"},"8":{"name":"stderr","output_type":"stream","text":"\r  2400.00000        250.00    98.00%    42.30%     0:00:01     0:00:02\r\r"},"80":{"name":"stderr","output_type":"stream","text":"\r    34.29286         65.00    36.38%    10.76%     0:00:06     0:00:06\r\r"},"81":{"name":"stderr","output_type":"stream","text":"\r    31.49949         69.00    37.24%    11.57%     0:00:06     0:00:06\r\r"},"82":{"name":"stderr","output_type":"stream","text":"\r    28.93366         68.00    31.76%     8.71%     0:00:06     0:00:05\r\r"},"83":{"name":"stderr","output_type":"stream","text":"\r    26.57683         65.00    33.71%     9.29%     0:00:06     0:00:05\r\r"},"84":{"name":"stderr","output_type":"stream","text":"\r    24.41198         63.00    30.10%     8.24%     0:00:06     0:00:05\r\r"},"85":{"name":"stderr","output_type":"stream","text":"\r    22.42347         63.00    29.05%     7.95%     0:00:06     0:00:05\r\r"},"86":{"name":"stderr","output_type":"stream","text":"\r    20.59694         65.00    29.71%     7.62%     0:00:06     0:00:05\r\r"},"87":{"name":"stderr","output_type":"stream","text":"\r    18.91919         65.00    27.43%     6.10%     0:00:06     0:00:05\r\r"},"88":{"name":"stderr","output_type":"stream","text":"\r    17.37811         69.00    27.71%     6.81%     0:00:06     0:00:05\r\r"},"89":{"name":"stderr","output_type":"stream","text":"\r    15.96255         69.00    25.62%     6.14%     0:00:07     0:00:05\r\r"},"9":{"name":"stderr","output_type":"stream","text":"\r  1600.00000        431.00    97.10%    39.90%     0:00:01     0:00:02\r\r"},"90":{"name":"stderr","output_type":"stream","text":"\r    14.66230         66.00    29.33%     7.71%     0:00:07     0:00:04\r\r"},"91":{"name":"stderr","output_type":"stream","text":"\r    13.46797         66.00    27.76%     7.10%     0:00:07     0:00:05\r\r"},"92":{"name":"stderr","output_type":"stream","text":"\r    12.37092         65.00    28.48%     6.52%     0:00:07     0:00:04\r\r"},"93":{"name":"stderr","output_type":"stream","text":"\r    11.36323         69.00    26.76%     6.00%     0:00:07     0:00:04\r\r"},"94":{"name":"stderr","output_type":"stream","text":"\r    10.43762         64.00    26.71%     6.29%     0:00:07     0:00:04\r\r"},"95":{"name":"stderr","output_type":"stream","text":"\r     9.58741         66.00    27.38%     6.10%     0:00:07     0:00:04\r\r"},"96":{"name":"stderr","output_type":"stream","text":"\r     8.80646         65.00    25.19%     6.14%     0:00:08     0:00:04\r\r"},"97":{"name":"stderr","output_type":"stream","text":"\r     8.08912         65.00    27.29%     6.38%     0:00:08     0:00:04\r\r"},"98":{"name":"stderr","output_type":"stream","text":"\r     7.43021         65.00    28.24%     6.33%     0:00:08     0:00:04\r\r"},"99":{"name":"stderr","output_type":"stream","text":"\r     6.82497         66.00    27.33%     5.57%     0:00:08     0:00:04\r\r"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"cd635f","input":"# execute this cell for video\nplay_video(\"ds775_lesson5_simulated-anneal-tsp\")","metadata":{"code_folding":[],"hidden":true},"output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_simulated-anneal-tsp/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f4016f7e910>"},"exec_count":2,"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"b84af3","input":"# Baye's optimization testing\n\n","pos":28.2,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"3f9795","input":"# import numpy as np\n# import json\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# sns.set_style(\"darkgrid\")\n\n# load data (this may have to be adapted for different problems)\nwith open(\"data/HillierTSP.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\nindividual_size = tsp[\"TourSize\"]\n\n# define objective function\ndef tour_distance(individual, dist_mat):\n    distance = dist_mat[individual[-1]][individual[0]]\n    for gene1, gene2 in zip(individual[0:-1], individual[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\n# Random Number Seed\n# if you want reproducible results, then uncomment the following line\n# and play with the seed value until you get a result you like. If you run \n# it again with the same value, then you'll get the same result.\n# np.random.seed(123)\n\ndef simanneal_tsp(init_state, dist_mat, max_no_improve, init_temp, alpha): ###\n    '''\n    We use state to refer to the values of the input variable(s) for the objective function.\n    For the TSP problem, the state is a tour of the cities.\n    We use obj to refer to the objective function value.\n    For the TSP problem, obj is the total distance of the tour.\n    \n    To adapt this for another minimization problem, \n    only the lines with tour_distance and sub_tour_reversal need to change \n    to give a different objective function and a different move function.\n    Additional arguments to the objective function should be passed into the search function\n    similar to how we passed in dist_mat abov\n    '''\n\n    curr_state = init_state\n    curr_obj = tour_distance(curr_state, dist_mat)\n    best_state = curr_state  ###\n    best_obj = curr_obj  ###\n\n    # stop search if no better state is found within max_no_improve iterations\n    num_moves_no_improve = 0\n    iterations = 0\n    temp = init_temp\n\n    # save history for plotting after optimization\n    history = np.array([[iterations, curr_obj, best_obj]])  ###\n\n    while (num_moves_no_improve < max_no_improve):\n        num_moves_no_improve += 1\n        iterations += 1  # just for tracking\n        new_state = sub_tour_reversal(curr_state) # make a move\n        new_obj = tour_distance(new_state, dist_mat)\n        delta = curr_obj - new_obj ###\n        prob = np.exp(min(delta, 0) / temp) ### # compute prob accept uphill move\n\n        if new_obj < curr_obj or np.random.uniform() < prob : ### # accept if decrease or rand < prob\n            curr_state = new_state\n            curr_obj = new_obj\n            if curr_obj < best_obj: ### # keep track of best ever\n                best_state = curr_state ###\n                best_obj = curr_obj ###\n                num_moves_no_improve = 0 ###\n\n        temp *= alpha ###\n\n        history = np.vstack( (history, np.array([[iterations,curr_obj,best_obj]]) ) ) ###\n\n    return best_state, best_obj, iterations, history\n\n# apply the simanneal_tsp() function to our seven city problem\nnum_cities = len(distance_matrix)\ninit_tour = np.random.permutation(np.arange(num_cities))\n\nbest_tour, best_dist, iterations, history = simanneal_tsp(init_tour, distance_matrix, 200, 100, .995)\nbest_dist","metadata":{"hidden":true},"output":{"0":{"data":{"text/plain":"63"},"exec_count":3,"output_type":"execute_result"}},"pos":9,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"af5938","input":"np.random.seed(7)\nnoise_level = 0\n\n# objective function\ndef objective(x, noise=noise_level):\n    return (x**2 * np.sin(5 * np.pi * x)**6.0) + (np.random.normal(loc=0, scale=noise_level) * noise)\n\n\n# grid-based sample of the domain [0,1]\nX = np.arange(0, 1, 0.01)\n# sample the domain without noise\ny = [objective(x, 0) for x in X]\n# sample the domain with noise\nynoise = [objective(x) for x in X]\n# find best result\nix = np.argmax(y)\nprint('Optima: x=%.3f, y=%.3f' % (X[ix], y[ix]))\n\nplt.rcParams[\"figure.figsize\"] = (8,6)\n# plot the points with noise\nplt.scatter(X, ynoise, c='#069AF3', label=\"Noisy\");\nplt.scatter(.9,.81, color=\"purple\", marker='X', label=\"Global Optimum\")\n# plot the points without noise\nplt.plot(X, y, c=\"green\", label=\"Actual\");\nplt.title('Simple Function with Noisy Sample');\nplt.legend();\n# show the plot\nplt.show();","output":{"0":{"name":"stdout","output_type":"stream","text":"Optima: x=0.900, y=0.810\n"},"1":{"data":{"image/png":"a3e2acfd1f64e03a31e90809307bac558372bcba","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":3,"metadata":{"image/png":{"height":372,"width":483},"needs_background":"light"},"output_type":"execute_result"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"3fc085","input":"# plot the progress of the search for visualization\n# it isn't necessary to do this in the homework, but you're welcome to do so\n\nfig = plt.figure(figsize=(8, 6))\nline_min, = plt.plot(history[:,0], history[:,1], label='Curr. Dist.',color='red')\nline_curr, = plt.plot(history[:,0],history[:,2], label='Best. Dist.')\nplt.xlabel('Generation')\nplt.ylabel('Distance')\nplt.legend(handles=[line_curr, line_min])\nplt.title('Smallest Dist. Found: {:d}'.format(int(best_dist)));","metadata":{"hidden":true},"output":{"0":{"data":{"image/png":"652ee0590b64d0bb32083f0cd95374254711126b","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":4,"metadata":{"image/png":{"height":386,"width":500}},"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"be5fef","input":"# surrogate or approximation for the objective function\ndef surrogate(model, X):\n    # catch any warning generated when making a prediction\n    with catch_warnings():\n        # ignore generated warnings\n        simplefilter(\"ignore\")\n        #return the predictions\n        return model.predict(X, return_std=True)","pos":32,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"0e0ae9","input":"# execute this cell for video\nplay_video(\"ds775_lesson5_simanneal-package-on-tsp\")","metadata":{"hidden":true},"output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_simanneal-package-on-tsp/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f3ff9f1c070>"},"exec_count":5,"output_type":"execute_result"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"cd7db6","input":"def objective(x, noise=noise_level):\n    return (x**2 * np.sin(5 * np.pi * x)**6.0) + (np.random.normal(loc=0, scale=noise_level) * noise)\n\n# plot helper\ndef plot(X, y, model, title, global_opt = [.9, .9]):\n    # scatter plot of inputs and real objective function\n    plt.scatter(X, y, c='#069AF3', label=\"Inputs\")\n    # line plot of surrogate function across domain\n    Xsamples = np.arange(0, 1, 0.01).reshape(-1,1)\n    ysamples, _ = surrogate(model, Xsamples)\n    plt.plot(Xsamples, ysamples, c=\"green\", label=\"Surrogate\")\n    plt.scatter(global_opt[0], global_opt[1], color=\"purple\", marker='X', label=\"Global Optimum\")\n    plt.title(title)\n    plt.legend()\n    # show the plot\n    plt.show()\n    \nnp.random.seed(1)\nsampleSize = 100\nlow = 0\nhigh = 1\n# sample the domain sparsely with noise\nX = np.random.uniform(low, high, sampleSize).reshape(-1,1)\ny = np.asarray([objective(x) for x in X]).reshape(-1,1)\n# define the model\nmodel = GaussianProcessRegressor()\n# fit the model\nmodel.fit(X, y)\n# plot before hand\nplot(X, y, model, 'Plot of Surrogate Function without Optimization')    ","output":{"0":{"data":{"image/png":"7a037c0165d6375ee030425f54796eaa163c48a1","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":5,"metadata":{"image/png":{"height":372,"width":492},"needs_background":"light"},"output_type":"execute_result"}},"pos":34,"type":"cell"}
{"cell_type":"code","exec_count":55,"id":"67b6d5","input":"noise_level = 0\n\ndef objective(x, noise=noise_level):\n#    return (x**2 * np.sin(5 * np.pi * x)**6.0) + (np.random.normal(loc=0, scale=noise_level) * noise)\n    return((x**2-x) * np.sin(10*x))\n\n#np.random.seed(3)\nsampleSize = 50\nlow = 0\nhigh = 1\n# sample the domain sparsely with noise\nX = np.random.uniform(low, high, sampleSize).reshape(-1,1)\ny = np.asarray([objective(x) for x in X]).reshape(-1,1)\n# define the model\nmodel = GaussianProcessRegressor()\n# fit the model\nmodel.fit(X, y)\n# plot before hand\n#plot(X, y, model, 'Plot of Surrogate Function without Optimization')\nplt.scatter(X,y)\n\nXsamples = np.arange(0,1,.0025).reshape(-1,1)\n#Xsamples = X\nysample,_  = model.predict(Xsamples,return_std=True)\n#ysample,_ = surrogate(model,Xsamples)\nplt.plot(Xsamples,ysample,color='green')","output":{"0":{"name":"stderr","output_type":"stream","text":"/home/user/.local/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:370: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n  warnings.warn(\"Predicted variances smaller than 0. \"\n"},"1":{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7fb3b055f400>]"},"exec_count":55,"output_type":"execute_result"},"2":{"data":{"image/png":"6702df51a90650b256b70da19279cb65e32a9c53","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":55,"metadata":{"image/png":{"height":357,"width":492},"needs_background":"light"},"output_type":"execute_result"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"0a1bd8","input":"# optimize the acquisition function\ndef acquisition(X, y, model, low, high, size, verbose=False):\n    # random search, generate random samples\n    Xsamples = np.random.uniform(low, high, size)\n    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n    # calculate the best surrogate score found so far\n    yhat, _ = surrogate(model, X)\n    best = max(yhat)\n    # calculate mean and stdev via surrogate function\n    mu, std = surrogate(model, Xsamples)\n    mu = mu[:, 0]\n    # calculate the probability of improvement\n    scores = norm.cdf((mu-best) / (std+1E-9))\n    # locate the index of the largest scores\n    ix = np.argmax(scores)\n    return Xsamples[ix, 0]\n","pos":37,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"2d3a2c","input":"from skopt import gp_minimize\n\n# objective function\ndef objective1(x, noise_level = 0.0 ):\n    y = x * np.sin(x) + noise_level * np.random.randn()\n    return(float(y))\n\n\nnp.random.seed(42) #adding random seed here, too, for the noise factor\n#call the optimization.\nres = gp_minimize(objective1,                  # the function to minimize\n                  [(0.0,10.0)],      # the bounds on each dimension of x\n                 # acq_func=\"PI\",      # the acquisition function - using PI like above\n                  n_calls=15,         # the number of evaluations of the objective function\n                  n_random_starts=5,  # the number of random initialization points\n                  random_state=42)   # the random seed\n\n\"x=%.4f, f(x)=%.4f\" % (res.x[0], res.fun)\n","kernel":"python3","output":{"0":{"data":{"text/plain":"'x=4.9138, f(x)=-4.8145'"},"exec_count":6}},"pos":28.799999999999997,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"86d609","input":"# define objective function and show a contour plot\n\ndef f(xy):\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n\n# we could have written the objective function like this for transparency:\n# if the argument is a list with [ numpy array of x's, numpy array of y's]\n# def f(xy):\n#     x = xy[0]\n#     y = xy[1]\n#     obj = 0.2 + x**2 + y**2 - 0.1*np.cos(6*np.pi*x) - 0.1*np.cos(6*np.pi*y)\n#     return obj\n\n# see script for details of plot\n%run scripts/bumpy_contours.py","metadata":{"code_folding":[],"hidden":true},"output":{"0":{"data":{"image/png":"44e21a10b473130d943bbdf38442b608b4a89f4c","text/plain":"<Figure size 576x576 with 1 Axes>"},"exec_count":7,"metadata":{"image/png":{"height":494,"width":523}},"output_type":"execute_result"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"c5c997","input":"def bayes_opt(outer_iters, inner_iters, size, X, y, model, low, high, verbose=False):\n    # perform the optimization process\n    for i in range(outer_iters):\n        #track the inner_iters best points using the acquisition model to determine where to sample next\n        next_points = []\n        for j in range(inner_iters):           \n            next_points.append(acquisition(X, y, model, low, high, size, verbose))\n        x = next_points[np.argmax(np.array(next_points))]  \n        # sample the point\n        actual = objective(x)       \n        if verbose:\n            # summarize the finding\n            est, _ = surrogate(model, [[x]])\n            print('x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n        \n        # add the data to the dataset\n        X = np.vstack((X, [[x]]))\n        y = np.vstack((y, [[actual]]))\n        # update the model\n        model.fit(X, y)\n    return X, y    \n","pos":39,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"186e42","input":"noise_level = .1\n\n# objective function\ndef objective(x, noise=noise_level):\n    return (x**2 * np.sin(5 * np.pi * x)**6.0) + np.random.randn() * noise\n\n# surrogate or approximation for the objective function\ndef surrogate(model, X):\n    # catch any warning generated when making a prediction\n    with catch_warnings():\n        # ignore generated warnings\n        simplefilter(\"ignore\")\n        return model.predict(X, return_std=True)\n\n\n# plot helper\ndef plot(X, y, model, title):\n    # scatter plot of inputs and real objective function\n    plt.scatter(X, y, c='#069AF3', label=\"Inputs\")\n    # line plot of surrogate function across domain\n    Xsamples = np.asarray(np.arange(0, 1, 0.001))\n    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n    ysamples, _ = surrogate(model, Xsamples)\n    #plot points from surrogate function\n    plt.plot(Xsamples, ysamples, c=\"green\", label=\"Surrogate\")\n    #plot the best values of x and y\n    best_y = np.argmax(y)\n    plt.scatter(X[best_y],y[best_y], color=\"red\", label=\"Best Value\")\n    plt.title(title)\n    plt.legend()\n    # show the plot\n    plt.show()\n\n\n# optimize the acquisition function\ndef acquisition(X, y, model, low, high, size, verbose=False):\n    # random search, generate random samples\n    Xsamples = np.random.uniform(low, high, size)\n    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n    # calculate the best surrogate score found so far\n    yhat, _ = surrogate(model, X)\n    best = max(yhat)\n    # calculate mean and stdev via surrogate function\n    mu, std = surrogate(model, Xsamples)\n    mu = mu[:, 0]\n    # calculate the probability of improvement\n    scores = norm.cdf((mu-best) / (std+1E-9))\n    # locate the index of the largest scores\n    ix = np.argmax(scores)\n    return Xsamples[ix, 0]\n\n\n\ndef bayes_opt(outer_iters, inner_iters, size, X, y, model, low, high, verbose=False):\n    log = {\n        'candidate': [],\n        'best_x': []\n    }\n    # perform the optimization process\n    for i in range(outer_iters):\n        #track the inner_iters best points using the acquisition model to determine where to sample next\n        next_points = []\n        for j in range(inner_iters):           \n            next_points.append(acquisition(X, y, model, low, high, size, verbose))\n        x = next_points[np.argmax(np.array(next_points))]  \n        # sample the point\n        actual = objective(x)       \n        if verbose:\n            # summarize the finding\n            est, _ = surrogate(model, [[x]])\n            print('x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n        \n        log['candidate'].append(x)\n        log['best_x'].append(actual)\n        # add the data to the dataset\n        X = np.vstack((X, [[x]]))\n        y = np.vstack((y, [[actual]]))\n        # update the model\n        model.fit(X, y)\n    return X, y, log  \n\n\nsampleSize = 100\nlow = 0\nhigh = 1\n# sample the domain sparsely with noise\nX = np.random.uniform(low, high, sampleSize)\ny = np.asarray([objective(x) for x in X])\n# reshape into rows and cols\nX = X.reshape(len(X), 1)\ny = y.reshape(len(y), 1)\n# define the model\nmodel = GaussianProcessRegressor()\n# fit the model\nmodel.fit(X, y)\n# plot before hand\nplot(X, y, model, 'Plot before optimization')\n# best result\nix = np.argmax(y)\nprint('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))\n\nfinal_X, final_y, logs = bayes_opt(25, 50, sampleSize, X, y, model, low, high, True)   #run with outer, inner iterations \n# plot all samples and the final surrogate function\nplot(final_X, final_y, model, 'Plot after optimization')\n# best result\nix = np.argmax(final_y)\nprint('Best Result: x=%.3f, y=%.3f' % (final_X[ix], final_y[ix]))","output":{"0":{"data":{"image/png":"43c9d0b7a241eeb83d9e3d164df408ac58ade8c9","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":8,"metadata":{"image/png":{"height":372,"width":492},"needs_background":"light"},"output_type":"execute_result"},"1":{"name":"stdout","output_type":"stream","text":"Best Result: x=0.893, y=0.794\n"},"10":{"name":"stdout","output_type":"stream","text":"x=0.930, f()=0.410597, actual=0.356\n"},"11":{"name":"stdout","output_type":"stream","text":"x=0.934, f()=0.401446, actual=0.181\n"},"12":{"name":"stdout","output_type":"stream","text":"x=0.935, f()=0.385715, actual=0.488\n"},"13":{"name":"stdout","output_type":"stream","text":"x=0.941, f()=0.377003, actual=0.117\n"},"14":{"name":"stdout","output_type":"stream","text":"x=0.928, f()=0.392515, actual=0.362\n"},"15":{"name":"stdout","output_type":"stream","text":"x=0.932, f()=0.385245, actual=0.439\n"},"16":{"name":"stdout","output_type":"stream","text":"x=0.939, f()=0.370138, actual=0.110\n"},"17":{"name":"stdout","output_type":"stream","text":"x=0.947, f()=0.329814, actual=0.182\n"},"18":{"name":"stdout","output_type":"stream","text":"x=0.984, f()=0.043928, actual=0.012\n"},"19":{"name":"stdout","output_type":"stream","text":"x=0.920, f()=0.387894, actual=0.627\n"},"2":{"name":"stdout","output_type":"stream","text":"x=0.937, f()=0.435872, actual=0.354\n"},"20":{"name":"stdout","output_type":"stream","text":"x=0.984, f()=0.028464, actual=-0.080\n"},"21":{"name":"stdout","output_type":"stream","text":"x=0.955, f()=0.280503, actual=0.063\n"},"22":{"name":"stdout","output_type":"stream","text":"x=0.939, f()=0.352435, actual=0.209\n"},"23":{"name":"stdout","output_type":"stream","text":"x=0.974, f()=0.109772, actual=0.131\n"},"24":{"name":"stdout","output_type":"stream","text":"x=0.940, f()=0.341485, actual=0.026\n"},"25":{"name":"stdout","output_type":"stream","text":"x=0.932, f()=0.357754, actual=0.477\n"},"26":{"name":"stdout","output_type":"stream","text":"x=0.934, f()=0.356106, actual=0.561\n"},"27":{"data":{"image/png":"0b0d9cdfc0f50c61b87b369178ca0c55555e3476","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":8,"metadata":{"image/png":{"height":372,"width":492},"needs_background":"light"},"output_type":"execute_result"},"28":{"name":"stdout","output_type":"stream","text":"Best Result: x=0.893, y=0.794\n"},"3":{"name":"stdout","output_type":"stream","text":"x=0.941, f()=0.416605, actual=0.328\n"},"4":{"name":"stdout","output_type":"stream","text":"x=0.947, f()=0.389682, actual=0.284\n"},"5":{"name":"stdout","output_type":"stream","text":"x=0.945, f()=0.387265, actual=0.250\n"},"6":{"name":"stdout","output_type":"stream","text":"x=0.928, f()=0.415654, actual=0.591\n"},"7":{"name":"stdout","output_type":"stream","text":"x=0.946, f()=0.381863, actual=0.059\n"},"8":{"name":"stdout","output_type":"stream","text":"x=0.931, f()=0.402671, actual=0.456\n"},"9":{"name":"stdout","output_type":"stream","text":"x=0.933, f()=0.403041, actual=0.454\n"}},"pos":41,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"6ffce3","input":"%run scripts/bumpy_2d.py","output":{"0":{"data":{"iframe":"b6097120804c793bb781f24bf80f0b7f5a2f65a6"},"exec_count":8,"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"e860f9","input":"from matplotlib.animation import FuncAnimation\n#get the dots provided by the acquisition function\nX2 = logs['candidate']\ny2 = [objective(x, noise_level) for x in X2]\n\ndef animate(i):\n    ax.scatter(X2[i], y2[i], c='#069AF3', label=f'Proposed Solution {i}')\n\n\n\nfig, ax = plt.subplots(figsize=(5, 3))\nax.set(xlim=(0, 1), ylim=(0, 1))\n    \n# grid-based sample of the domain [0,1]\nX = np.arange(0, 1, 0.01)\n# sample the domain without noise\ny = [objective(x, 0) for x in X]\nplt.scatter(.9,.9, color=\"purple\", marker='X', label=\"Global Optimum\")\n# plot the points without noise\nplt.plot(X, y, c=\"green\", label=\"Actual\");\n\nanim = FuncAnimation(fig, animate, interval=100, frames=len(X2)-1)\nplt.title('Simple Function with Proposed Solutions');\nplt.legend();\n# show the plot\nplt.show();\nanim.save('BayesOpt.gif')","output":{"0":{"data":{"image/png":"b71c6c867782f37a41616fbe7b07e735309dba5c","text/plain":"<Figure size 360x216 with 1 Axes>"},"exec_count":8,"metadata":{"image/png":{"height":209,"width":324},"needs_background":"light"},"output_type":"execute_result"}},"pos":43,"type":"cell"}
{"cell_type":"code","exec_count":86,"id":"ee9d4d","input":"acquire_next_point(model,10)","output":{"0":{"data":{"text/plain":"5.116097402702392"},"exec_count":86,"output_type":"execute_result"}},"pos":28.599999999999998,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"c0e845","input":"noise_level = .1\n\n# objective function\ndef neg_objective(x, noise=noise_level):\n    return -(x[0]**2 * np.sin(5 * np.pi * x[0])**6.0) + np.random.randn() * noise","pos":45,"type":"cell"}
{"cell_type":"markdown","id":"05a4a2","input":"Our from-scratch solution is not the best implementation of this algorithm. But we wanted to include it so that you could really step through each of the pieces. (Note, you can run it with a small sample size and small number of iterations and turn verbose to True to see some output for each iteration.) \n\nThere are several packages that implement Bayes Optimization in a much more efficient way. Let's take a look at two of them: Scikit Optimize and GPyOpt. \n\nLet's take a look at scikit-learn's function first.\n\n## Bayesian Optimization with Scikit-Optimize\n\nScikit-learn expects that you are minimizing a function. It also expects that your x value could be a n-dimensional array. Since we're only working with a single dimension here, we need to explicitly use x[0] to get the first item in our array.","pos":44,"type":"cell"}
{"cell_type":"markdown","id":"05babc","input":"Use the `simanneal` package to try to find a solution in which republicans win 9 of the 10 districts.  Beware that you're trying to maximize the fitness so you'll either need to use a negated fitness function.  You'll also have to set the cities data frame in the initializer (similar to the distance matrix in the tsp above).  The set up here is very similar to using the `locsearch` package to solve the gerrymandering problem as we did in the last self-assessment in Lesson 4.\n\nIf you're using the auto option for the temperature schedule then it could take several minutes to complete a run because the search space for this problem is huge.  Each entry in the 18 dimensional vector can be a number 0 through 9 so there are $10^{18}$ possible vectors to explore.  Alternately you can manually set the temperature schedule with something like this:\n\n```\ntsp.Tmax = 5000\ntsp.Tmin = 2.5\ntsp.steps = 5000\ntsp.updates = 100\n```\n\nYou should replace tsp with the appropriate name that you setup in your code and also experiment with the numbers.  Make sure to comment out the auto schedule.  ","metadata":{"hidden":true},"pos":18,"type":"cell"}
{"cell_type":"markdown","id":"0b4cde","input":"The following cell generates an animated gif of each of the new candidate samples that were returned from the acquisition function. We've included one such animated gif below.\n\n<img src=\"images/BayesOpt.gif\">\n\nYou can see that our algorithm did a good job of finding candidate solutions near the global maximum, and improved as the iterations increased.","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"1f1937","input":"Here is a 3D plot that makes it easier to see all of the local minima in the search space.  A local search will easily get stuck in the wrong minimum if the initial search point isn't very close to the origin.","pos":24,"type":"cell"}
{"cell_type":"markdown","id":"27a130","input":"### *Self Assessment: Simulated Annealing for Gerrymandering with `simanneal`*","metadata":{"hidden":true},"pos":17,"type":"cell"}
{"cell_type":"markdown","id":"2d77cc","input":"#### Define your Iterator Function\nFinally, just like in previous algorithms, we'll repeat a series of steps over and over, trying to narrow in on the best solution. Here we'll call our iteration function bayes_opt. It takes in the parameters needed to run each of our internal functions as well as the number of outer and inner iterations we want to run. For each outer iteration, we'll be evaluating our true objective function. For each inner iteration, we'll be evaulating our surrogate function.\n\nIt returns the best X and y values.","pos":38,"type":"cell"}
{"cell_type":"markdown","id":"3a67dc","input":"Simulated annealing was designed for combinatorial (discrete) optimization problems, but has been adapted to continuous optimization problems.  The main issue is how to generate a new move at each iteration.  There are many variations, but often the move is selected at random from a suitable probability distribution such as a normal or uniform distribution.\n\nThe objective functions we consider here aren't from real applications, instead they're chosen to give you an idea how the algorithm works for difficult optimization problems with many local optima.  It's good to have this sort of thing in mind when, for instance, you're trying to train a complicated neural network and have to optimize the weights in the network to find the best fit to your data.","metadata":{"hidden":true},"pos":20,"type":"cell"}
{"cell_type":"markdown","id":"403672","input":"## Bayesian Optimization\n\nBayesian Optimization is becoming quite popular in the machine learning world. The big advantage of Bayesian Optimization is that it learns as it goes, and does so more efficiently that just repeatedly solving whatever your objective function is. It does this by using a surrogate function that's generally less expensive to evaluate than the objective function is, and using the results of that surrogate function to update the sample data and zero in on the optimal solution.\n\n### Steps in Bayesian Optimization\n\n#### Define your Objective Function\n\nThe first step in any optimization problem is determining your objective function. Bayesian optimization requires an objective function in which your variables have bounds (a finite limit on each real or integer number or a defined set of values for categorical variables). We'll use the following simple maximization problem that with a bounds of [0,1] has a global optimum of .9. \n\n\n\n$$f(\\mathbf{x})=x^2 \\sin(5 * \\pi * x)^6$$\n\nThe domain is restricted so that each $x_i \\in [0,1].$   \n\n\nFor the purposes of walking through how Bayesian Optimization works, we'll define an objective function that takes in a single-dimension x and some amount of noise. (You wouldn't need or want noise in the real world, but since we're using this as a demonstration, we want to be able to provide a \"noisy\" or \"not perfect\" view of the data.)\n\nLet's look at the objective function and a sampling of noisy points around the objective function. The noisy points would be our sample data for which we're trying to find a global optimum.","pos":29,"type":"cell"}
{"cell_type":"markdown","id":"4cec95","input":"To use simulated annealing to optimize a function with continuous variables isn't all that different than how we used it to find a good, or even optimal, tour in the traveling salesman problem.  \n\nWe're going to rely on the `simanneal package` in the rest of this lesson because it's much more robust than our \"homebrewed\" code in the `simanneal_tsp()` function above. \nTo use the package we'll have to generate an initial state, define the `energy()` method for returning the objective function value, and define the `move()` method for making a move from a current state to a new state.\n\nTo generate an initial state you could select uniformly distributed random numbers between -1 and 1:\n```\ninit_state = np.random.uniform(low=-1, high=1, size=2)\n```\n\nWe like to write functions for computing the objective function value and for making moves and then call those functions from the `move()` and `energy()` methods in the class definition for our problem as we did in the simanneal package TSP example above.\n\nWe already have the objective function from where we made the contour plot:\n```\ndef f(xy):\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n```\n\nMaking a move will consist of applying two functions successively.  The first function adds normally distributed random numbers to each variable while the second function clips values that are out of the $[-1,1]$ bounds.  The scale of the move will need to be passed to the first function, while the values of the lower and upper bounds need to be passed to the clipping function.  These values will need to be initialized in the `__init__` constructor similar to how we worked with the distance matrix in the TSP example.  Here are the functions:\n```\ndef gauss_move(xy,sigma):\n    # xy is a 1 by dim numpy array\n    # sigma is the standard deviation for the normal distribution\n    dim = len(xy)\n    return xy + np.random.normal(loc = 0, scale = sigma, size=dim)\n\ndef clip_to_bounds(xy,low,high):\n    # xy is a 1 by dim numpy array\n    # low is the lower bound for clipping variables\n    # high is the upper bound for clipping variables\n    return np.array( [min(high,max(low,v)) for v in xy])\n```","metadata":{"hidden":true},"pos":26,"type":"cell"}
{"cell_type":"markdown","id":"52a509","input":"Note that if you change the numpy random seed, the green line (the actual function line) would not change. But the blue dots (the noisy data) would change. Feel free to change the seed and rerun the code to see that in action.\n\n**Our job would be, given the noisy blue dots, find the global maximum of the green line (.9,.81).**\n\n#### Define you Surrogate Function\nWith a function as simple as this function, we could simply just run the function from random starting points multiple times, looking for improvement - as we've seen before in hill-climbing. But imagine if your function was a 10-fold cross-validation of a machine learning algorithm with 10 hyperparameters that could each take on 5-10 values. It could take days to evaluate that over and over again, and we're not actually learning from our previous iterations.\n\nEnter the surrogate function. The surrogate function is a function that's less computationally expensive to evaluate, that helps the algorithm get closer to the optimum solution. It does this by summarizing the conditional probability of the objective function (f), given the available data (D). In other words, it determines the P(f|D).\n\nThere are several common surrogate functions you might see when Bayesian Optimization is implemented. Perhaps the most common is a Gaussian predictive model. A Gaussian model assumes that your parameters follow a normal distribution, even if the exact mean and standard variation are unknown. It's computationally quick to evaluate. And, thanks to scikit-learn, it's easy to implement in code. \n\nWe'll use the default parameters for the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html\">GaussianProcessRegressor</a> for our surrogate function. This function can issue warnings if we don't have a lot of data at a particular part of the distribution we're sampling, so we'll write a wrapper function to supress the warnings, and we'll return the standard deviation, which we'll use in the next step.\n\nLike all predictive models, this model needs to be trained. We'll get to that shortly. For now, let's just define our surrogate function.","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"5472d4","input":"#### *Self-Assessment for Simulated Annealing with Continuous Variables*\n\nUse the objective and move functions from above to create a class using the `simanneal` package.  Use it to approximate the location of the global minimum for the \"Bumpy\" function above.  You'll notice that you usually will get close to the location of the global minimum at the origin, but it won't be exact because it is very difficult to randomly move exactly to the minimum location.  Usually, for continuous functions simulated annealing is combined with local search in an iterative procedure (we'll see an example of this in the homework with the `dual_annealing` optimizer from the `scipy.optimize` package.  For this example you could take the best state found by simulated annealing and use it to start a local search using `minimize` from `scipy.optimize` package.\n\nThe code from the TSP example above is a good starting point.  Instead of the distance matrix you'll need to pass the scale parameter sigma to determine the size of the moves.  A good starting point for sigma is range/6 where range = upper bound - lower bound.  This value for sigma is because a normal distribution is about 6 * sigma wide.  You may want to experiment with the value of sigma to see how it effects the result of simulated annealing.  You could also play with the time allowed when you set the schedule for the annealing.","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"5abf57","input":"## Simulated Annealing for Continuous Optimization","metadata":{"heading_collapsed":true,"hidden":true},"pos":19,"type":"cell"}
{"cell_type":"markdown","id":"5c049f","input":"### *Self Assessment: Simulated Annealing for Gerrymandering*","metadata":{"heading_collapsed":true,"hidden":true},"pos":11,"type":"cell"}
{"cell_type":"markdown","id":"5c7529","input":"We'll use the seven city example TSP from the textbook. Find the shortest tour (or cheapest cost) to visit all 7 cities and return to the starting city in the following graph:\n\n<img src=\"./images/HillierTSP.png\" width=400>\n\nWe'll store all of the intercity distances in a two dimensional list that we call distance_matrix. For cities that aren't connected we'll use the \"bigM\" method and introduce a distance of 100 between those pairs of cities so that those routes won't be included in the tour. Note that the picture labels the cities 1 through 7, but in Python we'll use 0 through 6.  The data is stored in the included json file.\n\nIf you want to really understand how simulated annealing worksThe following video includes a walkthrough of the code below.","metadata":{"hidden":true},"pos":7,"type":"cell"}
{"cell_type":"markdown","id":"603a4c","input":"We can also view a plot of the final optimized value. We can see that we have a small cluster of samples near the global optimum. We can also see that the algorithm explored some areas that were not local optimum points, too. This can happen while the algorithm is in the exploration phase. If we changed the seed, we'd see different results, with potentially different areas explored.","pos":52,"type":"cell"}
{"cell_type":"markdown","id":"67af47","input":"# Simulated Annealing","metadata":{"heading_collapsed":true},"pos":4,"type":"cell"}
{"cell_type":"markdown","id":"7ae1d3","input":"#### Putting it all Together\n\nLet's put all of our code in one cell and run our optimization algorithm.","pos":40,"type":"cell"}
{"cell_type":"markdown","id":"87cacc","input":"We can also plot how points are added, and what the next point will be, based off the results of the optimization, using the <a href=\"https://scikit-optimize.github.io/stable/modules/generated/skopt.plots.plot_gaussian_process.html\">plot_gaussian_process function</a>. Note that this function only works with 1-dimensional objective functions.\n\nLet's see what the first 10 iterations of the problem look like. Note that an additional sample point (the red dots) is added with each iteration, and the optimized function line (the green dotted line) begins to resemble the true function line, with points beginning to cluster near the global optimum.","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"91e7cd","input":"To function we need to use to run our Bayesian Optimization is <a href=\"https://scikit-optimize.github.io/stable/modules/generated/skopt.gp_minimize.html\">gp_minimize</a>. There are a lot of parameters you can set on this function, so I encourage you to read the documentation to understand all of them. We are only going to set a few:\n\n* the function to minimize (which should return a scalar (single number) value)\n* the dimensions that will be searched\n* the acquisition function\n    * We can also choose from LCB for lower confidence bount, EI for negative expected improvement, PI for negative probability of improvement or gp_hedge, which probabilistically chooses from one of the first three options at every iteration. This is the default option. But, we'll switch to PI, since that's what we were using above.\n* the number of evaluations of the objective function (n_calls)\n\nThe function returns an \"Optimization Result\" object that contains the location of the minimum, the function value at the minimum, and several other values. ","pos":46,"type":"cell"}
{"cell_type":"markdown","id":"923146","input":"<font size=18>Lesson 06: Global Optimization 1</font>","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"94ba2b","input":"### A non-convex 2D example","metadata":{"heading_collapsed":true,"hidden":true},"pos":21,"type":"cell"}
{"cell_type":"markdown","id":"a2c8a8","input":"We found this two-dimensional example in <a href=\"http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\">this tutorial</a> on simulated annealing.\n\nFind the minimum value of \n$$f(x,y) = 0.2 + x^2 + y^2 - 0.1 \\cos(6 \\pi x) - 0.1 \\cos(6 \\pi y)$$ \n\nfor $-1 \\leq x,y \\leq 1$.  This function is similar to the Rastrigin function and the global minimum value is $f(0,0) = 0$.  A contour plot, shown below, illustrates that there are many local minima (in the center of many of the small loops, some correspond to local maxima).  The <a href = \"http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\">tutorial</a> itself is worthy of a look and has a nice flow chart outlining how simulated annealing works.","metadata":{"hidden":true},"pos":22,"type":"cell"}
{"cell_type":"markdown","id":"a92e00","input":"The global minimum is at zero, so we'll right an objective function that returns the absolute value, because we don't want a negative function result, which we can get with this function. We'll also again add some noise, so the optimization function has to work a bit harder.","pos":56,"type":"cell"}
{"cell_type":"markdown","id":"a9ad7a","input":"# Global Optimization\n\nThe goal of global optimization is to find the global optimimum value which means we want to identify the best possible solution in the entire search space.  However for many problems the search space is too large and/or the function landscape is too complicated to guarantee that the best solution can be found.\n\nA metaheuristic algorithm attempts to find a good solution without any guarantee of being able to find the best solution.  Often metaheuristics are stochastic in nature, that is they incorporate randomness as an element of the search, but they aren't generally completely random in nature.  They often incorporate search patterns which are known to work well for the problem at hand.\n\nMetaheuristic algorithms try to find a compromise somewhere between randomly searching the search space and local search.  People often speak of the **exploration and exploitation tradeoff**.  Exploration ensures the algorithm reaches different promising regions of the search space, whereas exploitation ensures the searching of optimal solutions within the given region.  The trick is in finding the right balance. Go too far into exploitation and the algorithm gets stuck in local extrema, go too far to exploration and the algorithm will waste time on solutions that are less likely to be good and ignore the information already gathered.\n\nUnfortunately there is no single algorithm which works best for all classes of problems.  This is often referred to as a \"no free lunch theorem\" in optimization.  We'll focus on the two stochastic optimization algorithms that are described in your textbook:  simulated annealing and genetic algorithms.","metadata":{"hidden":true},"pos":3,"type":"cell"}
{"cell_type":"markdown","id":"b526a3","input":"This week we're going to continue our exploration of global optimization by looking at two global optimization algorithms:  Simulated Annealing and Bayesian Optimization. \n","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"b7994a","input":"## Using the `simanneal` package (video)","metadata":{"heading_collapsed":true,"hidden":true},"pos":13,"type":"cell"}
{"cell_type":"markdown","id":"bdc16e","input":"Copy the gerrymandering code from Lesson 4 and adapt the simulated annealing code above to try to find a solution in which republicans win 9 of the 10 districts.  Beware that you're trying to maximize the fitness.  The simplest way to use a minimization algorithm to maximize is to negate the fitness value.  If you start with simanneal_tsp then you should need only minor changes.\n\nYou'll have to change the values of the initial temperature, max_no_improve, and alpha.  The positive initial temperature should be similar to the initial fitness values (in magnitude).  Increasing max_no_improve allows the search to explore for longer.  Increasing alpha means the temperature doesn't decrease as quickly so that more uphill moves are allowed and the algorithm can explore more of the search space.","metadata":{"hidden":true},"pos":12,"type":"cell"}
{"cell_type":"markdown","id":"bf28b4","input":"#### Define an Acquisition Function\nNext we need what's called an acquisition function. Remember we said that Bayes Optimization learns as it goes. It does that by \"acquiring\" new data points. Each iteration of the algorithm will run the surrogate model and then \"acquire\" the sample point or points that are most likely to improve the overall results. Again, there are many ways to do approach determining what the best new points are. Three common approaches are:\n\n* Probability of Improvement (PI).\n* Expected Improvement (EI).\n* Lower Confidence Bound (LCB).\n\nThe probability of improvement is the simplest approach, so we'll use that for demonstration purposes. The formula is\n\n$PI = cdf((mu-best\\_mu)/stdev)$\n\nWhere $cdf$ is the normal cumulative distribution function (available in <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\">sklearn</a>), $mu$ is the mean of the surrogate function for the given sample x, $stdev$ is the standard deviation of the surrogate function for the given sample x (which we can get as a returned value from our Gaussian model) and $best\\_mu$ is the mean of the surrogate function for the best sample found so far. \n\nWe can add a very small number to the standard deviation to avoid a divide by zero error. Let's look at our acquisition function and our function to optimize our acquisition value. Finally, we'll return the value with the best probability of improvement.\n\n","pos":36,"type":"cell"}
{"cell_type":"markdown","id":"d256fb","input":"The `simanneal` package is pretty straightforward to use. Using the simanneal package has a couple of advantages over our version of simulated annealing above.  First, we don't have to worry about the algorithm framework.  Second, we don't have to worry about figuring out a temperature schedule.  While it's possible to specify a temperature schedule, it is far easier to use the `auto` scheduler and specify the approximate amount of time we'd like to wait for a solution\n\nThe package works by making an object of the Annealer class and then calling the anneal method on that object. To set up a problem we have to set three things in our instance of the Annealer class.\n\n1.  the state initializer \n2.  the move function that tells the anneal how to generate new moves\n3.  the fitness function (fitness is called energy in this package and it was called objective in the locsearch package in Lesson 4).\n\nThe anneal method appears to always find minima so you may have to negate your function if you want to find a maximum. The <a href=\"https://github.com/perrygeo/simanneal\">Github page</a> has some short documentation about the simanneal package.\n\nThe next cell is walkthrough of the code below.","metadata":{"hidden":true},"pos":14,"type":"cell"}
{"cell_type":"markdown","id":"d5a3b6","input":"## Simulated Annealing with TSP (video)","metadata":{"hidden":true},"pos":6,"type":"cell"}
{"cell_type":"markdown","id":"e0e2ff","input":"Let's take a look at what our surrogate function returns, before we do any optimization of results. We're writing a helper function for plotting here. It takes in our X and y values, the surrogate model, and title we want displayed, and the location of our global optimum (since we know it). Then, we'll fit our model to some random data and plot it against our surrogate function.","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"e38bea","input":"This package also contains some handy plots. First, let's plot convergence. This will tell us how quickly the best value was achieved. In this case, we achieved our best result by the 15th iteration.","pos":48,"type":"cell"}
{"cell_type":"markdown","id":"f1bc8a","input":"The gp_minimize can handle multi-dimensional functions, as long as what's returned from your objective function is a scalar value. Let's take a look at another one of the test functions for optimization, the Booth function. This function has 2 dimensions (x and y). The function is:\n\n$f(x,y)=(x+2y-7)^2+(2x+y-5)^2$\n\nThe bounds for this function are[-10,10] for both x and y, and the global optimum of 0 is at f(1,3). We can plot this function using a contour plot, like in the cell below.\n\n","pos":54,"type":"cell"}
{"cell_type":"markdown","id":"f9d9f9","input":"Think of simulated annealing as an enhanced local search that allows some moves that don't improve the best function value to try to climb\n\nIn a hill-climbing local search we only allow moves that increase the objective function value.  \n\nHere is our pseudo-code from the previous lesson for **Local Search:**\n```\n set starting state \n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum \n             remember it \n endwhile \n ```\n\nSimulated annealing is a trajectory based method for generating a sequence of solutions and is similar our basic \"hill-climbing\" local search algorithm.  In a strict hill-climbing algorithm we only allow uphill moves, but in simulated move we sometimes allow downhill moves and are more likely to allow downhill moves in the early part of the search.  The idea is that to find the tallest peak in a mountain range we have to first descend from a lower peak.\n\nThe probability of a downhill move is determined by a temperature parameter that decreases throughout the search.  The probability of a downhill move depends on the size of the downhill move compared to the temperature.  At high temperatures large and small downhill moves are probable, but as the temperature decreases only small downhill moves are probable so that the search performs similarly to a local search at low temperatures\n\nIn simulated annealing algorithm high temperature promotes exploration (global search) while low temperature promote exploitation (local search).  As the algorithm proceeds the temperature decreases and transitions from exploration to exploitation.\n\nHere is pseudo-code for **Simulated Annealing:**\n```\n set starting state and initial temperature\n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum or random # < probability determined by temperature\n             remember it\n     decrease temperature\n endwhile \n ```\n \nChoosing the initial temperature and the manner in which the temperature decreases are critical to the performance of simulated annealing.  We'll start with a temperature schedule that looks like this:\n$$ T = T_0 \\alpha^n.$$\nWhere $T_0$ is the initial temperature, $0 < \\alpha < 1,$ and $n$ is the number of iterations.   This is called geometric temperature decay, but many other choices are possible.  In the next section we'll demonstrate simulated annealing for the traveling salesman problem.\n\n\n\nIn the next section we present simulated annealing using our own code so that you can see how it works, but in general we'll use the `simanneal` package that will be introduced further below.","metadata":{"hidden":true},"pos":5,"type":"cell"}
{"id":0,"time":1630355687407,"type":"user"}
{"last_load":1630370791928,"type":"file"}