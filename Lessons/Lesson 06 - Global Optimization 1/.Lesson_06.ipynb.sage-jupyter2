{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-245cd5c9-58f1-48de-bbff-caf81b97d860.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1673888492684,"exec_count":1,"id":"870c47","input":"# Execute this cell first\n\n# plotting imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\n# display imports\nfrom IPython.display import display, IFrame\nfrom IPython.core.display import HTML\n\n# for playing videos, customize height and width if desired\n# keep a 16:9 ratio, e.g. 960 by 540, or 1280 by 720\ndef play_video(vid_name, w=640, h=360):\n    vid_path = \"https://media.uwex.edu/content/ds/ds775_r19/\"\n    return IFrame(vid_path + vid_name + \"/index.html\", width=w, height=h)\n\nfrom scipy.stats import norm\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import confusion_matrix\n\nfrom skopt.plots import plot_convergence\nfrom skopt import gp_minimize\nfrom scipy.optimize import minimize_scalar, dual_annealing\n\nfrom warnings import catch_warnings, simplefilter, filterwarnings\nimport numpy as np\nimport pandas as pd\nimport json\nfrom simanneal import Annealer","kernel":"python3","no_halt":true,"pos":0,"start":1673888489740,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888492754,"exec_count":2,"id":"cd635f","input":"# execute this cell for video\nplay_video(\"ds775_lesson5_simulated-anneal-tsp\")","kernel":"python3","metadata":{"code_folding":[],"hidden":true},"no_halt":true,"output":{"0":{"data":{"iframe":"dad24f9a5ed4560a357c10ce69663554b22c24ca","text/plain":"<IPython.lib.display.IFrame at 0x7f47d5ae4310>"},"exec_count":2}},"pos":8,"start":1673888492697,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888492840,"exec_count":3,"id":"820c37","input":"# load data (this may have to be adapted for different problems)\nwith open(\"data/HillierTSP.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\nindividual_size = tsp[\"TourSize\"]\n\n# define objective function\ndef tour_distance(individual, dist_mat):\n    distance = dist_mat[individual[-1]][individual[0]]\n    for gene1, gene2 in zip(individual[0:-1], individual[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\n# Random Number Seed\n# if you want reproducible results, then uncomment the following line\n# and play with the seed value until you get a result you like. If you run \n# it again with the same value, then you'll get the same result.\n# np.random.seed(123)\n\ndef simanneal_tsp(init_state, dist_mat, max_no_improve, init_temp, alpha): ###\n    '''\n    We use state to refer to the values of the input variable(s) for the objective function.\n    For the TSP problem, the state is a tour of the cities.\n    We use obj to refer to the objective function value.\n    For the TSP problem, obj is the total distance of the tour.\n    \n    To adapt this for another minimization problem, \n    only the lines with tour_distance and sub_tour_reversal need to change \n    to give a different objective function and a different move function.\n    Additional arguments to the objective function should be passed into the search function\n    similar to how we passed in dist_mat abov\n    '''\n\n    curr_state = init_state\n    curr_obj = tour_distance(curr_state, dist_mat) \n    best_state = curr_state  ###\n    best_obj = curr_obj  ###\n\n    # stop search if no better state is found within max_no_improve iterations\n    num_moves_no_improve = 0\n    iterations = 0\n    temp = init_temp\n\n    # save history for plotting after optimization\n    history = np.array([[iterations, curr_obj, best_obj]])  ###\n\n    while (num_moves_no_improve < max_no_improve):\n        num_moves_no_improve += 1\n        iterations += 1  # just for tracking\n        new_state = sub_tour_reversal(curr_state) # make a move \n        new_obj = tour_distance(new_state, dist_mat)\n        delta = curr_obj - new_obj ###\n        prob = np.exp(min(delta, 0) / temp) ### # compute prob accept uphill move\n\n        if new_obj < curr_obj or np.random.uniform() < prob : ### # accept if decrease or rand < prob\n            curr_state = new_state\n            curr_obj = new_obj\n            if curr_obj < best_obj: ### # keep track of best ever\n                best_state = curr_state ###\n                best_obj = curr_obj ###\n                num_moves_no_improve = 0 ###\n\n        temp *= alpha ###\n\n        history = np.vstack( (history, np.array([[iterations,curr_obj,best_obj]]) ) ) ###\n\n    return best_state, best_obj, iterations, history\n\n# apply the simanneal_tsp() function to our seven city problem\nnum_cities = len(distance_matrix)\ninit_tour = np.random.permutation(np.arange(num_cities))\n\nbest_tour, best_dist, iterations, history = simanneal_tsp(init_tour, distance_matrix, 200, 100, .995)\nbest_dist","kernel":"python3","metadata":{"hidden":true},"no_halt":true,"output":{"0":{"data":{"text/plain":"63"},"exec_count":3}},"pos":9,"scrolled":true,"start":1673888492759,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888494009,"exec_count":4,"id":"3fc085","input":"# plot the progress of the search for visualization\n# it isn't necessary to do this in the homework, but you're welcome to do so\n\nfig = plt.figure(figsize=(8, 6))\nline_min, = plt.plot(history[:,0], history[:,1], label='Curr. Dist.',color='red')\nline_curr, = plt.plot(history[:,0],history[:,2], label='Best. Dist.')\nplt.xlabel('Generation')\nplt.ylabel('Distance')\nplt.legend(handles=[line_curr, line_min])\nplt.title('Smallest Dist. Found: {:d}'.format(int(best_dist)));","kernel":"python3","metadata":{"hidden":true},"no_halt":true,"output":{"0":{"data":{"image/png":"1634ae6c98b338abf0ee86c3403a5102630debeb","text/plain":"<Figure size 576x432 with 1 Axes>"},"metadata":{"image/png":{"height":386,"width":502}}}},"pos":10,"start":1673888492864,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888494047,"exec_count":5,"id":"d6678f","input":"# code for generating 1000 items to be balanced into 4 groups\nnp.random.seed(123)\n\ntot_num_items = 1000 # should be divisible by 4\nnum_items = int(tot_num_items / 4)\nnum_groups = 4\n\nvalues = np.random.randint(10,100,size=num_items)\nvalues = np.hstack([values,values,values,values])\ngroups = np.random.randint(num_groups,size=1000)\n\nnp.random.seed()","kernel":"python3","no_halt":true,"pos":13,"start":1673888494041,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888494117,"exec_count":6,"id":"0e0ae9","input":"# execute this cell for video\nplay_video(\"ds775_lesson5_simanneal-package-on-tsp\")","kernel":"python3","metadata":{"hidden":true},"no_halt":true,"output":{"0":{"data":{"iframe":"dd3e0212143f7dae8388da18acd183fdc555a0ca","text/plain":"<IPython.lib.display.IFrame at 0x7f47b314cdf0>"},"exec_count":6}},"pos":16,"start":1673888494057,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888509242,"exec_count":7,"id":"4d4024","input":"# relies on data loaded in previous section\n\n# import numpy as np\n# from simanneal import Annealer\n\ndef tour_distance(tour, dist_mat):\n    tour = [int(t) for t in tour] # tour must be integers for indexing to work, this is just to be sure\n    distance = dist_mat[tour[-1]][tour[0]]\n    for gene1, gene2 in zip(tour[0:-1], tour[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\nclass TravellingSalesmanProblem(Annealer):\n\n    # pass extra data (the distance matrix) into the constructor\n    def __init__(self, state, distance_matrix):\n        self.distance_matrix = distance_matrix\n        super(TravellingSalesmanProblem, self).__init__(state)  # important!\n\n    def move(self):\n        self.state = sub_tour_reversal(self.state)\n\n    def energy(self):\n        return tour_distance(self.state, self.distance_matrix)\n\n# load data (this may have to be adapted for different problems)\nwith open(\"data/HillierTSP.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\ninit_tour = np.random.permutation(np.arange(len(distance_matrix))).astype(int).tolist()\n\ntsp = TravellingSalesmanProblem(init_tour, distance_matrix)\ntsp.set_schedule(tsp.auto(minutes=.2)) #set approximate time to find results\n\nbest_tour, best_dist = tsp.anneal()\n\nbest_dist","kernel":"python3","no_halt":true,"output":{"0":{"name":"stderr","text":" Temperature        Energy    Accept   Improve     Elapsed   Remaining\n\r     0.00000        249.00                         0:00:00            \r"},"1":{"name":"stderr","text":"\r   270.00000        160.00    88.30%    37.30%     0:00:00     0:00:03\r\r"},"10":{"name":"stderr","text":"\r   410.00000        335.00    91.20%    37.90%     0:00:01     0:00:02\r\r"},"100":{"name":"stderr","text":"\r     4.32303         65.00    26.44%     6.22%     0:00:08     0:00:03\r\r"},"101":{"name":"stderr","text":"\r     3.96713         69.00    25.94%     5.00%     0:00:08     0:00:03\r\r"},"102":{"name":"stderr","text":"\r     3.64053         65.00    20.89%     3.94%     0:00:09     0:00:03\r\r"},"103":{"name":"stderr","text":"\r     3.34082         65.00    22.78%     4.44%     0:00:09     0:00:03\r\r"},"104":{"name":"stderr","text":"\r     3.06579         69.00    22.78%     3.89%     0:00:09     0:00:03\r\r"},"105":{"name":"stderr","text":"\r     2.81339         65.00    24.28%     4.78%     0:00:09     0:00:03\r\r"},"106":{"name":"stderr","text":"\r     2.58178         63.00    23.22%     4.44%     0:00:09     0:00:03\r\r"},"107":{"name":"stderr","text":"\r     2.36923         63.00    20.50%     3.44%     0:00:09     0:00:02\r\r"},"108":{"name":"stderr","text":"\r     2.17418         69.00    21.67%     4.17%     0:00:09     0:00:02\r\r"},"109":{"name":"stderr","text":"\r     1.99519         66.00    24.00%     4.50%     0:00:09     0:00:02\r\r"},"11":{"name":"stderr","text":"\r   270.00000        424.00    87.10%    36.05%     0:00:01     0:00:01\r\r"},"110":{"name":"stderr","text":"\r     1.83093         64.00    20.28%     3.06%     0:00:09     0:00:02\r\r"},"111":{"name":"stderr","text":"\r     1.68020         65.00    21.89%     2.94%     0:00:09     0:00:02\r\r"},"112":{"name":"stderr","text":"\r     1.54188         64.00    17.22%     1.94%     0:00:10     0:00:02\r\r"},"113":{"name":"stderr","text":"\r     1.41494         63.00    16.22%     1.78%     0:00:10     0:00:02\r\r"},"114":{"name":"stderr","text":"\r     1.29845         63.00    17.83%     1.72%     0:00:10     0:00:02\r\r"},"115":{"name":"stderr","text":"\r     1.19156         63.00    18.33%     1.44%     0:00:10     0:00:01\r\r"},"116":{"name":"stderr","text":"\r     1.09346         65.00    17.28%     1.50%     0:00:10     0:00:01\r\r"},"117":{"name":"stderr","text":"\r     1.00344         64.00    15.17%     1.22%     0:00:10     0:00:01\r\r"},"118":{"name":"stderr","text":"\r     0.92083         63.00    17.50%     1.72%     0:00:10     0:00:01\r\r"},"119":{"name":"stderr","text":"\r     0.84502         65.00    17.72%     1.50%     0:00:10     0:00:01\r\r"},"12":{"name":"stderr","text":"\r   180.00000        242.00    79.35%    33.10%     0:00:01     0:00:01\r\r"},"120":{"name":"stderr","text":"\r     0.77546         63.00    15.56%     0.89%     0:00:10     0:00:01\r\r"},"121":{"name":"stderr","text":"\r     0.71162         64.00    14.56%     0.33%     0:00:10     0:00:01\r\r"},"122":{"name":"stderr","text":"\r     0.65303         63.00    13.72%     0.06%     0:00:11     0:00:01\r\r"},"123":{"name":"stderr","text":"\r     0.59927         64.00    15.83%     1.17%     0:00:11     0:00:01\r\r"},"124":{"name":"stderr","text":"\r     0.54993         63.00    16.06%     0.06%     0:00:11     0:00:00\r\r"},"125":{"name":"stderr","text":"\r     0.50466         63.00    15.17%     0.00%     0:00:11     0:00:00\r\r"},"126":{"name":"stderr","text":"\r     0.46311         63.00    16.00%     0.00%     0:00:11     0:00:00\r\r"},"127":{"name":"stderr","text":"\r     0.42499         63.00    12.61%     0.11%     0:00:11     0:00:00\r\r"},"128":{"name":"stderr","text":"\r     0.39000         63.00    15.67%     0.00%     0:00:11     0:00:00\r\r"},"129":{"data":{"text/plain":"63"},"exec_count":7},"13":{"name":"stderr","text":"\r   120.00000        158.00    74.45%    29.75%     0:00:02     0:00:01\r\r"},"14":{"name":"stderr","text":"\r    80.00000         68.00    62.50%    25.30%     0:00:02     0:00:01\r\r"},"15":{"name":"stderr","text":"\r    53.00000        154.00    49.60%    16.60%     0:00:02     0:00:01\r\r"},"16":{"name":"stderr","text":"\r    35.00000         63.00    34.25%    10.00%     0:00:02     0:00:01\r\r"},"17":{"name":"stderr","text":"\r    23.00000        151.00    31.00%     7.85%     0:00:02     0:00:01\r\r"},"18":{"name":"stderr","text":"\r    15.00000         69.00    28.50%     7.00%     0:00:02     0:00:01\r\r"},"19":{"name":"stderr","text":"\r    10.00000         66.00    27.75%     6.25%     0:00:02     0:00:01\r\r"},"2":{"name":"stderr","text":"\r   400.00000        250.00    92.00%    38.50%     0:00:00     0:00:03\r\r"},"20":{"name":"stderr","text":"\r     6.70000         68.00    26.15%     6.50%     0:00:02     0:00:00\r\r"},"21":{"name":"stderr","text":"\r     4.50000         63.00    24.15%     5.30%     0:00:03     0:00:00\r\r"},"22":{"name":"stderr","text":"\r     3.00000         64.00    21.40%     3.35%     0:00:03     0:00:00\r\r"},"23":{"name":"stderr","text":"\r     2.00000         65.00    22.25%     3.60%     0:00:03     0:00:00\r\r"},"24":{"name":"stderr","text":"\r     1.30000         66.00    18.25%     2.10%     0:00:03     0:00:00\r\r"},"25":{"name":"stderr","text":"\r     0.87000         65.00    16.35%     1.05%     0:00:03     0:00:00\r\r"},"26":{"name":"stderr","text":"\r     0.58000         63.00    17.25%     0.80%     0:00:04     0:00:00\r\r"},"27":{"name":"stderr","text":"\r     0.39000         63.00    13.75%     0.00%     0:00:04     0:00:00\r\r"},"28":{"name":"stderr","text":" Temperature        Energy    Accept   Improve     Elapsed   Remaining\n\r  2100.00000         63.00                         0:00:00            \r"},"29":{"name":"stderr","text":"\r  1927.11551        518.00    98.00%    42.06%     0:00:00     0:00:13\r\r"},"3":{"name":"stderr","text":"\r   600.00000        429.00    93.05%    39.15%     0:00:00     0:00:03\r\r"},"30":{"name":"stderr","text":"\r  1768.46391        426.00    97.72%    41.28%     0:00:00     0:00:14\r\r"},"31":{"name":"stderr","text":"\r  1622.87345        334.00    97.44%    41.72%     0:00:00     0:00:13\r\r"},"32":{"name":"stderr","text":"\r  1489.26886        423.00    97.83%    41.78%     0:00:00     0:00:12\r\r"},"33":{"name":"stderr","text":"\r  1366.66339         66.00    97.67%    40.44%     0:00:01     0:00:12\r\r"},"34":{"name":"stderr","text":"\r  1254.15153        246.00    96.89%    41.50%     0:00:01     0:00:11\r\r"},"35":{"name":"stderr","text":"\r  1150.90232        159.00    96.89%    40.94%     0:00:01     0:00:10\r\r"},"36":{"name":"stderr","text":"\r  1056.15320        251.00    96.56%    40.94%     0:00:01     0:00:10\r\r"},"37":{"name":"stderr","text":"\r   969.20439        159.00    97.22%    42.28%     0:00:01     0:00:10\r\r"},"38":{"name":"stderr","text":"\r   889.41372        244.00    96.28%    41.28%     0:00:01     0:00:10\r\r"},"39":{"name":"stderr","text":"\r   816.19190        426.00    96.11%    40.11%     0:00:01     0:00:10\r\r"},"4":{"name":"stderr","text":"\r   900.00000        157.00    96.40%    40.55%     0:00:01     0:00:02\r\r"},"40":{"name":"stderr","text":"\r   748.99813        339.00    96.17%    39.33%     0:00:01     0:00:10\r\r"},"41":{"name":"stderr","text":"\r   687.33615        420.00    94.22%    40.00%     0:00:01     0:00:10\r\r"},"42":{"name":"stderr","text":"\r   630.75055        426.00    93.94%    38.33%     0:00:02     0:00:10\r\r"},"43":{"name":"stderr","text":"\r   578.82342        249.00    94.28%    39.67%     0:00:02     0:00:09\r\r"},"44":{"name":"stderr","text":"\r   531.17123        162.00    92.89%    39.94%     0:00:02     0:00:09\r\r"},"45":{"name":"stderr","text":"\r   487.44206        337.00    92.56%    38.56%     0:00:02     0:00:09\r\r"},"46":{"name":"stderr","text":"\r   447.31293        336.00    92.72%    38.06%     0:00:02     0:00:09\r\r"},"47":{"name":"stderr","text":"\r   410.48747         65.00    92.17%    38.94%     0:00:02     0:00:09\r\r"},"48":{"name":"stderr","text":"\r   376.69370        242.00    89.11%    36.83%     0:00:02     0:00:09\r\r"},"49":{"name":"stderr","text":"\r   345.68204        426.00    90.94%    37.78%     0:00:02     0:00:09\r\r"},"5":{"name":"stderr","text":"\r  1400.00000        339.00    97.15%    40.60%     0:00:01     0:00:02\r\r"},"50":{"name":"stderr","text":"\r   317.22343        335.00    90.44%    36.89%     0:00:03     0:00:09\r\r"},"51":{"name":"stderr","text":"\r   291.10772        159.00    89.39%    38.06%     0:00:03     0:00:09\r\r"},"52":{"name":"stderr","text":"\r   267.14200        250.00    86.94%    36.89%     0:00:03     0:00:09\r\r"},"53":{"name":"stderr","text":"\r   245.14928         66.00    86.33%    35.94%     0:00:03     0:00:09\r\r"},"54":{"name":"stderr","text":"\r   224.96713        244.00    86.39%    35.44%     0:00:03     0:00:08\r\r"},"55":{"name":"stderr","text":"\r   206.44650        154.00    84.17%    35.11%     0:00:03     0:00:08\r\r"},"56":{"name":"stderr","text":"\r   189.45060        157.00    82.06%    33.39%     0:00:03     0:00:08\r\r"},"57":{"name":"stderr","text":"\r   173.85390        336.00    82.39%    33.28%     0:00:03     0:00:08\r\r"},"58":{"name":"stderr","text":"\r   159.54121        156.00    79.22%    32.78%     0:00:03     0:00:08\r\r"},"59":{"name":"stderr","text":"\r   146.40683        157.00    77.39%    31.50%     0:00:03     0:00:08\r\r"},"6":{"name":"stderr","text":"\r  2100.00000        336.00    98.60%    42.85%     0:00:01     0:00:02\r\r"},"60":{"name":"stderr","text":"\r   134.35375         69.00    75.89%    30.17%     0:00:03     0:00:07\r\r"},"61":{"name":"stderr","text":"\r   123.29295        243.00    73.83%    30.61%     0:00:04     0:00:07\r\r"},"62":{"name":"stderr","text":"\r   113.14274        242.00    74.11%    29.83%     0:00:04     0:00:07\r\r"},"63":{"name":"stderr","text":"\r   103.82816        254.00    69.00%    26.78%     0:00:04     0:00:07\r\r"},"64":{"name":"stderr","text":"\r    95.28041        342.00    67.06%    26.06%     0:00:04     0:00:07\r\r"},"65":{"name":"stderr","text":"\r    87.43636        155.00    67.83%    27.72%     0:00:04     0:00:07\r\r"},"66":{"name":"stderr","text":"\r    80.23808        243.00    62.22%    23.17%     0:00:04     0:00:07\r\r"},"67":{"name":"stderr","text":"\r    73.63240        253.00    58.67%    21.06%     0:00:04     0:00:07\r\r"},"68":{"name":"stderr","text":"\r    67.57054        156.00    57.06%    21.72%     0:00:05     0:00:07\r\r"},"69":{"name":"stderr","text":"\r    62.00774         66.00    56.83%    21.61%     0:00:05     0:00:07\r\r"},"7":{"name":"stderr","text":"\r  1400.00000        428.00    96.90%    40.35%     0:00:01     0:00:02\r\r"},"70":{"name":"stderr","text":"\r    56.90289         64.00    51.17%    18.50%     0:00:05     0:00:07\r\r"},"71":{"name":"stderr","text":"\r    52.21831        156.00    50.22%    17.78%     0:00:05     0:00:07\r\r"},"72":{"name":"stderr","text":"\r    47.91938        156.00    47.67%    17.11%     0:00:05     0:00:07\r\r"},"73":{"name":"stderr","text":"\r    43.97438        240.00    45.17%    15.06%     0:00:05     0:00:06\r\r"},"74":{"name":"stderr","text":"\r    40.35414         65.00    43.00%    13.72%     0:00:05     0:00:06\r\r"},"75":{"name":"stderr","text":"\r    37.03195         63.00    40.39%    12.33%     0:00:06     0:00:06\r\r"},"76":{"name":"stderr","text":"\r    33.98326         68.00    36.00%    11.06%     0:00:06     0:00:06\r\r"},"77":{"name":"stderr","text":"\r    31.18556         65.00    35.67%     9.83%     0:00:06     0:00:06\r\r"},"78":{"name":"stderr","text":"\r    28.61818         63.00    31.94%     9.00%     0:00:06     0:00:06\r\r"},"79":{"name":"stderr","text":"\r    26.26216         66.00    30.94%     9.00%     0:00:06     0:00:06\r\r"},"8":{"name":"stderr","text":"\r   930.00000        336.00    96.30%    40.75%     0:00:01     0:00:02\r\r"},"80":{"name":"stderr","text":"\r    24.10010         65.00    32.28%     8.72%     0:00:06     0:00:06\r\r"},"81":{"name":"stderr","text":"\r    22.11604         65.00    31.72%     8.39%     0:00:06     0:00:06\r\r"},"82":{"name":"stderr","text":"\r    20.29531         66.00    30.39%     8.06%     0:00:06     0:00:05\r\r"},"83":{"name":"stderr","text":"\r    18.62448         69.00    28.44%     7.00%     0:00:06     0:00:05\r\r"},"84":{"name":"stderr","text":"\r    17.09120         65.00    29.44%     7.06%     0:00:07     0:00:05\r\r"},"85":{"name":"stderr","text":"\r    15.68415         66.00    27.50%     6.61%     0:00:07     0:00:05\r\r"},"86":{"name":"stderr","text":"\r    14.39294         68.00    30.22%     7.67%     0:00:07     0:00:05\r\r"},"87":{"name":"stderr","text":"\r    13.20803         64.00    26.89%     6.78%     0:00:07     0:00:05\r\r"},"88":{"name":"stderr","text":"\r    12.12067         65.00    29.94%     6.72%     0:00:07     0:00:05\r\r"},"89":{"name":"stderr","text":"\r    11.12282         65.00    28.06%     6.56%     0:00:07     0:00:04\r\r"},"9":{"name":"stderr","text":"\r   620.00000        340.00    93.95%    38.75%     0:00:01     0:00:02\r\r"},"90":{"name":"stderr","text":"\r    10.20712         68.00    26.56%     5.78%     0:00:07     0:00:04\r\r"},"91":{"name":"stderr","text":"\r     9.36681         65.00    27.33%     6.17%     0:00:07     0:00:04\r\r"},"92":{"name":"stderr","text":"\r     8.59568         69.00    25.11%     5.50%     0:00:07     0:00:04\r\r"},"93":{"name":"stderr","text":"\r     7.88803         65.00    25.72%     5.89%     0:00:07     0:00:04\r\r"},"94":{"name":"stderr","text":"\r     7.23864         69.00    26.00%     6.06%     0:00:07     0:00:04\r\r"},"95":{"name":"stderr","text":"\r     6.64272         66.00    28.39%     6.72%     0:00:08     0:00:04\r\r"},"96":{"name":"stderr","text":"\r     6.09585         63.00    25.61%     5.89%     0:00:08     0:00:04\r\r"},"97":{"name":"stderr","text":"\r     5.59400         63.00    24.28%     4.83%     0:00:08     0:00:04\r\r"},"98":{"name":"stderr","text":"\r     5.13347         63.00    24.39%     4.44%     0:00:08     0:00:04\r\r"},"99":{"name":"stderr","text":"\r     4.71085         66.00    23.06%     4.61%     0:00:08     0:00:03\r\r"}},"pos":17,"start":1673888494268,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888509280,"exec_count":8,"id":"852ced","input":"# code for generating 1000 items to be balanced into 4 groups\nnp.random.seed(123)\n\ntot_num_items = 1000 # should be divisible by 4\nnum_items = int(tot_num_items / 4)\nnum_groups = 4\n\nvalues = np.random.randint(10,100,size=num_items)\nvalues = np.hstack([values,values,values,values])\ngroups = np.random.randint(num_groups,size=1000)\n\nnp.random.seed()","kernel":"python3","no_halt":true,"pos":21,"start":1673888509265,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888511336,"exec_count":9,"id":"0a0f6c","input":"# define objective function and show a contour plot\n\n# note that xy here represents a numpy array with two elements (scalars x and y)\ndef bumpy(xy):\n    # xy can be any length ... the length of xy determines the number of input variables and is called the dimension\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n\n# we could have written the objective function like this for transparency:\n# if the argument is a list with [ numpy array of x's, numpy array of y's]\n# def bumpy(xy):\n#     x = xy[0]\n#     y = xy[1]\n#     obj = 0.2 + x**2 + y**2 - 0.1*np.cos(6*np.pi*x) - 0.1*np.cos(6*np.pi*y)\n#     return obj\n# see script for details of plot\n%run scripts/bumpy_contours.py","kernel":"python3","no_halt":true,"output":{"0":{"data":{"image/png":"1b6fc80a78660662d709054ef38728f6f8ef4683","text/plain":"<Figure size 576x576 with 1 Axes>"},"metadata":{"image/png":{"height":494,"width":523}}}},"pos":26,"start":1673888509289,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888515174,"exec_count":10,"id":"6ffce3","input":"%run scripts/bumpy_2d.py","kernel":"python3","no_halt":true,"output":{"0":{"data":{"iframe":"caf0b5de8c8d536da3c05faa65b114d4a5e16f3f"}}},"pos":28,"scrolled":true,"start":1673888511570,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888515293,"exec_count":11,"id":"77a854","input":"# execute for dual_annealing documentation\n?dual_annealing","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m\n\u001b[0mdual_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mlocal_search_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0minitial_temp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5230.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mrestart_temp_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mvisit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.62\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0maccept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmaxfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000000.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mno_local_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nFind the global minimum of a function using Dual Annealing.\n\nParameters\n----------\nfunc : callable\n    The objective function to be minimized. Must be in the form\n    ``f(x, *args)``, where ``x`` is the argument in the form of a 1-D array\n    and ``args`` is a  tuple of any additional fixed parameters needed to\n    completely specify the function.\nbounds : sequence, shape (n, 2)\n    Bounds for variables.  ``(min, max)`` pairs for each element in ``x``,\n    defining bounds for the objective function parameter.\nargs : tuple, optional\n    Any additional fixed parameters needed to completely specify the\n    objective function.\nmaxiter : int, optional\n    The maximum number of global search iterations. Default value is 1000.\nlocal_search_options : dict, optional\n    Extra keyword arguments to be passed to the local minimizer\n    (`minimize`). Some important options could be:\n    ``method`` for the minimizer method to use and ``args`` for\n    objective function additional arguments.\ninitial_temp : float, optional\n    The initial temperature, use higher values to facilitates a wider\n    search of the energy landscape, allowing dual_annealing to escape\n    local minima that it is trapped in. Default value is 5230. Range is\n    (0.01, 5.e4].\nrestart_temp_ratio : float, optional\n    During the annealing process, temperature is decreasing, when it\n    reaches ``initial_temp * restart_temp_ratio``, the reannealing process\n    is triggered. Default value of the ratio is 2e-5. Range is (0, 1).\nvisit : float, optional\n    Parameter for visiting distribution. Default value is 2.62. Higher\n    values give the visiting distribution a heavier tail, this makes\n    the algorithm jump to a more distant region. The value range is (0, 3].\naccept : float, optional\n    Parameter for acceptance distribution. It is used to control the\n    probability of acceptance. The lower the acceptance parameter, the\n    smaller the probability of acceptance. Default value is -5.0 with\n    a range (-1e4, -5].\nmaxfun : int, optional\n    Soft limit for the number of objective function calls. If the\n    algorithm is in the middle of a local search, this number will be\n    exceeded, the algorithm will stop just after the local search is\n    done. Default value is 1e7.\nseed : {int, `~numpy.random.RandomState`, `~numpy.random.Generator`}, optional\n    If `seed` is not specified the `~numpy.random.RandomState` singleton is\n    used.\n    If `seed` is an int, a new ``RandomState`` instance is used, seeded\n    with `seed`.\n    If `seed` is already a ``RandomState`` or ``Generator`` instance, then\n    that instance is used.\n    Specify `seed` for repeatable minimizations. The random numbers\n    generated with this seed only affect the visiting distribution function\n    and new coordinates generation.\nno_local_search : bool, optional\n    If `no_local_search` is set to True, a traditional Generalized\n    Simulated Annealing will be performed with no local search\n    strategy applied.\ncallback : callable, optional\n    A callback function with signature ``callback(x, f, context)``,\n    which will be called for all minima found.\n    ``x`` and ``f`` are the coordinates and function value of the\n    latest minimum found, and ``context`` has value in [0, 1, 2], with the\n    following meaning:\n\n        - 0: minimum detected in the annealing process.\n        - 1: detection occurred in the local search process.\n        - 2: detection done in the dual annealing process.\n\n    If the callback implementation returns True, the algorithm will stop.\nx0 : ndarray, shape(n,), optional\n    Coordinates of a single N-D starting point.\n\nReturns\n-------\nres : OptimizeResult\n    The optimization result represented as a `OptimizeResult` object.\n    Important attributes are: ``x`` the solution array, ``fun`` the value\n    of the function at the solution, and ``message`` which describes the\n    cause of the termination.\n    See `OptimizeResult` for a description of other attributes.\n\nNotes\n-----\nThis function implements the Dual Annealing optimization. This stochastic\napproach derived from [3]_ combines the generalization of CSA (Classical\nSimulated Annealing) and FSA (Fast Simulated Annealing) [1]_ [2]_ coupled\nto a strategy for applying a local search on accepted locations [4]_.\nAn alternative implementation of this same algorithm is described in [5]_\nand benchmarks are presented in [6]_. This approach introduces an advanced\nmethod to refine the solution found by the generalized annealing\nprocess. This algorithm uses a distorted Cauchy-Lorentz visiting\ndistribution, with its shape controlled by the parameter :math:`q_{v}`\n\n.. math::\n\n    g_{q_{v}}(\\Delta x(t)) \\propto \\frac{ \\\n    \\left[T_{q_{v}}(t) \\right]^{-\\frac{D}{3-q_{v}}}}{ \\\n    \\left[{1+(q_{v}-1)\\frac{(\\Delta x(t))^{2}} { \\\n    \\left[T_{q_{v}}(t)\\right]^{\\frac{2}{3-q_{v}}}}}\\right]^{ \\\n    \\frac{1}{q_{v}-1}+\\frac{D-1}{2}}}\n\nWhere :math:`t` is the artificial time. This visiting distribution is used\nto generate a trial jump distance :math:`\\Delta x(t)` of variable\n:math:`x(t)` under artificial temperature :math:`T_{q_{v}}(t)`.\n\nFrom the starting point, after calling the visiting distribution\nfunction, the acceptance probability is computed as follows:\n\n.. math::\n\n    p_{q_{a}} = \\min{\\{1,\\left[1-(1-q_{a}) \\beta \\Delta E \\right]^{ \\\n    \\frac{1}{1-q_{a}}}\\}}\n\nWhere :math:`q_{a}` is a acceptance parameter. For :math:`q_{a}<1`, zero\nacceptance probability is assigned to the cases where\n\n.. math::\n\n    [1-(1-q_{a}) \\beta \\Delta E] < 0\n\nThe artificial temperature :math:`T_{q_{v}}(t)` is decreased according to\n\n.. math::\n\n    T_{q_{v}}(t) = T_{q_{v}}(1) \\frac{2^{q_{v}-1}-1}{\\left( \\\n    1 + t\\right)^{q_{v}-1}-1}\n\nWhere :math:`q_{v}` is the visiting parameter.\n\n.. versionadded:: 1.2.0\n\nReferences\n----------\n.. [1] Tsallis C. Possible generalization of Boltzmann-Gibbs\n    statistics. Journal of Statistical Physics, 52, 479-487 (1998).\n.. [2] Tsallis C, Stariolo DA. Generalized Simulated Annealing.\n    Physica A, 233, 395-406 (1996).\n.. [3] Xiang Y, Sun DY, Fan W, Gong XG. Generalized Simulated\n    Annealing Algorithm and Its Application to the Thomson Model.\n    Physics Letters A, 233, 216-220 (1997).\n.. [4] Xiang Y, Gong XG. Efficiency of Generalized Simulated\n    Annealing. Physical Review E, 62, 4473 (2000).\n.. [5] Xiang Y, Gubian S, Suomela B, Hoeng J. Generalized\n    Simulated Annealing for Efficient Global Optimization: the GenSA\n    Package for R. The R Journal, Volume 5/1 (2013).\n.. [6] Mullen, K. Continuous Global Optimization in R. Journal of\n    Statistical Software, 60(6), 1 - 45, (2014).\n    :doi:`10.18637/jss.v060.i06`\n\nExamples\n--------\nThe following example is a 10-D problem, with many local minima.\nThe function involved is called Rastrigin\n(https://en.wikipedia.org/wiki/Rastrigin_function)\n\n>>> from scipy.optimize import dual_annealing\n>>> func = lambda x: np.sum(x*x - 10*np.cos(2*np.pi*x)) + 10*np.size(x)\n>>> lw = [-5.12] * 10\n>>> up = [5.12] * 10\n>>> ret = dual_annealing(func, bounds=list(zip(lw, up)), seed=1234)\n>>> ret.x\narray([-4.26437714e-09, -3.91699361e-09, -1.86149218e-09, -3.97165720e-09,\n       -6.29151648e-09, -6.53145322e-09, -3.93616815e-09, -6.55623025e-09,\n       -6.05775280e-09, -5.00668935e-09]) # may vary\n>>> ret.fun\n0.000000\n\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.8/site-packages/scipy/optimize/_dual_annealing.py\n\u001b[0;31mType:\u001b[0m      function\n"},"start":0}},"pos":32,"scrolled":true,"start":1673888515184,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888515658,"exec_count":12,"id":"74353a","input":"def bumpy(xy):\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n\nbounds = [(-1,1),(-1,1)] # one tuple for each dimension\nres = dual_annealing(bumpy, bounds)\n\nprint(f'The minimum value is {res.fun} and occurs at x = {res.x[0]}, y = {res.x[1]}')\n\nprint(f'\\n{res.nfev} evaluations of the bumpy function were needed.')","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"The minimum value is 6.2727600891321345e-15 and occurs at x = -1.762142618197849e-08, y = -4.890044917693503e-09\n\n4064 evaluations of the bumpy function were needed.\n"}},"pos":34,"start":1673888515307,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888515727,"exec_count":13,"id":"61820c","input":"# Execute for Video\nplay_video(\"ds775_lesson6_bayesian-optimization-overview\")","kernel":"python3","no_halt":true,"output":{"0":{"data":{"iframe":"238b0e890ca2335d61c35ee4b4b47de901b688e7","text/plain":"<IPython.lib.display.IFrame at 0x7f47ae2dc970>"},"exec_count":13}},"pos":37,"start":1673888515675,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888516381,"exec_count":14,"id":"4940b7","input":"def objective(x, noise_level = 0):\n    y = x * np.sin(x) + np.random.normal(loc=0,scale=noise_level)\n    return(float(y))\n\nnoise = 0\nX_plot = np.arange(0,10.05,.05).reshape(-1,1)\ny_plot = np.asarray([objective(x, noise) for x in X_plot])\nplt.plot(X_plot,y_plot,'g--',label='Actual Function')\nplt.plot(4.91,-4.81,'r.',markersize=20,label='Local Min.')\nplt.plot(10,-5.44,'b.',markersize=20,label='Global Min.')\nplt.legend()","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"<matplotlib.legend.Legend at 0x7f47b0cbd4f0>"},"exec_count":14},"1":{"data":{"image/png":"c27df66016f1c321ac48c1d4108144448206e3c9","text/plain":"<Figure size 864x504 with 1 Axes>"},"metadata":{"image/png":{"height":411,"width":705}}}},"pos":39,"start":1673888515742,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888517168,"exec_count":15,"id":"3942a7","input":"noise = 0\nX_plot = np.arange(0,10.05,.05).reshape(-1,1)\ny_plot = np.asarray([objective(x, noise) for x in X_plot])\nplt.plot(X_plot,y_plot,'g--',label='Actual Function')\n\nnoise = 0.1\nX_sample = np.asarray([0,2,4,7,9]).reshape(-1,1)\ny_sample = np.asarray([objective(x,noise) for x in X_sample]).reshape(-1,1)\nplt.plot(X_sample[:-1],y_sample[:-1],'m.',markersize=20,linestyle='',label='Sampled Points')\nplt.plot(X_sample[-1],y_sample[-1],'mX',markersize=15,linestyle='')\nplt.plot(4.91,-4.81,'r.',markersize=20,label='Local Min.')\nplt.plot(10,-5.44,'b.',markersize=20,label='Global Min.')\nplt.legend();","kernel":"python3","no_halt":true,"output":{"0":{"data":{"image/png":"9832c493caf12ccb8e144599bcb7bbda04819eb9","text/plain":"<Figure size 864x504 with 1 Axes>"},"metadata":{"image/png":{"height":411,"width":705}}}},"pos":41,"start":1673888516395,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888517182,"exec_count":16,"id":"9ea61e","input":"# surrogate or approximation for the objective function\ndef surrogate(X, model):\n    # catch any warning generated when making a prediction\n    with catch_warnings():\n\n        # ignore generated warnings\n        simplefilter(\"ignore\")\n        return model.predict(X, return_std=True)","kernel":"python3","no_halt":true,"pos":43,"start":1673888517177,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888517204,"exec_count":17,"id":"b74ade","input":"# define the model\nmodel = GaussianProcessRegressor()\n# fit the model\nmodel.fit(X_sample, y_sample)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"GaussianProcessRegressor()"},"exec_count":17}},"pos":45,"start":1673888517186,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888518551,"exec_count":18,"id":"d776b7","input":"y_surrogate, sd = surrogate(X_plot, model)\ny_surrogate = y_surrogate.reshape(-1,1)\nsd = sd.reshape(-1,1)\n\nplt.plot(X_sample[:-1],y_sample[:-1],'m.',markersize=20,linestyle='',label='Sampled Points')\nplt.plot(X_sample[-1],y_sample[-1],'mX',markersize=15,linestyle='')\nplt.plot(X_plot, y_plot,'g--',label='Actual Function')\nplt.plot(X_plot, y_surrogate,'b',label='Surrogate Function')\nplt.fill_between(X_plot.flatten(),(y_surrogate+sd+noise).flatten(),(y_surrogate-sd-noise).flatten(),color='blue',alpha=0.1,label='Uncertainty')\nplt.legend();","kernel":"python3","no_halt":true,"output":{"0":{"data":{"image/png":"84e65f3a2c5f692142e1d984568bf30dbc71cae1","text/plain":"<Figure size 864x504 with 1 Axes>"},"metadata":{"image/png":{"height":411,"width":705}}}},"pos":47,"start":1673888517271,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888519982,"exec_count":19,"id":"bbd2f4","input":"def plot_bayesian_opt(X,y,model,objective,axis,noise = 0, kappa = 1):\n    X_plot = np.arange(0,10,.05).reshape(-1,1)\n    y_obj = np.asarray([objective(x, noise_level = 0) for x in X_plot]) # no noise for exact eval\n    y_surrogate, sd = surrogate(X_plot, model)\n    y_surrogate = y_surrogate.reshape(-1,1)\n    sd = sd.reshape(-1,1)\n    axis.plot(X_sample[:-1],y_sample[:-1],'m.',markersize=20,linestyle='',label='Sampled Points')\n    axis.plot(X_sample[-1],y_sample[-1],'mX',markersize=15,linestyle='')\n    axis.plot(X_plot, y_obj,'g--',label='Actual Function')\n    axis.plot(X_plot, y_surrogate,'b',label='Surrogate Function')\n    axis.plot(X_plot, y_surrogate-kappa*sd-noise,'r',label='Acquisition Function')\n    axis.fill_between(X_plot.flatten(),(y_surrogate+kappa*sd+noise).flatten(),(y_surrogate-kappa*sd-noise).flatten(),color='blue',alpha=0.1,label='Uncertainty')\n    axis.legend()\n    \nfig, (ax1, ax2) = plt.subplots(1,2,figsize=(20,8))\n\nax1.set_title('kappa = 1, small kappa for exploitation (local search)')\nplot_bayesian_opt(X_sample,y_sample,model,objective,ax1,noise=0.1,kappa = 1)\nax1.plot([4.32,4.32],[-5,8.5],'k--',label='Next x')\nax1.set_ylim([-5,8.5])\nax1.legend();\n\nax2.set_title('kappa = 10, large kappa for exploration (global search)')\nplot_bayesian_opt(X_sample,y_sample,model,objective,ax2,noise = 0.1,kappa = 10)\nax2.plot([5.12,5.12],[-11,11],'k--',label='Next x')\nax2.set_ylim([-10,10.5])\nax2.legend();","kernel":"python3","no_halt":true,"output":{"0":{"data":{"image/png":"ca6d32d5751b32febdf88eb52602b16268c02f06","text/plain":"<Figure size 1440x576 with 2 Axes>"},"metadata":{"image/png":{"height":481,"width":1152}}}},"pos":49,"start":1673888518584,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888520643,"exec_count":20,"id":"be181b","input":"def acquisition_fun_lcb(X, model, kappa):\n    x2 = np.array(X).reshape(-1,1)\n    y,sd = surrogate(x2, model)\n    y = y.reshape(-1,1)\n    sd = sd.reshape(-1,1)\n    out = (y-kappa*sd).flatten()\n    return( out )\n\ndef acquire_next_point(model, kappa):\n    x_grid = np.arange(0,10.01,.01) # check points spaced every 0.01\n    y_grid = np.asarray([acquisition_fun_lcb(x,model,kappa) for x in x_grid]).reshape(-1,1)\n    min_y_idx = np.argmin(y_grid)\n    return x_grid[min_y_idx]\n\n# get next point when kappa = 1\nx1 = acquire_next_point(model,1)\nprint(f'Next sample point with kappa = 1 is {x1:.2f}')\n\n# get next point when kappa = 10\nx2 = acquire_next_point(model,10)\nprint(f'Next sample point with kappa = 10 is {x2:.2f}')","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"Next sample point with kappa = 1 is 4.31\nNext sample point with kappa = 10 is 5.12\n"}},"pos":51,"start":1673888519988,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888520678,"exec_count":21,"id":"ca70f8","input":"# reinitialize the sample data to start fresh\n\nnoise = 0.1\nkappa = 2\nX_sample = np.asarray([0,2,4,7,9]).reshape(-1,1)\ny_sample = np.asarray([objective(x,noise) for x in X_sample]).reshape(-1,1)\n\n# define and fit the model\nmodel = GaussianProcessRegressor()\nmodel.fit(X_sample, y_sample)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"GaussianProcessRegressor()"},"exec_count":21}},"pos":53,"start":1673888520668,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888522264,"exec_count":22,"id":"a3942f","input":"# each time this cell is executed on iteration of Bayesian Optimization occurs up to the point where the new point is selected, \n# on the next iteration it will be plotted\nkappa = 10\n\n# get next x coordinate\nx = acquire_next_point(model,kappa)\n\n# evaluate objective function to get new y coordinate (includes .1 noise)\ny = objective(x, noise_level = noise)\n\nprint(f'New point for sample: ({x:0.2f},{y:0.2f})')\n\n# plot to see where next point will be added\nfig = plt.figure(figsize = [10,6])\nax = plt.gca()\nplot_bayesian_opt(X_sample,y_sample,model,objective,ax,kappa = kappa)\nylim = ax.get_ylim()\nax.plot([x,x],ylim,'k--',label='Next x')\nax.legend()\n\n# now add the point to our sample\nX_sample = np.vstack((X_sample, [[x]]))\ny_sample = np.vstack((y_sample, [[y]]))\n\nprint(f'Smallest function value so far {np.min(y_sample):0.2f}')\n\n# refit the model\nmodel.fit(X_sample,y_sample)","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"New point for sample: (5.12,-4.59)\nSmallest function value so far -4.59\n"},"1":{"data":{"text/plain":"GaussianProcessRegressor()"},"exec_count":22},"2":{"data":{"image/png":"df8400e3e19a57d3908928a867d4d5b8345cedf6","text/plain":"<Figure size 720x432 with 1 Axes>"},"metadata":{"image/png":{"height":357,"width":600}}}},"pos":55,"start":1673888520684,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888522318,"exec_count":23,"id":"c101f7","input":"# execute for video\nplay_video(\"ds775_lesson6_bayesian-optimization-scikit-optimize\")","kernel":"python3","no_halt":true,"output":{"0":{"data":{"iframe":"83cbff766f644f8ddfb746cf64f9eb6af13d8e93","text/plain":"<IPython.lib.display.IFrame at 0x7f47a7fb0850>"},"exec_count":23}},"pos":57,"start":1673888522274,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888522350,"exec_count":24,"id":"c0e845","input":"noise = .1\n\ndef objective(x, noise_level = noise):\n    y = x * np.sin(x) + np.random.normal(loc=0,scale=noise_level)\n    return(float(y))","kernel":"python3","no_halt":true,"pos":59,"start":1673888522335,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888529381,"exec_count":25,"id":"03eb2e","input":"filterwarnings('ignore')\n\nnp.random.seed(42) #adding random seed here, too, for the noise factor\n#call the optimization.\nres = gp_minimize(objective,                  # the function to minimize\n                  [(0.0,10.0)],      # the bounds on each dimension of x\n                  acq_func=\"LCB\",      # the acquisition function\n                  kappa = 10,\n                  n_calls=20,         # the number of evaluations of the objective function\n                  n_random_starts=5,  # the number of random initialization points\n                  random_state=42)   # the random seed\n\nprint(f'The minimum value of f(x) is {res.fun:0.4f} and occurs at x={res.x[0]:0.4f}')\nprint(f'Recall that the objective function may include noise, so the optimized function value may not be exact.')","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"The minimum value of f(x) is -5.6315 and occurs at x=10.0000\nRecall that the objective function may include noise, so the optimized function value may not be exact.\n"}},"pos":61,"start":1673888522379,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888530714,"exec_count":26,"id":"36a02e","input":"fig = plt.figure(figsize=(10,6)) # we initialize the plot so we can control dimensions\nax = fig.add_axes\nplot_convergence(res,ax);","kernel":"python3","no_halt":true,"output":{"0":{"data":{"image/png":"a19e601f97a5ceb95c72e9990828d6ff1a0e90f0","text/plain":"<Figure size 720x432 with 1 Axes>"},"metadata":{"image/png":{"height":386,"width":608}}}},"pos":63,"start":1673888529390,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888537083,"exec_count":27,"id":"41962d","input":"filterwarnings('ignore') # suppress some of the warnings from B.O.\n\nnp.random.seed(42)\n\n# same \"bumpy\" function as in simulated annealing, just written differently\n# assumes xy is a list or array-like with xy = [x, y]\ndef bumpy(xy):\n    x = xy[0]\n    y = xy[1]\n    obj = 0.2 + x**2 + y**2 - 0.1 * np.cos(6*np.pi*x) - 0.1 * np.cos(6*np.pi*y)\n    return obj\n\n#call the optimization.\nres = gp_minimize(bumpy,                  # the function to minimize\n                  [(-1, 1), (-1, 1)],      # the bounds on each dimension of x\n                 acq_func=\"EI\",      # the acquisition function \n                  n_calls=20,         # the number of evaluations of the objective function\n                  n_random_starts=5,  # the number of random initialization points\n                  random_state=42)   # the random seed\n\nprint(f'The minimum value of f(x) is {res.fun:0.4f} and occurs at x={res.x[0]:0.4f}, y={res.x[1]:0.4f}')\nprint(f'Recall that the objective function may include noise, so the optimized function value may not be exact.')\n\nfig = plt.figure(figsize=(10,6)) # we initialize the plot so we can control dimensions\nax = fig.add_axes\nplot_convergence(res,ax);","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"The minimum value of f(x) is 0.0000 and occurs at x=0.0000, y=0.0000\nRecall that the objective function may include noise, so the optimized function value may not be exact.\n"},"1":{"data":{"image/png":"9f21970e0d26e9101e3a9292591d9a4639f4fbbc","text/plain":"<Figure size 720x432 with 1 Axes>"},"metadata":{"image/png":{"height":386,"width":616}}}},"pos":65,"start":1673888530736,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888537132,"exec_count":28,"id":"3b81de","input":"# execute for video\nplay_video(\"ds775_lesson6_hyperparameter-tuning\")","kernel":"python3","no_halt":true,"output":{"0":{"data":{"iframe":"6420a9a3136020d9af7fe9317a123e6fe0130e56","text/plain":"<IPython.lib.display.IFrame at 0x7f47a7e96c10>"},"exec_count":28}},"pos":69,"start":1673888537100,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888537238,"exec_count":29,"id":"6a8775","input":"X = np.array([i for i in range(30)]).reshape(-1,1)\n\nX, y = load_iris(return_X_y=True)\n\nlogreg=LogisticRegression(max_iter=500)\n\nlogreg.fit(X,y)\ny_pred = logreg.predict(X)\n\nconfusion_matrix(y,y_pred)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"array([[50,  0,  0],\n       [ 0, 47,  3],\n       [ 0,  1, 49]])"},"exec_count":29}},"pos":71,"start":1673888537143,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888539901,"exec_count":30,"id":"7ac37e","input":"def estimated_accuracy(p,X,y):\n    logreg = LogisticRegression(C=10.0**p, max_iter = 500 )\n    means = cross_val_score( logreg, X, y, cv = 10, scoring = 'accuracy')\n    return -np.mean(means)","kernel":"python3","no_halt":true,"pos":73,"start":1673888537261,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888541295,"exec_count":31,"id":"47d2b7","input":"-estimated_accuracy(0, X, y)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"0.9733333333333334"},"exec_count":31}},"pos":75,"start":1673888539965,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888557531,"exec_count":32,"id":"e9606c","input":"# this takes a second since 50*10 = 500 models are being trained\nnum_plot_points = 50\np_exp = np.linspace(-2,2,num=num_plot_points,endpoint=True)\nest_acc = np.array([-estimated_accuracy(p,X,y) for p in p_exp])","kernel":"python3","no_halt":true,"pos":77,"start":1673888541354,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888558220,"exec_count":33,"id":"60a977","input":"# make the plot\nplt.plot(p_exp,est_acc,'.-')\nplt.xlabel('p')\nplt.ylabel('estimated accuracy')\nplt.title('Estimated Accuracy of Logistic Regression with C = 10^p');","kernel":"python3","no_halt":true,"output":{"0":{"data":{"image/png":"cc843eb5aeecb30c209cde09dd8f8efd0ab232ae","text/plain":"<Figure size 864x504 with 1 Axes>"},"metadata":{"image/png":{"height":440,"width":726}}}},"pos":78,"start":1673888557564,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888577891,"exec_count":34,"id":"5cc052","input":"# define a lambda function that includes X,y to be passed to gp_minimize\nest_acc = lambda p:estimated_accuracy(float(p[0]),X,y)\n\nres = gp_minimize(est_acc,      # the function to minimize\n                  [(-2,2)],                # the bounds on each dimension of x\n                  acq_func=\"EI\",            # the acquisition function - using Expected Improvement\n                  n_calls=20,         # the number of evaluations of the objective function\n                  n_random_starts=5,  # the number of random initialization points\n                  random_state=38) # the random seed\n\nprint(f'The maximum accuracy is about {-100*res.fun:0.2f}%')\nprint(f'Max accuracy occurs when p = {res.x[0]:0.2f} or C = 10^p = {10**res.x[0]:0.2f}')\n      \nfig = plt.figure(figsize=(10,6)) # we initialize the plot so we can control dimensions\nax = fig.add_axes\nplot_convergence(res,ax);","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"The maximum accuracy is about 98.67%\nMax accuracy occurs when p = 1.00 or C = 10^p = 10.00\n"},"1":{"data":{"image/png":"5d84d1e9643202e404497575da0395bdaab993e9","text/plain":"<Figure size 720x432 with 1 Axes>"},"metadata":{"image/png":{"height":386,"width":630}}}},"pos":80,"start":1673888558235,"state":"done","type":"cell"}
{"cell_type":"code","end":1673888578091,"exec_count":35,"id":"5a56b7","input":"logreg=LogisticRegression(max_iter=500, C = 10.0)\n\nlogreg.fit(X,y)\ny_pred = logreg.predict(X)\n\nconfusion_matrix(y,y_pred)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"array([[50,  0,  0],\n       [ 0, 48,  2],\n       [ 0,  1, 49]])"},"exec_count":35}},"pos":82,"start":1673888577933,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"02597a","input":"The next step would be to find evaluate the actual objective function to get $y$ values for the new sample point and then append the point, $x$ and $y$, to the sample.  Now go back to the model building step and repeat the process until happy.  We'll show what that looks like for a couple of iterations with $\\kappa =10.$. The first cell below initializes the sample data and loads the helper functions.  The second cell can be executed repeatedly to perform multiple iterations of Bayesian Optimization.","pos":52,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"05babc","input":"Revisit the Value Balancing example from Lesson 5 and solve it using `simanneal`.\n\nSee if your code can find the correct answer to our 4-item/2 group problem first. Even if you don't use the debug flag, use plenty of print statements to help you follow the action at first.\n\nWhen you have that working, using the following code to generate a larger list of item values. Break it into 4 groups. \n\nWhich works better - our implementation or the `simanneal` package?","metadata":{"hidden":true},"pos":20,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"084141","input":"Scikit-Optimize expects that you are minimizing an objective function. ","pos":58,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"17c168","input":"In practice, we don't know the actual function and since it's very expensive to evaluate we only know it at a limited sample of points.  Let's say that we've evaluated the objective function at x = 0,2,4,7,9 to obtain our initial sample of points:","pos":40,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1d88bd","input":"### Tuning Hyperparameters using Bayesian Optimization\n\n**<font color=\"red\">The material in this section is optional but will provide you some background for the Lesson 8 Project on tuning hyperparameters for machine learning models.  There won't be any homework problems for the material in this section.</font>. You may still wish to read the final section below for a summary of Bayesian Optimization.**\n\nThis video summarizes the material in this section:","pos":68,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1f1937","input":"Here is a 3D plot that makes it easier to see the local minima in the search space.  A local search will easily get stuck in the wrong minimum if the initial search point isn't very close to the origin.","pos":27,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"21c479","input":"While there is not a dramatic difference we can see from the confusion matrix that one more observation was classified correctly than before, so optimizing the hyperparameter produced a small benefit here.  Sometimes hyperparameter optimization can make the difference between a good model and a bad one.  There is one homework problem where we'll have you optimize a parameter for a Ridge Regression (Linear Regression with overfitting penalty), but we'll explore hyperparameter optimization further in Lesson 8.","pos":83,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"27a130","input":"### *Self Assessment: Simulated Annealing for Value Balancing with `simanneal`*","metadata":{"hidden":true},"pos":19,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3a67dc","input":"Simulated annealing was designed for combinatorial (discrete) optimization problems, but has been adapted to continuous optimization problems.  The main issue is how to generate a new move at each iteration.  There are many variations, but often the move is selected at random from a suitable probability distribution such as a normal or uniform distribution.\n\nThe objective functions we consider here aren't from real applications, instead they're chosen to give you an idea how the algorithm works for difficult optimization problems with many local optima.  It's good to have this sort of thing in mind when, for instance, you're trying to train a complicated neural network and have to optimize the weights in the network to find the best fit to your data.","metadata":{"hidden":true},"pos":23,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"403672","input":"### Steps in Bayesian Optimization\n\nWe are going to walk through the steps in Bayesian Optimization below.  We'll implement each step in Python.  Don't worry too much about the exact coding details since we'll ultimately use packages to automate Bayesian Optimization.  Instead, just focus on developing a high-level picture of how Bayesian optimization works.  If you want more details, there are **many** tutorials available with a bit of googling.  <a href=\"https://towardsdatascience.com/the-beauty-of-bayesian-optimization-explained-in-simple-terms-81f3ee13b10f\">This article</a> gives a high-level view and talks a bit about what makes this optimization approach \"Bayesian\".  The image below illustrates the steps.  It's called \"Bayesian\" because a Bayesian probability framework is used to show how to update the surrogate model to reflect the knowledge gained from the additional sample point.\n\n<img src=\"images/BayesianOptimizationFlowChart.png\" width = \"400\" align=\"center\"/>\n\n<br><br>\n\n#### Define your Objective Function and Evaluate on Initial Sampling Set\n\nThe first step in any optimization problem is determining your objective function. Bayesian optimization requires an objective function in which your variables have bounds (a finite limit on each real or integer number or a defined set of values for categorical variables). \n\nFor illustration we'll work with an objective function that has one input variable.  Suppose we want to minimize\n$$f(\\mathbf{x})=x \\sin(x) + \\epsilon, \\mbox{ for } x \\in [0,10].$$\n\n$\\epsilon$ is a normally distributed random variable with mean 0 and standard deviation $\\sigma$ that represents the theoretical noise level.  Setting $\\sigma = 0$ gives an ordinary function without added noise.\n\nHere is a graph of the objective function (without noise) to help you visualize:","pos":38,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"474ab4","input":"It appears that the maximum estimated accuracy occurs around $p \\approx 1$ or $C \\approx 10^p = 10^1 =10$. We'll minimize the negative accuracy, using `gp_minimize` to find the maximum estimated accuracy and the value of $p$ for which it occurs.  If you haven't studied machine learning yet all you really need to understand is that to tune the hyperparameters we need to optimize a function (`estimated_accuracy`) of the hyperparameters.","pos":79,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4cec95","input":"To use simulated annealing to optimize a function with continuous variables isn't all that different than how we used it to find a good, or even optimal, tour in the traveling salesman problem.  \n\nWe're going to rely on the `simanneal` package in the rest of this lesson because it's much more robust than our \"home-brewed\" code in the `simanneal_tsp()` function above. \nTo use the package we'll have to generate an initial state, define the `energy()` method for returning the objective function value, and define the `move()` method for making a move from a current state to a new state.\n\nTo generate an initial state you could select uniformly distributed random numbers between -1 and 1:\n```\ninit_state = np.random.uniform(low=-1, high=1, size=2)\n```\n\nWe like to write functions for computing the objective function value and for making moves and then call those functions from the `move()` and `energy()` methods in the class definition for our problem as we did in the simanneal package TSP example above.\n\nWe already have the objective function from where we made the contour plot:\n```\ndef f(xy):\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n```\n\nMaking a move will consist of applying two functions successively.  The first function adds normally distributed random numbers to each variable while the second function clips values that are out of the $[-1,1]$ bounds.  The scale of the move will need to be passed to the first function, while the values of the lower and upper bounds need to be passed to the clipping function.  These values will need to be initialized in the `__init__` constructor similar to how we worked with the distance matrix in the TSP example.  Here are the functions:\n```\ndef gauss_move(xy,sigma):\n    # xy is a 1 by dim numpy array\n    # sigma is the standard deviation for the normal distribution\n    dim = len(xy)\n    return xy + np.random.normal(loc = 0, scale = sigma, size=dim)\n\ndef clip_to_bounds(xy,low,high):\n    # xy is a 1 by dim numpy array\n    # low is the lower bound for clipping variables\n    # high is the upper bound for clipping variables\n    return np.array( [min(high,max(low,v)) for v in xy])\n```","metadata":{"hidden":true},"pos":29,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"519e37","input":"### Building the Acquisition Function\n\nFrom the surrogate model we'd like to identify another point to add to our sample (another magenta point) where we'll evaluate the actual objective function.  To do this we will first construct an acquisition function from the surrogate and then use the acquisition to \"acquire\" the next point.\n\nNext we need what's called an acquisition function. Remember we said that Bayes Optimization learns as it goes. It does that by \"acquiring\" new data points. Each iteration of the algorithm will run the surrogate model and then \"acquire\" the sample point or points that are most likely to improve the overall results. Again, there are many ways to do approach determining what the best new points are. Three common approaches are:\n\n* Probability of Improvement (PI).\n* Expected Improvement (EI).\n* Lower Confidence Bound (LCB).\n\nWe'll demonstrate by building the LCB acquisition function.  The surrogate model returns both the approximate function value as $\\mu(x)$ and the expected variability, the standard deviation, as $\\sigma(x)$.  The formula for the LCB is\n$$a(x) = \\mu(x) - \\kappa \\sigma(x).$$ Essentially, the LCB is found by looking $\\kappa$ standard deviations below the surrogate function values.  We won't discuss the other acquisition functions here, but there are many articles that can help <a href=\"https://distill.pub/2020/bayesian-optimization/\">like this one.</a>\n\nHere are two examples.  (We've also defined a helper function for plotting here.)","pos":48,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"5472d4","input":"#### *Self-Assessment for Simulated Annealing with Continuous Variables*\n\nUse the objective and move functions from above to create a class using the `simanneal` package.  Use it to approximate the location of the global minimum for the \"Bumpy\" function above.  You'll notice that you will usually get close to the location of the global minimum at the origin, but it won't be exact because it is very difficult to randomly move exactly to the minimum location.  Typically, for continuous functions, simulated annealing is combined with local search in an iterative procedure (we'll see an example of this in the homework with the `dual_annealing` optimizer from the `scipy.optimize` package.  For this example you could take the best state found by simulated annealing and use it to start a local search using `minimize` from `scipy.optimize` package.\n\nThe code from the TSP example above is a good starting point.  Instead of the distance matrix you'll need to pass the scale parameter sigma to determine the size of the moves.  A good starting point for sigma is range/6 where range = upper bound - lower bound.  This value for sigma is because a normal distribution is about 6 * sigma wide.  You may want to experiment with the value of sigma to see how it affects the result of simulated annealing.  You could also play with the time allowed when you set the schedule for the annealing.\n\n### Dual_Annealing from scipy.optimize\n\nSimulated annealing works with both continuous and discrete variables.  For the case of continuous variables the dual_annealing algorithm in the scipy.optimize package tends to work rather well.  It combines simulated annealing for exploration of the search space along with local search to enhance the convergence once a good minimum is found.  It's pretty easy to use and <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.dual_annealing.html\">documentation can be found here.</a>. You can also execute the cell below to see the documentation:","pos":31,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"59de18","input":"To complete the surrogate function we still need to declare a Gaussian Process Regressor object and fit it to the sample points:","pos":44,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"5abf57","input":"## Simulated Annealing for Continuous Optimization","metadata":{"heading_collapsed":true,"hidden":true},"pos":22,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"5c049f","input":"### *Self Assessment: Simulated Annealing for Value Balancing*","metadata":{"heading_collapsed":true,"hidden":true},"pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"5c7529","input":"We'll use the seven city example TSP from the textbook. Find the shortest tour (or cheapest cost) to visit all 7 cities and return to the starting city in the following graph:\n\n<img src=\"./images/HillierTSP.png\" width=400>\n\nWe'll store all the intercity distances in a two-dimensional list that we call distance_matrix. For cities that aren't connected we'll use the \"bigM\" method and introduce a distance of 100 between those pairs of cities so that those routes won't be included in the tour. Note that the picture labels the cities 1 through 7, but in Python we'll use 0 through 6.  The data is stored in the included json file.\n\nIf you want to really understand how simulated annealing works, the following video includes a walkthrough of the code below.","metadata":{"hidden":true},"pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"67af47","input":"# Simulated Annealing","metadata":{"heading_collapsed":true},"pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"748b93","input":"#### Dual_Annealing Applied to \"Bumpy\"\n\nTry executing the cell below.  Note that you won't get exactly the same answer if you execute the cell repeatedly because of the random nature of simulated annealing.  In any case, the global minimum function value is 0 and occurs at x = 0, y = 0.  Dual_annealing finds this minimum approximately to within its default convergence settings:","pos":33,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7c6e77","input":"Our from-scratch solution is not the best implementation of this algorithm. But we wanted to include it so that you could really step through each of the pieces.  Instead of continuing forward and writing our own Bayesian Optimization function we'll rely on packages.\n\nThere are several packages that implement Bayes Optimization in a much more efficient way. We'll focus on `Scikit-Optimize` since it's designed to work in conjunction `Scikit-Learn` package for machine learning that we'll meet in Lesson 8.\n\n\n## Bayesian Optimization with `Scikit-Optimize`\n\nThe video below describes the material in this section and the next.","pos":56,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"91e7cd","input":"The function we need to use to run our Bayesian Optimization is <a href=\"https://scikit-optimize.github.io/stable/modules/generated/skopt.gp_minimize.html\">gp_minimize</a>. There are many parameters you can set on this function, so I encourage you to read the documentation to understand all of them. We are only going to set a few:\n\n* the function to minimize (which should return a scalar (single number) value)\n* the dimensions that will be searched\n* the acquisition function\n    * We can also choose from LCB for lower confidence bound, EI for expected improvement, PI for probability of improvement or gp_hedge, which probabilistically chooses from one of the first three options at every iteration. This is the default option. But, we'll switch to LCB, since that's what we were using above.\n* the number of evaluations of the objective function (n_calls)\n\nThe function returns an \"Optimization Result\" object that contains the location of the minimum, the function value at the minimum, and several other values. (Don't worry if you see warnings, they seem to be harmless.  We've attempted to suppress the warnings in this section.)","pos":60,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"923146","input":"# Lesson 06: Global Optimization 1","pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"94ba2b","input":"### A non-convex 2D example","metadata":{"heading_collapsed":true,"hidden":true},"pos":24,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9a1f21","input":"#### Self-Assessment - Bayesian Optimization of the Booth function\n\nUse Bayesian Optimization (`gp_minimize`) to estimate the global minimum value of the Booth function, a common optimization test problem:\n\n$f(x,y)=(x+2y-7)^2+(2x+y-5)^2$\n\nfor $x$ and $y$ both in [-10,10].","pos":67,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9dace8","input":"The estimated accuracy when $C=1$ (this is $p=0$ and is the default value) is:","pos":74,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a2c8a8","input":"We found this two-dimensional example in <a href=\"http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\">this tutorial</a> on simulated annealing.\n\nFind the minimum value of \n$$f(x,y) = 0.2 + x^2 + y^2 - 0.1 \\cos(6 \\pi x) - 0.1 \\cos(6 \\pi y)$$ \n\nfor $-1 \\leq x,y \\leq 1$.  This function is similar to the Rastrigin function and the global minimum value is $f(0,0) = 0$.  A contour plot, shown below, illustrates that there are many local minima (in the center of many of the small loops, some correspond to local maxima).  The <a href = \"http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\">tutorial</a> itself is worthy of a look and has a nice flow chart outlining how simulated annealing works.","metadata":{"hidden":true},"pos":25,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a9ad7a","input":"# Global Optimization\n\nThe goal of global optimization is to find the global optimal value which means we want to identify the best possible solution in the entire search space.  However, for many problems the search space is too large and/or the function landscape is too complicated to guarantee that the best solution can be found.\n\nA metaheuristic algorithm attempts to find a good solution without any guarantee of being able to find the best solution.  Often metaheuristics are stochastic in nature, that is they incorporate randomness as an element of the search, but they aren't generally completely random in nature.  They incorporate search patterns which are known to work well for the problem at hand.\n\nMetaheuristic algorithms try to find a compromise somewhere between randomly searching the search space and local search.  People speak of the **exploration and exploitation tradeoff**.  Exploration ensures the algorithm reaches different promising regions of the search space, whereas exploitation ensures the searching of optimal solutions within the given region.  The trick is in finding the right balance. Go too far into exploitation and the algorithm gets stuck in local extrema, go too far to exploration and the algorithm will waste time on solutions that are less likely to be good and ignore the information already gathered.\n\nUnfortunately, there is no single algorithm which works best for all classes of problems.  This is often referred to as a \"no free lunch theorem\" in optimization.  In this lesson, we focus on Simulated Annealing and Bayesian Optimization.","metadata":{"hidden":true},"pos":3,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"abc29e","input":"The LCB acquisition function is the red curve at the bottom of the uncertainty envelope.  To acquire the next search point we seek the global minimum of the acquisition function.  Note that when $\\kappa = 1$ the acquisition (red) and surrogate function graphs are pretty similar so that when we minimize the acquisition function we get about $x = 4.3$ which is close to the current minimum value at $x = 4.3$. When $\\kappa = 10$ the new minimum occurs around $x = 5.1$ because $\\kappa = 10$ places more emphasis on the uncertainty in the surrogate model.  The vertical dashed black lines show the location of the next point identified by minimizing the acquisition function.\n\n*Small values of $\\kappa$ emphasize local search (exploitation) while large values of $\\kappa$ emphasize global search (exploration).*\n\nThe next step is to acquire the new point by finding or approximating the minimum of the acquisition function.  Normally we'd let a Bayesian Optimization package handle the details, but we'll show one way to do it for a one-dimensional function here.","pos":50,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b319b4","input":"## Some Final Notes on Bayesian Optimization\n\nBayesian Optimization is expensive and should only be used if \n\n* the objective function is very expensive to evaluate\n* the dimensionality of the problem (the number of input variables) is not too large, e.g. $\\leq 20$\n* the derivative of the objective function is unknown or unavailable (the derivate is a function which reveals the slope of the function)\n* you are seeking a global minimum instead of a local minimum.\n* the objective function may include noise so that the function does not return the same value every time it is evaluated\n\nIf your objective function doesn't meet those conditions, then there are probably better optimization methods available like simulated annealing or genetic algorithms (next lesson).\n\nBayesian Optimization can also be extended to accommodate discrete (integer) and categorical decision variables.  We won't study those extensions here, but we'll seem then in Lesson 8 where we'll see how Bayesian Optimization is used to optimize the hyperparameters of machine learning models.  We'll see a lot more about this in the Lesson 8 Project.\n\nThe animated gif below is kind of fun and illustrates Bayesian Optimization for a maximization problem with two decision variables.  Notice how the surrogate function (the Gaussian Process mean) becomes more and more like the actual function as sampling points are added.\n<br>\n\n<img src=\"./images/bayesian_optimization.gif\" width = \"1000\">\n\nThis animated gif is from this <a href=\"https://github.com/fmfn/BayesianOptimization\">Bayesian Optimization repository on Github</a>. We haven't tried the Bayesian Optimizer in that repository, but it looks like it could be pretty good.","pos":84,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b526a3","input":"This week we're going to continue our exploration of global optimization by looking at two global optimization algorithms:  Simulated Annealing and Bayesian Optimization.","pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b7994a","input":"## Using the `simanneal` package (video)","metadata":{"heading_collapsed":true,"hidden":true},"pos":14,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"bdb1e2","input":"Let's see how the estimated accuracy varies as $p$ changes.  We'll consider $ -2 \\leq p \\leq 2$ corresponding to $ 0.01 \\leq C \\leq 100.$. ","pos":76,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"bdc16e","input":"Revisit the Value Balancing Problem introduced in Lesson 5 (it's the next-to-last section in the lesson).  Start with the local search code that is included in the self-assessment solutions and adapt it to do simulated annealing for the Value Balancing problem.  First try it on the four item problem and then see how it performs on the 1000 item problem.  Do you get good solutions?","metadata":{"hidden":true},"pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c4079a","input":"\nIn machine learning the predictive models must be trained to give predictions that match the data as well as possible.  Each model has both parameters and hyperparameters.  Parameters are coefficients in the model that are determined directly from the data.  Hyperparameters are values that affect the model but aren't determined directly from the data.  Normally they are supplied by the scientist and sometimes tuned to produce a better fit.\n\nRegression models often include regularization terms that help prevent the model from overfitting (memorizing) the data instead of capturing the underlying trend.  We won't talk about the details of regularization here, but it's discussed in the DS740 class (<a href=\"https://towardsdatascience.com/the-basics-logistic-regression-and-regularization-828b0d2d206c\">here's an article if you really want to explore more</a>).  The strength of the regularization is inversely proportional to a constant $C$ (regularization $\\sim 1/C$).  So when C is large there is very little regularization, but when $C$ is small the regularization is large which forces the logistic regression model to depend mostly on only the important predictor variables.  We're going to consider $C = 10^p$ so positive $p$ corresponds to large $C$ and negative $p$ corresponds to small values of $C$.  The value of $C$ (or $p$) is not determined by the data but must be specified.  Below, we'll show an example of using Bayesian Optimization to determine an optimal value of $C$ to maximize model accuracy.  You'll be doing much more of this in Lesson 8 so don't worry too much about the details here.\n\n#### Predicting Iris Species\n\nIn the classic Iris dataset we have a four predictor variables corresponding to physical measurements of the iris and a single categorical variable that is species of the iris.  Three species are possible.  If you've never seen this data before or want to review some logistic regression then <a href=\"https://randerson112358.medium.com/python-logistic-regression-program-5e1b32f964db\">here is a short article that may help.</a>\n\nTo get an idea how logistic regression works here we'll load the data, train a model using the default hyperparameter values, and display the confusion matrix.  We've increased the maximum iterations for the Logisitic Regression model fit to help with convergence.","pos":70,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d256fb","input":"The `simanneal` package is pretty straightforward to use. Using the `simanneal` package has a couple of advantages over our version of simulated annealing above.  First, we don't have to worry about the algorithm framework.  Second, we don't have to worry about figuring out a temperature schedule.  While it's possible to specify a temperature schedule, it is far easier to use the `auto` scheduler and specify the approximate amount of time we'd like to wait for a solution\n\nThe package works by making an object of the `Annealer` class and then calling the anneal method on that object. To set up a problem we have to set three things in our instance of the `Annealer` class.\n\n1.  the state initializer \n2.  the move function that tells the annealing algorithm how to generate new moves\n3.  the fitness function (fitness is called energy in this package, and it was called objective in the `locsearch` package in Lesson 4).\n\nThe anneal method appears to always find minima, so you may have to negate your function if you want to find a maximum. The <a href=\"https://github.com/perrygeo/simanneal\">Github page</a> has some short documentation about the `simanneal` package.\n\nThe next cell is walkthrough of the code below.","metadata":{"hidden":true},"pos":15,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d5a3b6","input":"# Simulated Annealing with TSP (video)","metadata":{"hidden":true},"pos":6,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d8d074","input":"If the classification were perfect there would be 50's along the diagonal and zeros elsewhere.  This confusion matrix indicates that four of the 150 irises were misclassified.  The accuracy is $146/150 = 97.3\\%.$. Now we'll see if we can maximize the accuracy by using Bayesian Optimization to optimize the value of the regularization parameter $C$.  Instead of optimizing $C$ directly, we'll actually optimize $p$ and set $C = 10^p$.  This is because for many small parameters it makes sense to try values like $10^{-4}, 10^{-3}, 10^{-2}, \\ldots$ instead of $0.1, 0.2, 0.3, \\ldots$ (this <a href=\"https://stats.stackexchange.com/questions/291552/why-do-we-sample-from-log-space-when-optimizing-learning-rate-regularization-p\">Stackexchange post</a> explains it nicely). The accuracy is estimated by finding the average accuracy after 10-fold cross validation.  Note, we've defined our function to return the negative average accuracy for the purpose of maximization a bit later.","pos":72,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e38bea","input":"This package also contains some handy plots. Let's plot convergence. This will tell us how quickly the best value was achieved. In this case, we achieved our best result by the 15th iteration.","pos":62,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e63d56","input":"## Bayesian Optimization\n\nBayesian Optimization is becoming quite popular in the machine learning world. The big advantage of Bayesian Optimization is that it learns as it goes, and does so more efficiently than just repeatedly solving whatever your objective function is. It does this by using a surrogate function that's generally much less expensive to evaluate than the objective function is, and using the results of that surrogate function to update the sample data and zero in on the optimal solution.  Bayesian Optimization is useful when:\n* the objective function is very expensive to evaluate\n* the dimensionality of the problem (the number of input variables) is not too large, e.g. $\\leq 20$\n* the derivative of the objective function is unknown or unavailable (the derivate is a function which reveals the slope of the function)\n* you are seeking a global minimum instead of a local minimum.\n* the objective function may include noise so that the function does not return the same value every time it is evaluated\n\nWe will see that Bayesian Optimization gets used for Hyperparameter Optimization of machine learning models.  Machine learning models can be expensive to evaluate and because they often work with random subsets of the training data they may not produce the same results on every evaluation.\n\n### Bayesian Walkthrough Video 1\n\nIn this video we talk through the main ideas in Bayesian Optimization and we go through the notebook sections below \"Steps in Bayesian Optimization\" through \"Putting it Together by Iterating\".   There will be two more videos on Bayesian Optimization further below.","pos":36,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e65538","input":"We find it pretty amazing that Bayesian Optimization finds the global optimum so quickly for a function with so many local optima.","pos":66,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e744c2","input":"The five magenta points are all the information we currently know about the objective function. Note that they don't lie exactly on the graph of the objective function because we've included a bit of noise. We want to use the information from the sampled points to smartly choose another point that will, hopefully, be closer to the global minimum.  We build a model of the function called a surrogate function to help choose that next point.\n\n### Building the Surrogate Function\n\nThe idea behind the surrogate is that it will be cheap to evaluate compared to the objective function so that we can use it to select an optimal next point to add to our sample points.  For Bayesian Optimization the surrogate function is usually a Gaussian Process Regressor.  We won't discuss the details of the model here, but it's important to know that in addition to estimating the function values, a Gaussian Process Regressor model also estimates the uncertainty of the function.\n\nWe'll use the default parameters for the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html\">GaussianProcessRegressor</a> for our surrogate function. This function can issue warnings if we don't have a lot of data at a particular part of the distribution we're sampling, so we'll write a wrapper function to supress the warnings, and we'll return the standard deviation, which we'll use in the next step.\n\nLike all predictive models, this model needs to be trained. We'll get to that shortly. For now, let's just define our surrogate function.","pos":42,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e7bcf4","input":"Notice that the Dual_Annealing algorithm requires many fewer function evaluations than either of the simulated annealing implementations we studied above.  This is because the combination of global and local search is especially efficient.","pos":35,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ea816e","input":"At this point we've initialized the Gaussian Process regression model using the first five sample points.  \n\n### Putting it Together by Iterating\n\nEach time you execute the next cell you'll complete one iteration of Bayesian optimization that results in new value of $x$ that will be added to the sample (the vertical black dashed line is the location of the next $x$ based on the current data.","pos":54,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ebf6f0","input":"Interestingly, the best model fit occurs when $\\alpha = 0.1$, but the default value of $\\alpha$ is 1.0.","pos":85,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f1466d","input":"In the plot above we're showing negative accuracy, so more negative is good.  Let's look at the confusion matrix with the optimized parameter.","pos":81,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f1bc8a","input":"### Bayesian Optimization for Multi-Dimensional Functions\n\nThe `gp_minimize` algorithm can handle multi-dimensional functions, as long as what's returned from your objective function is a scalar value. Let's consider the \"bumpy\" function from our simulated annealing section above.\n\nFind the minimum value of \n$$f(x,y) = 0.2 + x^2 + y^2 - 0.1 \\cos(6 \\pi x) - 0.1 \\cos(6 \\pi y)$$ \n\nfor $-1 \\leq x,y \\leq 1$. \n\nThe bounds for this function are [-1,1] for both x and y, and the global minimum of 0 is at f(0,0). For plots of the \"bumpy\" function scroll up to the Simulated Annealing section.\n","pos":64,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f66ad9","input":"To visualize we plot the actual function, the surrogate function, the sample points, and an envelope around the surrogate function that extends vertically by one (estimated) standard deviation in each direction.  Notice that the uncertainty is largest when we are far from the sampled points and smallest near the sampled points.","pos":46,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f9d9f9","input":"Think of simulated annealing as an enhanced local search that allows some moves that don't improve the best function value to try to climb\n\nIn a hill-climbing local search we only allow moves that increase the objective function value.\n\nHere is our pseudo-code from the previous lesson for **Local Search:**\n```\n set starting state \n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum \n             remember it \n endwhile \n ```\n\nSimulated annealing is a trajectory based method for generating a sequence of solutions and is similar our basic \"hill-climbing\" local search algorithm.  In a strict hill-climbing algorithm we only allow uphill moves, but in simulated move we sometimes allow downhill moves and are more likely to allow downhill moves in the early part of the search.  The idea is that to find the tallest peak in a mountain range we have to first descend from a lower peak.\n\nThe probability of a downhill move is determined by a temperature parameter that decreases throughout the search.  The probability of a downhill move depends on the size of the downhill move compared to the temperature.  At high temperatures large and small downhill moves are probable, but as the temperature decreases only small downhill moves are probable so that the search performs similarly to a local search at low temperatures\n\nIn simulated annealing algorithm high temperature promotes exploration (global search) while low temperature promote exploitation (local search).  As the algorithm proceeds, the temperature decreases and transitions from exploration to exploitation.\n\nHere is pseudocode for **Simulated Annealing:**\n```\n set starting state and initial temperature\n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum or random # < probability determined by temperature\n             remember it\n     decrease temperature\n endwhile \n ```\n \nChoosing the initial temperature and the manner in which the temperature decreases are critical to the performance of simulated annealing.  We'll start with a temperature schedule that looks like this:\n$$ T = T_0 \\alpha^n.$$\nWhere $T_0$ is the initial temperature, $0 < \\alpha < 1,$ and $n$ is the number of iterations.   This is called geometric temperature decay, but many other choices are possible.  However, there aren't really rules for how to choose $T_0$ and $\\alpha$.  Usually we'll choose $T_0$ to be similar to the size of the function to be optimized when it is evaluated at random points and $\\alpha$ should be close to $1$ like $\\alpha = 0.99$.  You may have to experiment with the values of these parameters to achieve good results.  The simanneal package introduced below includes some automatic tuning of the temperature schedule that seems to work well for many problems, but it can be much slower than setting a fixed schedule for some problems.\n\nIn the next section we'll demonstrate simulated annealing using our own code for the traveling salesman problem, but in general we'll use the `simanneal` package that will be introduced further below.","metadata":{"hidden":true},"pos":5,"state":"done","type":"cell"}
{"id":0,"time":1673887576003,"type":"user"}
{"last_load":1673887577044,"type":"file"}